# Task ID: 15
# Title: Production Monitoring and Observability
# Status: pending
# Dependencies: 12
# Priority: medium
# Description: Implement comprehensive monitoring with Prometheus metrics, structured logging, and distributed tracing for production observability.
# Details:
Add Prometheus metrics endpoint (/metrics) with custom metrics (query latency, embedding generation time, cache hit rate). Implement structured JSON logging with correlation IDs. Add OpenTelemetry tracing with Jaeger integration. Create custom dashboards in Grafana for key metrics. Implement alerting rules for SLA violations. Add performance profiling endpoints (pprof compatible). Use tracing and tracing-subscriber with json feature.

# Test Strategy:
Validate metrics endpoint format and values, test log aggregation and searching, verify trace propagation across services, test alert triggering for various scenarios, and validate dashboard accuracy under load.

# Subtasks:
## 1. Set up Prometheus metrics infrastructure [pending]
### Dependencies: None
### Description: Initialize Prometheus metrics collection with prometheus-rust crate, create metrics registry, and implement /metrics endpoint in the HTTP server
### Details:
Add prometheus and prometheus-hyper crates to Cargo.toml dependencies. Create a metrics module in crates/mcp/src/metrics.rs to define custom metrics (query_latency_histogram, embedding_generation_time_histogram, cache_hit_rate_counter, active_connections_gauge, request_counter). Integrate metrics registry into McpServer and add GET /metrics endpoint to expose Prometheus-formatted metrics. Ensure metrics are thread-safe using Arc and lazy_static for global registry.

## 2. Implement structured JSON logging with correlation IDs [pending]
### Dependencies: None
### Description: Replace current logging with structured JSON format using tracing-subscriber's json feature and add correlation ID propagation across requests
### Details:
Configure tracing-subscriber with json formatter in http_server.rs main function. Create middleware in server.rs to generate and inject X-Correlation-ID headers for each request. Add correlation_id field to all log spans using tracing::span! macro. Include structured fields like service_name, version, environment, timestamp in all log outputs. Ensure correlation IDs propagate through async operations and database queries.

## 3. Add OpenTelemetry tracing with Jaeger integration [pending]
### Dependencies: 14.1, 14.2
### Description: Implement distributed tracing using OpenTelemetry SDK with Jaeger exporter for end-to-end request visibility
### Details:
Add opentelemetry, opentelemetry-jaeger, and tracing-opentelemetry crates. Configure OpenTelemetry pipeline with Jaeger exporter in main initialization. Create spans for key operations: database queries (queries.rs), embedding generation, tool execution (handlers.rs), SSE connections. Add trace context propagation headers (traceparent, tracestate) to all HTTP responses. Configure sampling rate via OTEL_TRACE_SAMPLE_RATE environment variable.

## 4. Create custom metrics for query performance monitoring [pending]
### Dependencies: 14.1, 14.3
### Description: Instrument database queries and tool executions with detailed performance metrics including p50/p95/p99 latencies
### Details:
Add timing instrumentation to DocumentQueries methods in queries.rs using histogram metrics. Implement per-tool metrics in McpHandler::handle_tool_call with labels for tool_name and status. Track embedding generation time in batch processing. Add database connection pool metrics (active, idle, pending connections). Create custom buckets for latency histograms based on expected SLA (0.1s, 0.5s, 1s, 2s, 5s). Export metrics with appropriate labels for Grafana dashboard filtering.

## 5. Implement performance profiling endpoints [pending]
### Dependencies: 14.1, 14.2
### Description: Add pprof-compatible profiling endpoints for CPU and memory analysis in production
### Details:
Add pprof crate for profiling support. Create /debug/pprof/profile endpoint for CPU profiling with configurable duration. Add /debug/pprof/heap endpoint for memory profiling snapshots. Implement authentication middleware to protect profiling endpoints. Add rate limiting to prevent profiling abuse. Configure profiling to be opt-in via ENABLE_PROFILING environment variable. Document profiling endpoints in runbook for production debugging.


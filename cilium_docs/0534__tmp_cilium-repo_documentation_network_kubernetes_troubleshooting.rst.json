{
  "url": "file:///tmp/cilium-repo/Documentation/network/kubernetes/troubleshooting.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _troubleshooting_k8s:\n\n***************\nTroubleshooting\n***************\n\nVerifying the installation\n==========================\n\nCheck the status of the :term:`DaemonSet` and verify that all desired instances are in\n\"ready\" state:\n\n.. code-block:: shell-session\n\n        $ kubectl --namespace kube-system get ds\n        NAME      DESIRED   CURRENT   READY     NODE-SELECTOR   AGE\n        cilium    1         1         0         <none>          3s\n\nIn this example, we see a desired state of 1 with 0 being ready. This indicates\na problem. The next step is to list all cilium pods by matching on the label\n``k8s-app=cilium`` and also sort the list by the restart count of each pod to\neasily identify the failing pods:\n\n.. code-block:: shell-session\n\n        $ kubectl --namespace kube-system get pods --selector k8s-app=cilium \\\n                  --sort-by='.status.containerStatuses[0].restartCount'\n        NAME           READY     STATUS             RESTARTS   AGE\n        cilium-813gf   0/1       CrashLoopBackOff   2          44s\n\nPod ``cilium-813gf`` is failing and has already been restarted 2 times. Let's\nprint the logfile of that pod to investigate the cause:\n\n.. code-block:: shell-session\n\n        $ kubectl --namespace kube-system logs cilium-813gf\n        INFO      _ _ _\n        INFO  ___|_| |_|_ _ _____\n        INFO |  _| | | | | |     |\n        INFO |___|_|_|_|___|_|_|_|\n        INFO Cilium 0.8.90 f022e2f Thu, 27 Apr 2017 23:17:56 -0700 go version go1.7.5 linux/amd64\n        CRIT kernel version: NOT OK: minimal supported kernel version is >= 4.8\n\nIn this example, the cause for the failure is a Linux kernel running on the\nworker node which is not meeting :ref:`admin_system_reqs`.\n\nIf the cause for the problem is not apparent based on these simple steps,\nplease come and seek help on `Cilium Slack`_.\n\nApiserver outside of cluster\n==============================\n\nIf you are running Kubernetes Apiserver outside of your cluster for some reason (like keeping master nodes behind a firewall), make sure that you run Cilium on master nodes too.\nOtherwise Kubernetes pod proxies created by Apiserver will not be able to route to pod IPs and you may encounter errors when trying to proxy traffic to pods.\n\nYou may run Cilium as a `static pod <https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/>`_ or set `tolerations <https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/>`_ for Cilium DaemonSet to ensure\nthat Cilium pods will be scheduled on your master nodes. The exact way to do it depends on your setup.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/network/kubernetes/troubleshooting.rst",
  "extracted_at": "2025-09-03T01:13:29.243395Z"
}
{
  "url": "file:///tmp/cilium-repo/Documentation/network/concepts/ipam/multi-pool.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    http://docs.cilium.io\n\n.. _ipam_crd_multi_pool:\n\nMulti-Pool (Beta)\n#################\n\n.. include:: ../../../beta.rst\n\nThe Multi-Pool IPAM mode supports allocating PodCIDRs from multiple different IPAM pools, depending\non workload annotations and node labels defined by the user.\n\nArchitecture\n************\n\n.. image:: multi-pool.png\n    :align: center\n\nWhen running in the Multi-Pool IPAM mode, Cilium will use the ``ipam.cilium.io/ip-pool`` annotation\non pods and namespaces to determine the IPAM pool from which a pod's IP is allocated from.\n\n  1. If there is an ``ipam.cilium.io/ip-pool=A`` annotation on the pod itself, Cilium will\n     allocate the pod's IP from the pool named ``A``.\n  2. If there is no annotation on the pod, but the namespace of the pod has an\n     ``ipam.cilium.io/ip-pool=B`` annotation, Cilium will\n     allocate the pod's IP from the pool named ``B``.\n  3. If neither the pod nor the namespace have a ``ipam.cilium.io/ip-pool`` annotation,\n     the pod's IP will be allocated from the pool named ``default``.\n\nThe annotation is only considered when a pod is created. Changing the ``ip-pool``\nannotation on an already running pod has no effect.\n\nThe ``CiliumNode`` resource is extended with an additional ``spec.ipam.pools`` section:\n\n``spec.ipam.pools.requested``\n  List of IPAM pool requests for this node. Each entry specifies the pool and the number of\n  requested IP addresses. This field is owned and written to by the Cilium agent running on\n  the particular node. It is read by the Cilium operator to fulfill the requests.\n\n``spec.ipam.pools.allocated``\n  List of CIDRs allocated to this node and the pool they were allocated from.\n  Cilium operator adds new PodCIDRs to this field. Cilium agent removes PodCIDRs\n  it has released and is no longer using.\n\nIP pools are managed using the cluster-wide ``CiliumPodIPPool`` custom resource.\nEach ``CiliumPodIPPool`` contains the cluster-wide CIDR from which per-node\nPodCIDRs are allocated:\n\n.. code-block:: yaml\n\n  apiVersion: cilium.io/v2alpha1\n  kind: CiliumPodIPPool\n  metadata:\n    name: green-pool\n  spec:\n    ipv4:\n      cidrs:\n        - 10.20.0.0/16\n        - 10.30.0.0/16\n      maskSize: 24\n    ipv6:\n      cidrs:\n        - fd00::/104\n      maskSize: 120\n\nNew pools can be added at run-time. The list of CIDRs in each pool can also be\nextended at run-time. In-use CIDRs may not be removed from an existing pool, and\nexisting pools may not be deleted if they are still in use by a Cilium node.\nThe mask size of a pool is immutable and the same for all nodes. Neither restriction\nis enforced until :gh-issue:`26966` is resolved. The first and last address of a\n``CiliumPodIPPool`` are reserved and cannot be allocated. Pools with less than 3\naddresses (/31, /32, /127, /128) do not have this limitation.\n\n\nConfiguration\n*************\n\nMulti-Pool IPAM can be enabled using the ``ipam.mode=multi-pool`` Helm value.\nTo have the Cilium operator automatically create ``CiliumPodIPPools`` custom\nresources at startup, use the ``ipam.operator.autoCreateCiliumPodIPPools`` Helm\nvalue. It contains a map which follows the ``CiliumPodIPPools`` CRD schema\ndescribed above.\n\n.. code-block:: yaml\n\n  ipam:\n    mode: multi-pool\n    operator:\n      autoCreateCiliumPodIPPools:\n        default:\n          ipv4:\n            cidrs:\n              - 10.10.0.0/16\n            maskSize: 24\n        other:\n          ipv4:\n            cidrs:\n              - 10.20.0.0/16\n            maskSize: 24\n\n.. note::\n\n  For a practical tutorial on how to enable this mode in Cilium, see\n  :ref:`gsg_ipam_crd_multi_pool`.\n\nUpdating existing CiliumPodIPPools\n----------------------------------\n\nOnce you configure the ``CiliumPodIPPools``, you cannot update the existing pool. For example, \nyou can't change the default pool to a different CIDR or add an IPv6 CIDR to the default pool. \nThis restriction prevents pods from receiving IPs from a new range while some pods still use \nthe old IP pool on the same nodes. If you need to update the existing CiliumPodIPPools, Please\nuse these steps as the references.\n\nLet's assume you have a Kubernetes cluster and are using the ``multi-pool`` as the IPAM mode. \nYou would like to change the existing default pool CIDR to something else and pods will take the IP address from the new CIDR. \nYou hope the change will cause the least disruption to your clusters while updating the default pool to another CIDR.\n\nWe will pick some of your nodes where you would like to update the CIDR first and call them Node Group 1. \nThe other nodes, which will update the CIDR later than Node Group 1, will be called Node Group 2.\n\n1. Update your existing pool through ``autoCreateCiliumPodIPPools`` in helm values.\n2. Delete the existing ``CiliumPodIPPools`` from CR and restart the Cilium operator to create new ``CiliumPodIPPools``.\n3. Cordon the Node Group 1 and evict pods to the Node Group 2.\n4. Delete ``CiliumNodes`` for Node Group 1, restart the Cilium agents and uncordon for Node Group 1.\n5. Cordon Node Group 2, and evict pods to Node Group 1 so they can get IPs from the new CIDR from the pool.\n6. Delete ``CiliumNodes`` for Node Group 2, restart the Cilium agents and uncordon for Node Group 2.\n7. (Optional) Reschedule pods to ensure workload is evenly distributed across nodes in cluster.\n\nPer-Node Default Pool\n---------------------\n\nCilium can allocate specific IP pools to nodes based on their labels. This\nfeature is particularly useful in multi-datacenter environments where different\nnodes require IP ranges that align with their respective datacenter's subnets.\nFor instance, nodes in DC1 might use the range 10.1.0.0/16, while nodes in DC2\nmight use the range 10.2.0.0/16.\n\nIn particular, it is possible to set a per-node default pool by setting the\n``ipam-default-ip-pool`` in a ``CiliumNodeConfig`` resource on nodes matching\ncertain node labels.\n\n.. code-block:: yaml\n\n    ---\n    apiVersion: cilium.io/v2alpha1\n    kind: CiliumPodIPPool\n    metadata:\n      name: dc1-pool\n    spec:\n      ipv4:\n        cidrs:\n          - 10.1.0.0/16\n        maskSize: 24\n    ---\n    apiVersion: cilium.io/v2alpha1\n    kind: CiliumPodIPPool\n    metadata:\n      name: dc2-pool\n    spec:\n      ipv4:\n        cidrs:\n          - 10.2.0.0/16\n        maskSize: 24\n    ---\n    apiVersion: cilium.io/v2\n    kind: CiliumNodeConfig\n    metadata:\n      name: ip-pool-dc1\n      namespace: kube-system\n    spec:\n      defaults:\n        ipam-default-ip-pool: dc1-pool\n      nodeSelector:\n        matchLabels:\n          topology.kubernetes.io/zone: dc1\n    ---\n    apiVersion: cilium.io/v2\n    kind: CiliumNodeConfig\n    metadata:\n      name: ip-pool-dc2\n      namespace: kube-system\n    spec:\n      defaults:\n        ipam-default-ip-pool: dc2-pool\n      nodeSelector:\n        matchLabels:\n          topology.kubernetes.io/zone: dc2\n\nAllocation Parameters\n---------------------\n\nCilium agent can be configured to pre-allocate IPs from each pool. This behavior\ncan be controlled using the ``ipam-multi-pool-pre-allocation`` flag. It\ncontains a key-value map of the form ``<pool-name>=<preAllocIPs>`` where\n``preAllocIPs`` specifies how many IPs are to be pre-allocated to the local\nnode. The same number of IPs are pre-allocated for each address family. This\nmeans that a pool which contains both IPv4 and IPv6 CIDRs will pre-allocate\n``preAllocIPs`` IPv4 addresses and ``preAllocIPs`` IPv6 addresses.\n\nThe flag defaults to ``default=8``, which means it will pre-allocate 8 IPs from\nthe ``default`` pool. All other pools which do not have an entry in the\n``ipam-multi-pool-pre-allocation`` map are assumed to have a ``preAllocIPs`` of\nzero, i.e. no IPs are pre-allocated for that pool.\n\nDepending on the number of in-use IPs and the number of pending IP allocation\nrequests, Cilium agent might pre-allocate more than ``preAllocIPs`` IPs. The\nformula Cilium agent uses to compute the absolute number of needed IPs from each\npool is:\n\n.. code-block:: go\n\n  neededIPs = roundUp(inUseIPs + pendingIPs + preAllocIPs, preAllocIPs)\n\nWhere ``inUseIPs`` is the number of IPs that are currently in use,\n``pendingIPs`` number of IPs that have a pending pod (i.e. pods which have been\nscheduled on the node, but not yet received an IP), and ``preAllocIPs`` is the\nminimum number of IPs that we want to pre-allocate as a buffer, i.e. the value\ntaken from the ``ipam-multi-pool-pre-allocation`` map.\n\nRouting to Allocated PodCIDRs\n-----------------------------\n\nPodCIDRs allocated from ``CiliumPodIPPools`` can be announced to the network by the\n:ref:`bgp_control_plane` (:ref:`bgp_control_plane_multipool_ipam`). Alternatively,\nthe ``autoDirectNodeRoutes`` Helm option can be used to enable automatic routing\nbetween nodes on a L2 network.\n\n .. _ipam_crd_multi_pool_limitations:\n\nLimitations\n***********\n\nMulti-Pool IPAM is a preview feature. The following limitations apply to Cilium running in\nMulti-Pool IPAM mode:\n\n.. warning::\n   - IPAM pools with overlapping CIDRs are not supported. Each pod IP must be\n     unique in the cluster due the way Cilium determines the security identity\n     of endpoints by way of the IPCache.\n   - iptables-based masquerading requires ``egressMasqueradeInterfaces`` to be set\n     (see masquerading :ref:`masq_modes` and :gh-issue:`22273` for details).\n     Alternatively, eBPF-based masquerading is fully supported and may be used instead.\n     Note that if the used IPAM pools do not belong to a common native-routing CIDR,\n     you may want to use ``ip-masq-agent``, which allows multiple disjunct non-masquerading\n     CIDRs to be defined. See :ref:`concepts_masquerading` for details on how to use the\n     ``ip-masq-agent`` feature.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/network/concepts/ipam/multi-pool.rst",
  "extracted_at": "2025-09-03T01:13:29.210727Z"
}
{
  "url": "file:///tmp/cilium-repo/Documentation/observability/metrics.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _metrics:\n\n********************\nMonitoring & Metrics\n********************\n\nCilium and Hubble can both be configured to serve `Prometheus\n<https://prometheus.io>`_ metrics. Prometheus is a pluggable metrics collection\nand storage system and can act as a data source for `Grafana\n<https://grafana.com/>`_, a metrics visualization frontend. Unlike some metrics\ncollectors like statsd, Prometheus requires the collectors to pull metrics from\neach source.\n\nCilium and Hubble metrics can be enabled independently of each other.\n\nCilium Metrics\n==============\n\nCilium metrics provide insights into the state of Cilium itself, namely\nof the ``cilium-agent``, ``cilium-envoy``, and ``cilium-operator`` processes.\nTo run Cilium with Prometheus metrics enabled, deploy it with the\n``prometheus.enabled=true`` Helm value set.\n\nCilium metrics are exported under the ``cilium_`` Prometheus namespace. Envoy\nmetrics are exported under the ``envoy_`` Prometheus namespace, of which the\nCilium-defined metrics are exported under the ``envoy_cilium_`` namespace.\nWhen running and collecting in Kubernetes they will be tagged with a pod name\nand namespace.\n\nInstallation\n------------\n\nYou can enable metrics for ``cilium-agent`` (including Envoy) with the Helm value\n``prometheus.enabled=true``. ``cilium-operator`` metrics are enabled by default,\nif you want to disable them, set Helm value ``operator.prometheus.enabled=false``.\n\n.. parsed-literal::\n\n   helm install cilium |CHART_RELEASE| \\\\\n     --namespace kube-system \\\\\n     --set prometheus.enabled=true \\\\\n     --set operator.prometheus.enabled=true\n\nThe ports can be configured via ``prometheus.port``,\n``envoy.prometheus.port``, or ``operator.prometheus.port`` respectively.\n\n\nWhen metrics are enabled and ServiceMonitor is not enabled (``hubble.metrics.serviceMonitor.enabled: false``), all Cilium components will have the following annotations. These annotations can be used to signal Prometheus whether to scrape metrics.\n\nIf ServiceMonitor is enabled (``hubble.metrics.serviceMonitor.enabled: true``), these annotations are omitted and Prometheus discovers metrics via the ServiceMonitor resource.\n\n.. code-block:: yaml\n\n        prometheus.io/scrape: true\n        prometheus.io/port: 9962\n\nTo collect Envoy metrics the Cilium chart will create a Kubernetes headless\nservice named ``cilium-agent`` with the ``prometheus.io/scrape:'true'`` annotation set:\n\n.. code-block:: yaml\n\n        prometheus.io/scrape: true\n        prometheus.io/port: 9964\n\nThis additional headless service in addition to the other Cilium components is needed\nas each component can only have one Prometheus scrape and port annotation.\n\nPrometheus will pick up the Cilium and Envoy metrics automatically if the following\noption is set in the ``scrape_configs`` section:\n\n.. code-block:: yaml\n\n    scrape_configs:\n    - job_name: 'kubernetes-pods'\n      kubernetes_sd_configs:\n      - role: pod\n      relabel_configs:\n        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n          action: keep\n          regex: true\n        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n          action: replace\n          regex: ([^:]+)(?::\\d+)?;(\\d+)\n          replacement: ${1}:${2}\n          target_label: __address__\n\n.. _hubble_metrics:\n\nHubble Metrics\n==============\n\nWhile Cilium metrics allow you to monitor the state Cilium itself,\nHubble metrics on the other hand allow you to monitor the network behavior\nof your Cilium-managed Kubernetes pods with respect to connectivity and security.\n\nInstallation\n------------\n\nTo deploy Cilium with Hubble metrics enabled, you need to enable Hubble with\n``hubble.enabled=true`` and provide a set of Hubble metrics you want to\nenable via ``hubble.metrics.enabled``.\n\nSome of the metrics can also be configured with additional options.\nSee the :ref:`Hubble exported metrics<hubble_exported_metrics>`\nsection for the full list of available metrics and their options.\n\n.. parsed-literal::\n\n   helm install cilium |CHART_RELEASE| \\\\\n     --namespace kube-system \\\\\n     --set prometheus.enabled=true \\\\\n     --set operator.prometheus.enabled=true \\\\\n     --set hubble.enabled=true \\\\\n     --set hubble.metrics.enableOpenMetrics=true \\\\\n     --set hubble.metrics.enabled=\"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\\\\,source_namespace\\\\,source_workload\\\\,destination_ip\\\\,destination_namespace\\\\,destination_workload\\\\,traffic_direction}\"\n\nThe port of the Hubble metrics can be configured with the\n``hubble.metrics.port`` Helm value.\n\nFor details on enabling Hubble metrics with TLS see the\n:ref:`hubble_configure_metrics_tls` section of the documentation.\n\n.. Note::\n\n    L7 metrics such as HTTP, are only emitted for pods that enable\n    :ref:`Layer 7 Protocol Visibility <proxy_visibility>`.\n\nWhen deployed with a non-empty ``hubble.metrics.enabled`` Helm value, the\nCilium chart will create a Kubernetes headless service named ``hubble-metrics``\nwith the ``prometheus.io/scrape:'true'`` annotation set:\n\n.. code-block:: yaml\n\n        prometheus.io/scrape: true\n        prometheus.io/port: 9965\n\nSet the following options in the ``scrape_configs`` section of Prometheus to\nhave it scrape all Hubble metrics from the endpoints automatically:\n\n.. code-block:: yaml\n\n    scrape_configs:\n      - job_name: 'kubernetes-endpoints'\n        scrape_interval: 30s\n        kubernetes_sd_configs:\n          - role: endpoints\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n            action: replace\n            target_label: __address__\n            regex: (.+)(?::\\d+);(\\d+)\n            replacement: $1:$2\n\n.. _hubble_open_metrics:\n\nOpenMetrics\n-----------\n\nAdditionally, you can opt-in to `OpenMetrics <https://openmetrics.io>`_ by\nsetting ``hubble.metrics.enableOpenMetrics=true``.\nEnabling OpenMetrics configures the Hubble metrics endpoint to support exporting\nmetrics in OpenMetrics format when explicitly requested by clients.\n\nUsing OpenMetrics supports additional functionality such as Exemplars, which\nenables associating metrics with traces by embedding trace IDs into the\nexported metrics.\n\nPrometheus needs to be configured to take advantage of OpenMetrics and will\nonly scrape exemplars when the `exemplars storage feature is enabled\n<https://prometheus.io/docs/prometheus/latest/feature_flags/#exemplars-storage>`_.\n\nOpenMetrics imposes a few additional requirements on metrics names and labels,\nso this functionality is currently opt-in, though we believe all of the Hubble\nmetrics conform to the OpenMetrics requirements.\n\n\n.. _clustermesh_apiserver_metrics:\n\nCluster Mesh API Server Metrics\n===============================\n\nCluster Mesh API Server metrics provide insights into the state of the\n``clustermesh-apiserver`` process, the ``kvstoremesh`` process (if enabled),\nand the sidecar etcd instance.\nCluster Mesh API Server metrics are exported under the ``cilium_clustermesh_apiserver_``\nPrometheus namespace. KVStoreMesh metrics are exported under the ``cilium_kvstoremesh_``\nPrometheus namespace. Etcd metrics are exported under the ``etcd_`` Prometheus namespace.\n\n\nInstallation\n------------\n\nYou can enable the metrics for different Cluster Mesh API Server components by\nsetting the following values:\n\n* clustermesh-apiserver: ``clustermesh.apiserver.metrics.enabled=true``\n* kvstoremesh: ``clustermesh.apiserver.metrics.kvstoremesh.enabled=true``\n* sidecar etcd instance: ``clustermesh.apiserver.metrics.etcd.enabled=true``\n\n.. parsed-literal::\n\n   helm install cilium |CHART_RELEASE| \\\\\n     --namespace kube-system \\\\\n     --set clustermesh.useAPIServer=true \\\\\n     --set clustermesh.apiserver.metrics.enabled=true \\\\\n     --set clustermesh.apiserver.metrics.kvstoremesh.enabled=true \\\\\n     --set clustermesh.apiserver.metrics.etcd.enabled=true\n\nYou can figure the ports by way of ``clustermesh.apiserver.metrics.port``,\n``clustermesh.apiserver.metrics.kvstoremesh.port`` and\n``clustermesh.apiserver.metrics.etcd.port`` respectively.\n\nYou can automatically create a\n`Prometheus Operator <https://github.com/prometheus-operator/prometheus-operator>`_\n``ServiceMonitor`` by setting ``clustermesh.apiserver.metrics.serviceMonitor.enabled=true``.\n\nExample Prometheus & Grafana Deployment\n=======================================\n\nIf you don't have an existing Prometheus and Grafana stack running, you can\ndeploy a stack with:\n\n.. parsed-literal::\n\n    kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/addons/prometheus/monitoring-example.yaml\n\nIt will run Prometheus and Grafana in the ``cilium-monitoring`` namespace. If\nyou have either enabled Cilium or Hubble metrics, they will automatically\nbe scraped by Prometheus. You can then expose Grafana to access it via your browser.\n\n.. code-block:: shell-session\n\n    kubectl -n cilium-monitoring port-forward service/grafana --address 0.0.0.0 --address :: 3000:3000\n\nOpen your browser and access http://localhost:3000/\n\nMetrics Reference\n=================\n\ncilium-agent\n------------\n\nConfiguration\n^^^^^^^^^^^^^\n\nTo expose any metrics, invoke ``cilium-agent`` with the\n``--prometheus-serve-addr`` option. This option takes a ``IP:Port`` pair but\npassing an empty IP (e.g. ``:9962``) will bind the server to all available\ninterfaces (there is usually only one in a container).\n\nTo customize ``cilium-agent`` metrics, configure the ``--metrics`` option with\n``\"+metric_a -metric_b -metric_c\"``, where ``+/-`` means to enable/disable\nthe metric. For example, for really large clusters, users may consider to\ndisable the following two metrics as they generate too much data:\n\n- ``cilium_node_connectivity_status``\n- ``cilium_node_connectivity_latency_seconds``\n\nYou can then configure the agent with ``--metrics=\"-cilium_node_connectivity_status -cilium_node_connectivity_latency_seconds\"``.\n\nFeature Metrics\n~~~~~~~~~~~~~~~\n\nCilium Feature Metrics are exported under the ``cilium_feature`` Prometheus\nnamespace.\n\nThe following tables categorize feature metrics into four groups:\n\n- **Advanced Connectivity and Load Balancing** (:ref:`cilium-feature-adv-connect-and-lb`)\n\n  This category includes features related to advanced networking and load\n  balancing capabilities, such as Bandwidth Manager, BGP, Envoy Proxy, and\n  Cluster Mesh.\n\n- **Control Plane** (:ref:`cilium-feature-controlplane`)\n\n  These metrics track control plane configurations, including identity\n  allocation modes and IP address management (IPAM).\n\n- **Datapath** (:ref:`cilium-feature-datapath`)\n\n  Metrics in this group monitor datapath configurations, such as Internet\n  protocol modes, chaining modes, and network modes.\n\n- **Network Policies** (:ref:`cilium-feature-network-policies`)\n\n  This group encompasses metrics related to policy enforcement, including\n  Cilium Network Policies, Host Firewall, DNS policies, and Mutual Auth.\n\nFor example, to check if the Bandwidth Manager is enabled on a Cilium agent,\nobserve the metric ``cilium_feature_adv_connect_and_lb_bandwidth_manager_enabled``.\nAll metrics follow the format ``cilium_feature`` + group name + metric name.\nA value of ``0`` indicates that the feature is disabled, while ``1`` indicates it\nis enabled.\n\n.. note::\n\n   For metrics of type \"counter\", the agent has processed the associated object\n   (e.g., a network policy) but might not be actively enforcing it. These\n   metrics serve to observe if the object has been received and processed, but\n   not necessarily enforced by the agent.\n\n.. include:: feature-metrics-agent.txt\n\nExported Metrics\n^^^^^^^^^^^^^^^^\n\nEndpoint\n~~~~~~~~\n\n============================================ ================================================== ========== ========================================================\nName                                         Labels                                             Default    Description\n============================================ ================================================== ========== ========================================================\n``endpoint``                                                                                    Enabled    Number of endpoints managed by this agent\n``endpoint_max_ifindex``                                                                        Disabled   Maximum interface index observed for existing endpoints\n``endpoint_regenerations_total``             ``outcome``                                        Enabled    Count of all endpoint regenerations that have completed\n``endpoint_regeneration_time_stats_seconds`` ``scope``                                          Enabled    Endpoint regeneration time stats\n``endpoint_state``                           ``state``                                          Enabled    Count of all endpoints\n============================================ ================================================== ========== ========================================================\n\nThe default enabled status of ``endpoint_max_ifindex`` is dynamic. On earlier\nkernels (typically with version lower than 5.10), Cilium must store the\ninterface index for each endpoint in the conntrack map, which reserves 16 bits\nfor this field. If Cilium is running on such a kernel, this metric will be\nenabled by default. It can be used to implement an alert if the ifindex is\napproaching the limit of 65535. This may be the case in instances of\nsignificant Endpoint churn.\n\nServices\n~~~~~~~~\n\n========================================== ================================================== ========== ========================================================\nName                                       Labels                                             Default    Description\n========================================== ================================================== ========== ========================================================\n``services_events_total``                                                                     Enabled    Number of services events labeled by action type\n``service_implementation_delay``           ``action``                                         Enabled    Duration in seconds to propagate the data plane programming of a service, its network and endpoints from the time the service or the service pod was changed excluding the event queue latency\n========================================== ================================================== ========== ========================================================\n\nCluster health\n~~~~~~~~~~~~~~\n\n========================================== ================================================== ========== ========================================================\nName                                       Labels                                             Default    Description\n========================================== ================================================== ========== ========================================================\n``unreachable_nodes``                                                                         Enabled    Number of nodes that cannot be reached\n``unreachable_health_endpoints``                                                              Enabled    Number of health endpoints that cannot be reached\n========================================== ================================================== ========== ========================================================\n\nNode Connectivity\n~~~~~~~~~~~~~~~~~\n\n============================================= ====================================================================================================================================================================== ========== ==================================================================================================================================================================================================================\nName                                          Labels                                                                                                                                                                 Default    Description\n============================================= ====================================================================================================================================================================== ========== ==================================================================================================================================================================================================================\n``node_health_connectivity_status``           ``source_cluster``, ``source_node_name``, ``type``, ``status``                                                                                                         Enabled    Number of endpoints with last observed status of both ICMP and HTTP connectivity between the current Cilium agent and other Cilium nodes\n``node_health_connectivity_latency_seconds``  ``source_cluster``, ``source_node_name``, ``type``, ``address_type``, ``protocol``                                                                                     Enabled    Histogram of the last observed latency between the current Cilium agent and other Cilium nodes in seconds\n============================================= ====================================================================================================================================================================== ========== ==================================================================================================================================================================================================================\n\nClustermesh\n~~~~~~~~~~~\n\n=============================================== ============================================================ ========== =================================================================\nName                                            Labels                                                       Default    Description\n=============================================== ============================================================ ========== =================================================================\n``clustermesh_global_services``                 ``source_cluster``, ``source_node_name``                     Enabled    The total number of global services in the cluster mesh\n``clustermesh_remote_clusters``                 ``source_cluster``, ``source_node_name``                     Enabled    The total number of remote clusters meshed with the local cluster\n``clustermesh_remote_cluster_failures``         ``source_cluster``, ``source_node_name``, ``target_cluster`` Enabled    The total number of failures related to the remote cluster\n``clustermesh_remote_cluster_nodes``            ``source_cluster``, ``source_node_name``, ``target_cluster`` Enabled    The total number of nodes in the remote cluster\n``clustermesh_remote_cluster_last_failure_ts``  ``source_cluster``, ``source_node_name``, ``target_cluster`` Enabled    The timestamp of the last failure of the remote cluster\n``clustermesh_remote_cluster_readiness_status`` ``source_cluster``, ``source_node_name``, ``target_cluster`` Enabled    The readiness status of the remote cluster\n=============================================== ============================================================ ========== =================================================================\n\nDatapath\n~~~~~~~~\n\n============================================= ================================================== ========== ========================================================\nName                                          Labels                                             Default    Description\n============================================= ================================================== ========== ========================================================\n``datapath_conntrack_dump_resets_total``      ``area``, ``name``, ``family``                     Enabled    Number of conntrack dump resets. Happens when a BPF entry gets removed while dumping the map is in progress.\n``datapath_conntrack_gc_runs_total``          ``status``                                         Enabled    Number of times that the conntrack garbage collector process was run\n``datapath_conntrack_gc_key_fallbacks_total``                                                    Enabled    The number of alive and deleted conntrack entries at the end of a garbage collector run labeled by datapath family\n``datapath_conntrack_gc_entries``             ``family``                                         Enabled    The number of alive and deleted conntrack entries at the end of a garbage collector run\n``datapath_conntrack_gc_duration_seconds``    ``status``                                         Enabled    Duration in seconds of the garbage collector process\n============================================= ================================================== ========== ========================================================\n\nIPsec\n~~~~~\n\n============================================= ================================================== ========== ===========================================================\nName                                          Labels                                             Default    Description\n============================================= ================================================== ========== ===========================================================\n``ipsec_xfrm_error``                          ``error``, ``type``                                Enabled    Total number of xfrm errors\n``ipsec_keys``                                                                                   Enabled    Number of keys in use\n``ipsec_xfrm_states``                         ``direction``                                      Enabled    Number of XFRM states\n``ipsec_xfrm_policies``                       ``direction``                                      Enabled    Number of XFRM policies\n============================================= ================================================== ========== ===========================================================\n\neBPF\n~~~~\n\n========================================== ===================================================================== ========== ========================================================\nName                                       Labels                                                                Default    Description\n========================================== ===================================================================== ========== ========================================================\n``bpf_syscall_duration_seconds``           ``operation``, ``outcome``                                            Disabled   Duration of eBPF system call performed\n``bpf_map_ops_total``                      ``mapName`` (deprecated), ``map_name``, ``operation``, ``outcome``    Enabled    Number of eBPF map operations performed. ``mapName`` is deprecated and will be removed in 1.10. Use ``map_name`` instead.\n``bpf_map_pressure``                       ``map_name``                                                          Enabled    Map pressure is defined as a ratio of the required map size compared to its configured size. Values < 1.0 indicate the map's utilization, while values >= 1.0 indicate that the map is full. Policy map pressure metrics are emitted only when map utilization exceeds the threshold set by ``policyMapPressureMetricsThreshold`` helm value, which defaults to 0.1 (10% full).\n``bpf_map_capacity``                       ``map_group``                                                         Enabled    Maximum size of eBPF maps by group of maps (type of map that have the same max capacity size). Map types with size of 65536 are not emitted, missing map types can be assumed to be 65536.\n``bpf_maps_virtual_memory_max_bytes``                                                                            Enabled    Max memory used by eBPF maps installed in the system\n``bpf_progs_virtual_memory_max_bytes``                                                                           Enabled    Max memory used by eBPF programs installed in the system\n``bpf_ratelimit_dropped_total``            ``usage``                                                             Enabled    Total drops resulting from BPF ratelimiter, tagged by source of drop\n========================================== ===================================================================== ========== ========================================================\n\nBoth ``bpf_maps_virtual_memory_max_bytes`` and ``bpf_progs_virtual_memory_max_bytes``\nare currently reporting the system-wide memory usage of eBPF that is directly\nand not directly managed by Cilium. This might change in the future and only\nreport the eBPF memory usage directly managed by Cilium.\n\nDrops/Forwards (L3/L4)\n~~~~~~~~~~~~~~~~~~~~~~\n\n========================================== ================================================== ========== ========================================================\nName                                       Labels                                             Default    Description\n========================================== ================================================== ========== ========================================================\n``drop_count_total``                       ``reason``, ``direction``                          Enabled    Total dropped packets\n``drop_bytes_total``                       ``reason``, ``direction``                          Enabled    Total dropped bytes\n``forward_count_total``                    ``direction``                                      Enabled    Total forwarded packets\n``forward_bytes_total``                    ``direction``                                      Enabled    Total forwarded bytes\n========================================== ================================================== ========== ========================================================\n\nPolicy\n~~~~~~\n\n========================================== ================================================== ========== ========================================================\nName                                       Labels                                             Default    Description\n========================================== ================================================== ========== ========================================================\n``policy``                                                                                    Enabled    Number of policies currently loaded\n``policy_regeneration_total``                                                                 Enabled    Deprecated, will be removed in Cilium 1.17 - use ``endpoint_regenerations_total`` instead. Total number of policies regenerated successfully\n``policy_regeneration_time_stats_seconds`` ``scope``                                          Enabled    Deprecated, will be removed in Cilium 1.17 - use ``endpoint_regeneration_time_stats_seconds`` instead. Policy regeneration time stats labeled by the scope\n``policy_max_revision``                                                                       Enabled    Highest policy revision number in the agent\n``policy_change_total``                                                                       Enabled    Number of policy changes by outcome\n``policy_endpoint_enforcement_status``                                                        Enabled    Number of endpoints labeled by policy enforcement status\n``policy_implementation_delay``            ``source``                                         Enabled    Time in seconds between a policy change and it being fully deployed into the datapath, labeled by the policy's source\n``policy_selector_match_count_max``        ``class``                                          Enabled    The maximum number of identities selected by a network policy selector\n``policy_incremental_update_duration``     ``scope``                                          Enabled    The time taken for newly learned identities to be added to the policy system, including BPF policy maps and L7 proxies.\n========================================== ================================================== ========== ========================================================\n\nPolicy L7 (HTTP/Kafka/FQDN)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``proxy_redirects``                      ``protocol``                                       Enabled    Number of redirects installed for endpoints\n``proxy_upstream_reply_seconds``         ``error``, ``protocol_l7``, ``scope``              Enabled    Seconds waited for upstream server to reply to a request\n``proxy_datapath_update_timeout_total``                                                     Disabled   Number of total datapath update timeouts due to FQDN IP updates\n``policy_l7_total``                      ``rule``, ``proxy_type``                           Enabled    Number of total L7 requests/responses\n======================================== ================================================== ========== ========================================================\n\nIdentity\n~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``identity``                             ``type``                                           Enabled    Number of identities currently allocated\n``identity_label_sources``               ``source``                                         Enabled    Number of identities which contain at least one label from the given label source\n``identity_gc_entries``                  ``identity_type``                                  Enabled    Number of alive and deleted identities at the end of a garbage collector run\n``identity_gc_runs``                     ``outcome``, ``identity_type``                     Enabled    Number of times identity garbage collector has run\n``identity_gc_latency``                  ``outcome``, ``identity_type``                     Enabled    Duration of the last successful identity GC run\n``ipcache_errors_total``                 ``type``, ``error``                                Enabled    Number of errors interacting with the ipcache\n``ipcache_events_total``                 ``type``                                           Enabled    Number of events interacting with the ipcache\n``identity_cache_timer_duration``        ``name``                                           Enabled    Seconds required to execute periodic policy processes. ``name=\"id-alloc-update-policy-maps\"`` is the time taken to apply incremental updates to the BPF policy maps.\n``identity_cache_timer_trigger_latency`` ``name``                                           Enabled    Seconds spent waiting for a previous process to finish before starting the next round. ``name=\"id-alloc-update-policy-maps\"`` is the time waiting before applying incremental updates to the BPF policy maps.\n``identity_cache_timer_trigger_folds``   ``name``                                           Enabled    Number of timer triggers that were coalesced in to one execution. ``name=\"id-alloc-update-policy-maps\"`` applies the incremental updates to the BPF policy maps.\n======================================== ================================================== ========== ========================================================\n\nEvents external to Cilium\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``event_ts``                             ``source``                                         Enabled    Last timestamp when Cilium received an event from a control plane source, per resource and per action\n``k8s_event_lag_seconds``                ``source``                                         Disabled   Lag for Kubernetes events - computed value between receiving a CNI ADD event from kubelet and a Pod event received from kube-api-server\n======================================== ================================================== ========== ========================================================\n\nControllers\n~~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``controllers_runs_total``               ``status``                                         Enabled    Number of times that a controller process was run\n``controllers_runs_duration_seconds``    ``status``                                         Enabled    Duration in seconds of the controller process\n``controllers_group_runs_total``         ``status``, ``group_name``                         Enabled    Number of times that a controller process was run, labeled by controller group name\n``controllers_failing``                                                                     Enabled    Number of failing controllers\n======================================== ================================================== ========== ========================================================\n\nThe ``controllers_group_runs_total`` metric reports the success and failure\ncount of each controller within the system, labeled by controller group name\nand completion status. Due to the large number of controllers, enabling this\nmetric is on a per-controller basis. This is configured using an allow-list\nwhich is passed as the ``controller-group-metrics`` configuration flag,\nor the ``prometheus.controllerGroupMetrics`` helm value. The current\nrecommended default set of group names can be found in the values file of\nthe Cilium Helm chart. The special names \"all\" and \"none\" are supported.\n\nSubProcess\n~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``subprocess_start_total``               ``subsystem``                                      Enabled    Number of times that Cilium has started a subprocess\n======================================== ================================================== ========== ========================================================\n\nKubernetes\n~~~~~~~~~~\n\n=========================================== ================================================== ========== ========================================================\nName                                        Labels                                             Default    Description\n=========================================== ================================================== ========== ========================================================\n``kubernetes_events_received_total``        ``scope``, ``action``, ``validity``, ``equal``     Enabled    Number of Kubernetes events received\n``kubernetes_events_total``                 ``scope``, ``action``, ``outcome``                 Enabled    Number of Kubernetes events processed\n``k8s_cnp_status_completion_seconds``       ``attempts``, ``outcome``                          Enabled    Duration in seconds in how long it took to complete a CNP status update\n``k8s_terminating_endpoints_events_total``                                                     Enabled    Number of terminating endpoint events received from Kubernetes\n=========================================== ================================================== ========== ========================================================\n\nKubernetes Rest Client\n~~~~~~~~~~~~~~~~~~~~~~\n\n============================================= ============================================= ========== ===========================================================\nName                                          Labels                                        Default    Description\n============================================= ============================================= ========== ===========================================================\n``k8s_client_api_latency_time_seconds``       ``path``, ``method``                          Enabled    Duration of processed API calls labeled by path and method\n``k8s_client_rate_limiter_duration_seconds``                                                Enabled    Kubernetes client rate limiter latency in seconds.\n``k8s_client_api_calls_total``                ``host``, ``method``, ``return_code``         Enabled    Number of API calls made to kube-apiserver labeled by host, method and return code\n============================================= ============================================= ========== ===========================================================\n\nKubernetes workqueue\n~~~~~~~~~~~~~~~~~~~~\n\n==================================================== ============================================= ========== ===========================================================\nName                                                 Labels                                        Default    Description\n==================================================== ============================================= ========== ===========================================================\n``k8s_workqueue_depth``                              ``name``                                      Enabled    Current depth of workqueue\n``k8s_workqueue_adds_total``                         ``name``                                      Enabled    Total number of adds handled by workqueue\n``k8s_workqueue_queue_duration_seconds``             ``name``                                      Enabled    Duration in seconds an item stays in workqueue prior to request\n``k8s_workqueue_work_duration_seconds``              ``name``                                      Enabled    Duration in seconds to process an item from workqueue\n``k8s_workqueue_unfinished_work_seconds``            ``name``                                      Enabled    Duration in seconds of work in progress that hasn't been observed by work_duration. Large values indicate stuck threads. You can deduce the number of stuck threads by observing the rate at which this value increases.\n``k8s_workqueue_longest_running_processor_seconds``  ``name``                                      Enabled    Duration in seconds of the longest running processor for workqueue\n``k8s_workqueue_retries_total``                      ``name``                                      Enabled    Total number of retries handled by workqueue\n==================================================== ============================================= ========== ===========================================================\n\nIPAM\n~~~~\n\n======================================== ============================================ ========== ========================================================\nName                                     Labels                                       Default    Description\n======================================== ============================================ ========== ========================================================\n``ipam_capacity``                        ``family``                                   Enabled    Total number of IPs in the IPAM pool labeled by family\n``ipam_events_total``                                                                 Enabled    Number of IPAM events received labeled by action and datapath family type\n``ip_addresses``                         ``family``                                   Enabled    Number of allocated IP addresses\n======================================== ============================================ ========== ========================================================\n\nKVstore\n~~~~~~~\n\n======================================== ============================================ ========== ========================================================\nName                                     Labels                                       Default    Description\n======================================== ============================================ ========== ========================================================\n``kvstore_operations_duration_seconds``  ``action``, ``kind``, ``outcome``, ``scope`` Enabled    Duration of kvstore operation\n``kvstore_events_queue_seconds``         ``action``, ``scope``                        Enabled    Seconds waited before a received event was queued\n``kvstore_quorum_errors_total``          ``error``                                    Enabled    Number of quorum errors\n``kvstore_sync_errors_total``            ``scope``, ``source_cluster``                Enabled    Number of times synchronization to the kvstore failed\n``kvstore_sync_queue_size``              ``scope``, ``source_cluster``                Enabled    Number of elements queued for synchronization in the kvstore\n``kvstore_initial_sync_completed``       ``scope``, ``source_cluster``, ``action``    Enabled    Whether the initial synchronization from/to the kvstore has completed\n======================================== ============================================ ========== ========================================================\n\nAgent\n~~~~~\n\n================================ ================================ ========== ========================================================\nName                             Labels                           Default    Description\n================================ ================================ ========== ========================================================\n``agent_bootstrap_seconds``      ``scope``, ``outcome``           Enabled    Duration of various bootstrap phases\n``api_process_time_seconds``                                      Enabled    Processing time of all the API calls made to the cilium-agent, labeled by API method, API path and returned HTTP code.\n================================ ================================ ========== ========================================================\n\nFQDN\n~~~~\n\n================================== ================================ ============ ========================================================\nName                               Labels                           Default      Description\n================================== ================================ ============ ========================================================\n``fqdn_gc_deletions_total``                                         Enabled      Number of FQDNs that have been cleaned on FQDN garbage collector job\n``fqdn_active_names``              ``endpoint``                     Disabled     Number of domains inside the DNS cache that have not expired (by TTL), per endpoint\n``fqdn_active_ips``                ``endpoint``                     Disabled     Number of IPs inside the DNS cache associated with a domain that has not expired (by TTL), per endpoint\n``fqdn_alive_zombie_connections``  ``endpoint``                     Disabled     Number of IPs associated with domains that have expired (by TTL) yet still associated with an active connection (aka zombie), per endpoint\n``fqdn_selectors``                                                  Enabled      Number of registered ToFQDN selectors\n================================== ================================ ============ ========================================================\n\nJobs\n~~~~\n\n================================== ================================ ============ ========================================================\nName                               Labels                           Default      Description\n================================== ================================ ============ ========================================================\n``jobs_errors_total``              ``job``                          Enabled      Number of jobs runs that returned an error\n``jobs_one_shot_run_seconds``      ``job``                          Enabled      Histogram of one shot job run duration\n``jobs_timer_run_seconds``         ``job``                          Enabled      Histogram of timer job run duration\n``jobs_observer_run_seconds``      ``job``                          Enabled      Histogram of observer job run duration\n================================== ================================ ============ ========================================================\n\nCIDRGroups\n~~~~~~~~~~\n\n=================================================== ===================== =============================\nName                                                Labels                Default    Description\n=================================================== ===================== =============================\n``cidrgroups_referenced``                                                 Enabled    Number of CNPs and CCNPs referencing at least one CiliumCIDRGroup. CNPs with empty or non-existing CIDRGroupRefs are not considered\n``cidrgroup_translation_time_stats_seconds``                              Disabled   CIDRGroup translation time stats\n=================================================== ===================== =============================\n\n.. _metrics_api_rate_limiting:\n\nAPI Rate Limiting\n~~~~~~~~~~~~~~~~~\n\n============================================== ========================================== ========== ========================================================\nName                                           Labels                                     Default    Description\n============================================== ========================================== ========== ========================================================\n``api_limiter_adjustment_factor``              ``api_call``                               Enabled    Most recent adjustment factor for automatic adjustment\n``api_limiter_processed_requests_total``       ``api_call``, ``outcome``, ``return_code`` Enabled    Total number of API requests processed\n``api_limiter_processing_duration_seconds``    ``api_call``, ``value``                    Enabled    Mean and estimated processing duration in seconds\n``api_limiter_rate_limit``                     ``api_call``, ``value``                    Enabled    Current rate limiting configuration (limit and burst)\n``api_limiter_requests_in_flight``             ``api_call``  ``value``                    Enabled    Current and maximum allowed number of requests in flight\n``api_limiter_wait_duration_seconds``          ``api_call``, ``value``                    Enabled    Mean, min, and max wait duration\n``api_limiter_wait_history_duration_seconds``  ``api_call``                               Disabled   Histogram of wait duration per API call processed\n============================================== ========================================== ========== ========================================================\n\n.. _metrics_bgp_control_plane:\n\nBGP Control Plane\n~~~~~~~~~~~~~~~~~\n\n================================== =============================================================== ======== ===================================================================\nName                               Labels                                                          Default  Description\n================================== =============================================================== ======== ===================================================================\n``session_state``                  ``vrouter``, ``neighbor``, ``neighbor_asn``                     Enabled  Current state of the BGP session with the peer, Up = 1 or Down = 0\n``advertised_routes``              ``vrouter``, ``neighbor``, ``neighbor_asn``, ``afi``, ``safi``  Enabled  Number of routes advertised to the peer\n``received_routes``                ``vrouter``, ``neighbor``, ``neighbor_asn``, ``afi``, ``safi``  Enabled  Number of routes received from the peer\n``reconcile_errors_total``         ``vrouter``                                                     Enabled  Number of reconciliation runs that returned an error\n``reconcile_run_duration_seconds`` ``vrouter``                                                     Enabled  Histogram of reconciliation run duration\n================================== =============================================================== ======== ===================================================================\n\nAll metrics are enabled only when the BGP Control Plane is enabled.\n\ncilium-operator\n---------------\n\nConfiguration\n^^^^^^^^^^^^^\n\n``cilium-operator`` can be configured to serve metrics by running with the\noption ``--enable-metrics``.  By default, the operator will expose metrics on\nport 9963, the port can be changed with the option\n``--operator-prometheus-serve-addr``.\n\nFeature Metrics\n~~~~~~~~~~~~~~~\n\nCilium Operator Feature Metrics are exported under the\n``cilium_operator_feature`` Prometheus namespace.\n\nThe following tables categorize feature metrics into the following groups:\n\n- **Advanced Connectivity and Load Balancing** (:ref:`cilium-operator-feature-adv-connect-and-lb`)\n\n  This category includes features related to advanced networking and load\n  balancing capabilities, such as Gateway API, Ingress Controller, LB IPAM,\n  Node IPAM and L7 Aware Traffic Management.\n\nFor example, to check if the Gateway API is enabled on a Cilium operator,\nobserve the metric ``cilium_operator_feature_adv_connect_and_lb_gateway_api_enabled``.\nAll metrics follows the format ``cilium_operator_feature`` + group name + metric name.\nA value of ``0`` indicates that the feature is disabled, while ``1`` indicates it\nis enabled.\n\n.. note::\n\n   For metrics of type \"counter,\" the operator has processed the associated object\n   (e.g., a network policy) but might not be actively enforcing it. These\n   metrics serve to observe if the object has been received and processed, but\n   not necessarily enforced by the operator.\n\n.. include:: feature-metrics-operator.txt\n\nExported Metrics\n^^^^^^^^^^^^^^^^\n\nAll metrics are exported under the ``cilium_operator_`` Prometheus namespace.\n\n.. _metrics_bgp_control_plane_operator:\n\nBGP Control Plane Operator\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n================================== ===================================== ======== ======================================================================\nName                               Labels                                Default  Description\n================================== ===================================== ======== ======================================================================\n``reconcile_errors_total``         ``resource_kind``, ``resource_name``  Enabled  Number of errors returned per BGP resource reconciliation\n``reconcile_run_duration_seconds``                                       Enabled  Histogram of reconciliation run duration\n================================== ===================================== ======== ======================================================================\n\nAll metrics are enabled only when the BGP Control Plane is enabled.\n\n.. _ipam_metrics:\n\nIPAM\n~~~~\n\n.. Note::\n\n    IPAM metrics are all ``Enabled`` only if using the AWS, Alibabacloud or Azure IPAM plugins.\n\n======================================== ================================================================= ========== ========================================================\nName                                     Labels                                                            Default    Description\n======================================== ================================================================= ========== ========================================================\n``ipam_ips``                             ``type``                                                          Enabled    Number of IPs allocated\n``ipam_ip_allocation_ops``               ``subnet_id``                                                     Enabled    Number of IP allocation operations.\n``ipam_ip_release_ops``                  ``subnet_id``                                                     Enabled    Number of IP release operations.\n``ipam_interface_creation_ops``          ``subnet_id``                                                     Enabled    Number of interfaces creation operations.\n``ipam_release_duration_seconds``        ``type``, ``status``, ``subnet_id``                               Enabled    Release ip or interface latency in seconds\n``ipam_allocation_duration_seconds``     ``type``, ``status``, ``subnet_id``                               Enabled    Allocation ip or interface latency in seconds\n``ipam_available_interfaces``                                                                              Enabled    Number of interfaces with addresses available\n``ipam_nodes``                           ``category``                                                      Enabled    Number of nodes by category { total | in-deficit | at-capacity }\n``ipam_resync_total``                                                                                      Enabled    Number of synchronization operations with external IPAM API\n``ipam_api_duration_seconds``            ``operation``, ``response_code``                                  Enabled    Duration of interactions with external IPAM API.\n``ipam_api_rate_limit_duration_seconds`` ``operation``                                                     Enabled    Duration of rate limiting while accessing external IPAM API\n``ipam_available_ips``                   ``target_node``                                                   Enabled    Number of available IPs on a node (taking into account plugin specific NIC/Address limits).\n``ipam_used_ips``                        ``target_node``                                                   Enabled    Number of currently used IPs on a node.\n``ipam_needed_ips``                      ``target_node``                                                   Enabled    Number of IPs needed to satisfy allocation on a node.\n======================================== ================================================================= ========== ========================================================\n\nLB-IPAM\n~~~~~~~\n\n======================================== ================================================================= ========== ========================================================\nName                                     Labels                                                            Default    Description\n======================================== ================================================================= ========== ========================================================\n``lbipam_conflicting_pools``                                                                               Enabled    Number of conflicting pools\n``lbipam_ips_available``                 ``pool``                                                          Enabled    Number of available IPs per pool\n``lbipam_ips_used``                      ``pool``                                                          Enabled    Number of used IPs per pool\n``lbipam_services_matching``                                                                               Enabled    Number of matching services\n``lbipam_services_unsatisfied``                                                                            Enabled    Number of services which did not get requested IPs\n======================================== ================================================================= ========== ========================================================\n\nControllers\n~~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``controllers_group_runs_total``         ``status``, ``group_name``                         Enabled    Number of times that a controller process was run, labeled by controller group name\n======================================== ================================================== ========== ========================================================\n\nThe ``controllers_group_runs_total`` metric reports the success and failure\ncount of each controller within the system, labeled by controller group name\nand completion status. Due to the large number of controllers, enabling this\nmetric is on a per-controller basis. This is configured using an allow-list\nwhich is passed as the ``controller-group-metrics`` configuration flag,\nor the ``prometheus.controllerGroupMetrics`` helm value. The current\nrecommended default set of group names can be found in the values file of\nthe Cilium Helm chart. The special names \"all\" and \"none\" are supported.\n\n.. _ces_metrics:\n\nCiliumEndpointSlices (CES)\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n============================================== ================================ ========================================================\nName                                           Labels                           Description\n============================================== ================================ ========================================================\n``number_of_ceps_per_ces``                                                      The number of CEPs batched in a CES\n``number_of_cep_changes_per_ces``              ``opcode``, ``failure_type``     The number of changed CEPs in each CES update\n``ces_sync_total``                             ``outcome``                      The number of completed CES syncs by outcome\n``ces_queueing_delay_seconds``                                                  CiliumEndpointSlice queueing delay in seconds\n============================================== ================================ ========================================================\n\nNote that the CES controller has multiple internal queues for handling CES updates.\nDetailed metrics which are emitted by these queues can be found in the\n:ref:`Internal WorkQueues <internal_workqueues_metrics>` section below.\n\nUnmanaged Pods\n~~~~~~~~~~~~~~\n\n============================================ ======= ========== ====================================================================\nName                                         Labels  Default    Description\n============================================ ======= ========== ====================================================================\n``unmanaged_pods``                                   Enabled    The total number of pods observed to be unmanaged by Cilium operator\n============================================ ======= ========== ====================================================================\n\n\"Double Write\" Identity Allocation Mode\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nWhen the \":ref:`Double Write <double_write_migration>`\" identity allocation mode is\nenabled, the following metrics are available:\n\n============================================ ======= ========== ============================================================\nName                                         Labels  Default    Description\n============================================ ======= ========== ============================================================\n``doublewrite_crd_identities``                       Enabled    The total number of CRD identities\n``doublewrite_kvstore_identities``                   Enabled    The total number of identities in the KVStore\n``doublewrite_crd_only_identities``                  Enabled    The number of CRD identities not present in the KVStore\n``doublewrite_kvstore_only_identities``              Enabled    The number of identities in the KVStore not present as a CRD\n============================================ ======= ========== ============================================================\n\n.. _identity_management_metrics:\n\nIdentity Management Mode\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n=========================================== =========================== =====================================================================================\nName                                        Labels                      Description\n=========================================== =========================== =====================================================================================\n``cid_controller_work_queue_event_count``   ``resource``, ``outcome``   Counts processed events by CID controller work queues\n``cid_controller_work_queue_latency``       ``resource``, ``phase``     Duration of CID controller work queues enqueuing and processing latencies in seconds\n=========================================== =========================== =====================================================================================\n\n.. _internal_workqueues_metrics:\n\nInternal WorkQueues\n~~~~~~~~~~~~~~~~~~~~\n\nThe Operator uses internal queues to manage the processing of various tasks.\nCurrently, only the Cilium Node Synchronizer queues and Cilium EndpointSlice Controller queues are reporting the metrics listed below.\n\n==================================================== ============================================= ========== ===========================================================\nName                                                 Labels                                        Default    Description\n==================================================== ============================================= ========== ===========================================================\n``workqueue_depth``                                  ``queue_name``                                 Enabled    Current depth of workqueue\n``workqueue_adds_total``                             ``queue_name``                                 Enabled    Total number of adds handled by workqueue\n``workqueue_queue_duration_seconds``                 ``queue_name``                                 Enabled    Duration in seconds an item stays in workqueue prior to request\n``workqueue_work_duration_seconds``                  ``queue_name``                                 Enabled    Duration in seconds to process an item from workqueue\n``workqueue_unfinished_work_seconds``                ``queue_name``                                 Enabled    Duration in seconds of work in progress that hasn't been observed by work_duration. Large values indicate stuck threads. You can deduce the number of stuck threads by observing the rate at which this value increases.\n``workqueue_longest_running_processor_seconds``      ``queue_name``                                 Enabled    Duration in seconds of the longest running processor for workqueue\n``workqueue_retries_total``                          ``queue_name``                                 Enabled    Total number of retries handled by workqueue\n==================================================== ============================================= ========== ===========================================================\n\nMCS-API\n~~~~~~~\n\n==================================== ============================================================ ========== ===========================================================\nName                                                 Labels                                                    Default     Description\n==================================== ============================================================ ========== ===========================================================\n``serviceexport_info``               ``serviceexport``, ``namespace``                             Enabled    Information about ServiceExport in the local cluster\n``serviceexport_status_condition``   ``serviceexport``, ``namespace``, ``condition``, ``status``  Enabled    Status Condition of ServiceExport in the local cluster\n``serviceimport_info``               ``serviceimport``, ``namespace``                             Enabled    Information about ServiceImport in the local cluster\n==================================== ============================================================ ========== ===========================================================\n\n\nHubble\n------\n\nConfiguration\n^^^^^^^^^^^^^\n\nHubble metrics are served by a Hubble instance running inside ``cilium-agent``.\nThe command-line options to configure them are ``--enable-hubble``,\n``--hubble-metrics-server``, and ``--hubble-metrics``.\n``--hubble-metrics-server`` takes an ``IP:Port`` pair, but\npassing an empty IP (e.g. ``:9965``) will bind the server to all available\ninterfaces. ``--hubble-metrics`` takes a space-separated list of metrics.\nIt's also possible to configure Hubble metrics to listen with TLS and\noptionally use mTLS for authentication. For details see :ref:`hubble_configure_metrics_tls`.\n\nSome metrics can take additional semicolon-separated options per metric, e.g.\n``--hubble-metrics=\"dns:query;ignoreAAAA http:destinationContext=workload-name\"``\nwill enable the ``dns`` metric with the ``query`` and ``ignoreAAAA`` options,\nand the ``http`` metric with the ``destinationContext=workload-name`` option.\n\n.. _hubble_context_options:\n\nContext Options\n^^^^^^^^^^^^^^^\n\nHubble metrics support configuration via context options.\nSupported context options for all metrics:\n\n- ``sourceContext`` - Configures the ``source`` label on metrics for both egress and ingress traffic.\n- ``sourceEgressContext`` - Configures the ``source`` label on metrics for egress traffic (takes precedence over ``sourceContext``).\n- ``sourceIngressContext`` - Configures the ``source`` label on metrics for ingress traffic (takes precedence over ``sourceContext``).\n- ``destinationContext`` - Configures the ``destination`` label on metrics for both egress and ingress traffic.\n- ``destinationEgressContext`` - Configures the ``destination`` label on metrics for egress traffic (takes precedence over ``destinationContext``).\n- ``destinationIngressContext`` - Configures the ``destination`` label on metrics for ingress traffic (takes precedence over ``destinationContext``).\n- ``labelsContext`` - Configures a list of labels to be enabled on metrics.\n\nThere are also some context options that are specific to certain metrics.\nSee the documentation for the individual metrics to see what options are available for each.\n\nSee below for details on each of the different context options.\n\nMost Hubble metrics can be configured to add the source and/or destination\ncontext as a label using the ``sourceContext`` and ``destinationContext``\noptions. The possible values are:\n\n===================== ===================================================================================\nOption Value          Description\n===================== ===================================================================================\n``identity``          All Cilium security identity labels\n``namespace``         Kubernetes namespace name\n``pod``               Kubernetes pod name and namespace name in the form of ``namespace/pod``.\n``pod-name``          Kubernetes pod name.\n``dns``               All known DNS names of the source or destination (comma-separated)\n``ip``                The IPv4 or IPv6 address\n``reserved-identity`` Reserved identity label.\n``workload``          Kubernetes pod's workload name and namespace in the form of ``namespace/workload-name``.\n``workload-name``     Kubernetes pod's workload name (workloads are: Deployment, Statefulset, Daemonset, ReplicationController, CronJob, Job, DeploymentConfig (OpenShift), etc).\n``app``               Kubernetes pod's app name, derived from pod labels (``app.kubernetes.io/name``, ``k8s-app``, or ``app``).\n===================== ===================================================================================\n\nWhen specifying the source and/or destination context, multiple contexts can be\nspecified by separating them via the ``|`` symbol.\nWhen multiple are specified, then the first non-empty value is added to the\nmetric as a label. For example, a metric configuration of\n``flow:destinationContext=dns|ip`` will first try to use the DNS name of the\ntarget for the label. If no DNS name is known for the target, it will fall back\nand use the IP address of the target instead.\n\n.. note::\n\n   There are 3 cases in which the identity label list contains multiple reserved labels:\n\n   1. ``reserved:kube-apiserver`` and ``reserved:host``\n   2. ``reserved:kube-apiserver`` and ``reserved:remote-node``\n   3. ``reserved:kube-apiserver`` and ``reserved:world``\n\n   In all of these 3 cases, ``reserved-identity`` context returns ``reserved:kube-apiserver``.\n\nHubble metrics can also be configured with a ``labelsContext`` which allows providing a list of labels\nthat should be added to the metric. Unlike ``sourceContext`` and ``destinationContext``, instead\nof different values being put into the same metric label, the ``labelsContext`` puts them into different label values.\n\n============================== ===============================================================================\nOption Value                   Description\n============================== ===============================================================================\n``source_ip``                  The source IP of the flow.\n``source_namespace``           The namespace of the pod if the flow source is from a Kubernetes pod.\n``source_pod``                 The pod name if the flow source is from a Kubernetes pod.\n``source_workload``            The name of the source pod's workload (Deployment, Statefulset, Daemonset, ReplicationController, CronJob, Job, DeploymentConfig (OpenShift)).\n``source_workload_kind``       The kind of the source pod's workload, for example, Deployment, Statefulset, Daemonset, ReplicationController, CronJob, Job, DeploymentConfig (OpenShift).\n``source_app``                 The app name of the source pod, derived from pod labels (``app.kubernetes.io/name``, ``k8s-app``, or ``app``).\n``destination_ip``             The destination IP of the flow.\n``destination_namespace``      The namespace of the pod if the flow destination is from a Kubernetes pod.\n``destination_pod``            The pod name if the flow destination is from a Kubernetes pod.\n``destination_workload``       The name of the destination pod's workload (Deployment, Statefulset, Daemonset, ReplicationController, CronJob, Job, DeploymentConfig (OpenShift)).\n``destination_workload_kind``  The kind of the destination pod's workload, for example, Deployment, Statefulset, Daemonset, ReplicationController, CronJob, Job, DeploymentConfig (OpenShift).\n``destination_app``            The app name of the source pod, derived from pod labels (``app.kubernetes.io/name``, ``k8s-app``, or ``app``).\n``traffic_direction``          Identifies the traffic direction of the flow. Possible values are ``ingress``, ``egress`` and ``unknown``.\n============================== ===============================================================================\n\nWhen specifying the flow context, multiple values can be specified by separating them via the ``,`` symbol.\nAll labels listed are included in the metric, even if empty. For example, a metric configuration of\n``http:labelsContext=source_namespace,source_pod`` will add the ``source_namespace`` and ``source_pod``\nlabels to all Hubble HTTP metrics.\n\n.. note::\n\n    To limit metrics cardinality hubble will remove data series bound to specific pod after one minute from pod deletion.\n    Metric is considered to be bound to a specific pod when at least one of the following conditions is met:\n\n    * ``sourceContext`` is set to ``pod`` and metric series has ``source`` label matching ``<pod_namespace>/<pod_name>``\n    * ``destinationContext`` is set to ``pod`` and metric series has ``destination`` label matching ``<pod_namespace>/<pod_name>``\n    * ``labelsContext`` contains both ``source_namespace`` and ``source_pod`` and metric series labels match namespace and name of deleted pod\n    * ``labelsContext`` contains both ``destination_namespace`` and ``destination_pod`` and metric series labels match namespace and name of deleted pod\n\n.. _hubble_exported_metrics:\n\nExported Metrics\n^^^^^^^^^^^^^^^^\n\nHubble metrics are exported under the ``hubble_`` Prometheus namespace.\n\nlost events\n~~~~~~~~~~~\n\nThis metric, unlike other ones, is not directly tied to network flows. It's enabled if any of the other metrics is enabled.\n\n================================ ======================================== ========== ==================================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ==================================================\n``lost_events_total``            ``source``                               Enabled    Number of lost events\n================================ ======================================== ========== ==================================================\n\nLabels\n\"\"\"\"\"\"\n\n- ``source`` identifies the source of lost events, one of:\n   - ``perf_event_ring_buffer``\n   - ``observer_events_queue``\n   - ``hubble_ring_buffer``\n\n\n``dns``\n~~~~~~~\n\n================================ ======================================== ========== ===================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ===================================\n``dns_queries_total``            ``rcode``, ``qtypes``, ``ips_returned``  Disabled   Number of DNS queries observed\n``dns_responses_total``          ``rcode``, ``qtypes``, ``ips_returned``  Disabled   Number of DNS responses observed\n``dns_response_types_total``     ``type``, ``qtypes``                     Disabled   Number of DNS response types\n================================ ======================================== ========== ===================================\n\nOptions\n\"\"\"\"\"\"\"\n\n============== ============= ====================================================================================\nOption Key     Option Value  Description\n============== ============= ====================================================================================\n``query``      N/A           Include the query as label \"query\"\n``ignoreAAAA`` N/A           Ignore any AAAA requests/responses\n============== ============= ====================================================================================\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n\n``drop``\n~~~~~~~~\n\n================================ ======================================== ========== ===================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ===================================\n``drop_total``                   ``reason``, ``protocol``                 Disabled   Number of drops\n================================ ======================================== ========== ===================================\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``flow``\n~~~~~~~~\n\n================================ ======================================== ========== ===================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ===================================\n``flows_processed_total``        ``type``, ``subtype``, ``verdict``       Disabled   Total number of flows processed\n================================ ======================================== ========== ===================================\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``flows-to-world``\n~~~~~~~~~~~~~~~~~~\n\nThis metric counts all non-reply flows containing the ``reserved:world`` label in their\ndestination identity. By default, dropped flows are counted if and only if the drop reason\nis ``Policy denied``. Set ``any-drop`` option to count all dropped flows.\n\n================================ ======================================== ========== ============================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ============================================\n``flows_to_world_total``         ``protocol``, ``verdict``                Disabled   Total number of flows to ``reserved:world``.\n================================ ======================================== ========== ============================================\n\nOptions\n\"\"\"\"\"\"\"\n\n============== ============= ======================================================\nOption Key     Option Value  Description\n============== ============= ======================================================\n``any-drop``   N/A           Count any dropped flows regardless of the drop reason.\n``port``       N/A           Include the destination port as label ``port``.\n``syn-only``   N/A           Only count non-reply SYNs for TCP flows.\n============== ============= ======================================================\n\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``http``\n~~~~~~~~\n\nDeprecated, use ``httpV2`` instead.\nThese metrics can not be enabled at the same time as ``httpV2``.\n\n================================= ======================================= ========== ==============================================\nName                              Labels                                  Default    Description\n================================= ======================================= ========== ==============================================\n``http_requests_total``           ``method``, ``protocol``, ``reporter``  Disabled   Count of HTTP requests\n``http_responses_total``          ``method``, ``status``, ``reporter``    Disabled   Count of HTTP responses\n``http_request_duration_seconds`` ``method``, ``reporter``                Disabled   Histogram of HTTP request duration in seconds\n================================= ======================================= ========== ==============================================\n\nLabels\n\"\"\"\"\"\"\n\n- ``method`` is the HTTP method of the request/response.\n- ``protocol`` is the HTTP protocol of the request, (For example: ``HTTP/1.1``, ``HTTP/2``).\n- ``status`` is the HTTP status code of the response.\n- ``reporter`` identifies the origin of the request/response. It is set to ``client`` if it originated from the client, ``server`` if it originated from the server, or ``unknown`` if its origin is unknown.\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``httpV2``\n~~~~~~~~~~\n\n``httpV2`` is an updated version of the existing ``http`` metrics.\nThese metrics can not be enabled at the same time as ``http``.\n\nThe main difference is that ``http_requests_total`` and\n``http_responses_total`` have been consolidated, and use the response flow\ndata.\n\nAdditionally, the ``http_request_duration_seconds`` metric source/destination\nrelated labels now are from the perspective of the request. In the ``http``\nmetrics, the source/destination were swapped, because the metric uses the\nresponse flow data, where the source/destination are swapped, but in ``httpV2``\nwe correctly account for this.\n\n================================= =================================================== ========== ==============================================\nName                              Labels                                              Default    Description\n================================= =================================================== ========== ==============================================\n``http_requests_total``           ``method``, ``protocol``, ``status``, ``reporter``  Disabled   Count of HTTP requests\n``http_request_duration_seconds`` ``method``, ``reporter``                            Disabled   Histogram of HTTP request duration in seconds\n================================= =================================================== ========== ==============================================\n\nLabels\n\"\"\"\"\"\"\n\n- ``method`` is the HTTP method of the request/response.\n- ``protocol`` is the HTTP protocol of the request, (For example: ``HTTP/1.1``, ``HTTP/2``).\n- ``status`` is the HTTP status code of the response.\n- ``reporter`` identifies the origin of the request/response. It is set to ``client`` if it originated from the client, ``server`` if it originated from the server, or ``unknown`` if its origin is unknown.\n\nOptions\n\"\"\"\"\"\"\"\n\n============== ============== =============================================================================================================\nOption Key     Option Value   Description\n============== ============== =============================================================================================================\n``exemplars``  ``true``       Include extracted trace IDs in HTTP metrics. Requires :ref:`OpenMetrics to be enabled<hubble_open_metrics>`.\n============== ============== =============================================================================================================\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``icmp``\n~~~~~~~~\n\n================================ ======================================== ========== ===================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ===================================\n``icmp_total``                   ``family``, ``type``                     Disabled   Number of ICMP messages\n================================ ======================================== ========== ===================================\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``kafka``\n~~~~~~~~~\n\n=================================== ===================================================== ========== ==============================================\nName                                Labels                                                Default    Description\n=================================== ===================================================== ========== ==============================================\n``kafka_requests_total``            ``topic``, ``api_key``, ``error_code``, ``reporter``  Disabled   Count of Kafka requests by topic\n``kafka_request_duration_seconds``  ``topic``, ``api_key``, ``reporter``                  Disabled   Histogram of Kafka request duration by topic\n=================================== ===================================================== ========== ==============================================\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``port-distribution``\n~~~~~~~~~~~~~~~~~~~~~\n\n================================ ======================================== ========== ==================================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ==================================================\n``port_distribution_total``      ``protocol``, ``port``                   Disabled   Numbers of packets distributed by destination port\n================================ ======================================== ========== ==================================================\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\n``tcp``\n~~~~~~~\n\n================================ ======================================== ========== ==================================================\nName                             Labels                                   Default    Description\n================================ ======================================== ========== ==================================================\n``tcp_flags_total``              ``flag``, ``family``                     Disabled   TCP flag occurrences\n================================ ======================================== ========== ==================================================\n\nOptions\n\"\"\"\"\"\"\"\n\nThis metric supports :ref:`Context Options<hubble_context_options>`.\n\ndynamic_exporter_exporters_total\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis is dynamic hubble exporter metric.\n\n==================================== ======================================== ========== ==================================================\nName                                 Labels                                   Default    Description\n==================================== ======================================== ========== ==================================================\n``dynamic_exporter_exporters_total`` ``source``                               Enabled    Number of configured hubble exporters\n==================================== ======================================== ========== ==================================================\n\nLabels\n\"\"\"\"\"\"\n\n- ``status`` identifies status of exporters, can be one of:\n   - ``active``\n   - ``inactive``\n\ndynamic_exporter_up\n~~~~~~~~~~~~~~~~~~~\n\nThis is dynamic hubble exporter metric.\n\n==================================== ======================================== ========== ==================================================\nName                                 Labels                                   Default    Description\n==================================== ======================================== ========== ==================================================\n``dynamic_exporter_up``              ``source``                               Enabled    Status of exporter (1 - active, 0 - inactive)\n==================================== ======================================== ========== ==================================================\n\nLabels\n\"\"\"\"\"\"\n\n- ``name`` identifies exporter name\n\ndynamic_exporter_reconfigurations_total\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis is dynamic hubble exporter metric.\n\n=========================================== ======================================== ========== ==================================================\nName                                        Labels                                   Default    Description\n=========================================== ======================================== ========== ==================================================\n``dynamic_exporter_reconfigurations_total`` ``op``                                   Enabled    Number of dynamic exporters reconfigurations\n=========================================== ======================================== ========== ==================================================\n\nLabels\n\"\"\"\"\"\"\n\n- ``op`` identifies reconfiguration operation type, can be one of:\n   - ``add``\n   - ``update``\n   - ``remove``\n\ndynamic_exporter_config_hash\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis is dynamic hubble exporter metric.\n\n==================================== ======================================== ========== ==================================================\nName                                 Labels                                   Default    Description\n==================================== ======================================== ========== ==================================================\n``dynamic_exporter_config_hash``                                              Enabled    Hash of last applied config\n==================================== ======================================== ========== ==================================================\n\ndynamic_exporter_config_last_applied\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis is dynamic hubble exporter metric.\n\n======================================== ======================================== ========== ==================================================\nName                                     Labels                                   Default    Description\n======================================== ======================================== ========== ==================================================\n``dynamic_exporter_config_last_applied``                                          Enabled    Timestamp of last applied config\n======================================== ======================================== ========== ==================================================\n\n\n\n\n.. _clustermesh_apiserver_metrics_reference:\n\nclustermesh-apiserver\n---------------------\n\nConfiguration\n^^^^^^^^^^^^^\n\nTo expose any metrics, invoke ``clustermesh-apiserver`` with the\n``--prometheus-serve-addr`` option. This option takes a ``IP:Port`` pair but\npassing an empty IP (e.g. ``:9962``) will bind the server to all available\ninterfaces (there is usually only one in a container).\n\nExported Metrics\n^^^^^^^^^^^^^^^^\n\nAll metrics are exported under the ``cilium_clustermesh_apiserver_``\nPrometheus namespace.\n\nBootstrap\n~~~~~~~~~\n\n======================================== ============================================ ========================================================\nName                                     Labels                                       Description\n======================================== ============================================ ========================================================\n``bootstrap_seconds``                    ``source_cluster``                           Duration in seconds to complete bootstrap\n======================================== ============================================ ========================================================\n\nKVstore\n~~~~~~~\n\n======================================== ============================================ ========================================================\nName                                     Labels                                       Description\n======================================== ============================================ ========================================================\n``kvstore_operations_duration_seconds``  ``action``, ``kind``, ``outcome``, ``scope`` Duration of kvstore operation\n``kvstore_events_queue_seconds``         ``action``, ``scope``                        Seconds waited before a received event was queued\n``kvstore_quorum_errors_total``          ``error``                                    Number of quorum errors\n``kvstore_sync_errors_total``            ``scope``, ``source_cluster``                Number of times synchronization to the kvstore failed\n``kvstore_sync_queue_size``              ``scope``, ``source_cluster``                Number of elements queued for synchronization in the kvstore\n``kvstore_initial_sync_completed``       ``scope``, ``source_cluster``, ``action``    Whether the initial synchronization from/to the kvstore has completed\n======================================== ============================================ ========================================================\n\nAPI Rate Limiting\n~~~~~~~~~~~~~~~~~\n\n============================================== ========================================== ========================================================\nName                                           Labels                                     Description\n============================================== ========================================== ========================================================\n``api_limiter_processed_requests_total``       ``api_call``, ``outcome``, ``return_code`` Total number of API requests processed\n``api_limiter_processing_duration_seconds``    ``api_call``, ``value``                    Mean and estimated processing duration in seconds\n``api_limiter_rate_limit``                     ``api_call``, ``value``                    Current rate limiting configuration (limit and burst)\n``api_limiter_requests_in_flight``             ``api_call``  ``value``                    Current and maximum allowed number of requests in flight\n``api_limiter_wait_duration_seconds``          ``api_call``, ``value``                     Mean, min, and max wait duration\n============================================== ========================================== ========================================================\n\nControllers\n~~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``controllers_group_runs_total``         ``status``, ``group_name``                         Enabled    Number of times that a controller process was run, labeled by controller group name\n======================================== ================================================== ========== ========================================================\n\nThe ``controllers_group_runs_total`` metric reports the success\nand failure count of each controller within the system, labeled by\ncontroller group name and completion status. Enabling this metric is\non a per-controller basis. This is configured using an allow-list which\nis passed as the ``controller-group-metrics`` configuration flag.\nThe current default set for ``clustermesh-apiserver`` found in the\nCilium Helm chart is the special name \"all\", which enables the metric\nfor all controller groups. The special name \"none\" is also supported.\n\n.. _kvstoremesh_metrics_reference:\n\nkvstoremesh\n-----------\n\nConfiguration\n^^^^^^^^^^^^^\n\nTo expose any metrics, invoke ``kvstoremesh`` with the\n``--prometheus-serve-addr`` option. This option takes a ``IP:Port`` pair but\npassing an empty IP (e.g. ``:9964``) binds the server to all available\ninterfaces (there is usually only one interface in a container).\n\nExported Metrics\n^^^^^^^^^^^^^^^^\n\nAll metrics are exported under the ``cilium_kvstoremesh_`` Prometheus namespace.\n\nBootstrap\n~~~~~~~~~\n\n======================================== ============================================ ========================================================\nName                                     Labels                                       Description\n======================================== ============================================ ========================================================\n``bootstrap_seconds``                    ``source_cluster``                           Duration in seconds to complete bootstrap\n======================================== ============================================ ========================================================\n\nRemote clusters\n~~~~~~~~~~~~~~~\n\n==================================== ======================================= =================================================================\nName                                 Labels                                                       Description\n==================================== ======================================= =================================================================\n``remote_clusters``                  ``source_cluster``                      The total number of remote clusters meshed with the local cluster\n``remote_cluster_failures``          ``source_cluster``, ``target_cluster``  The total number of failures related to the remote cluster\n``remote_cluster_last_failure_ts``   ``source_cluster``, ``target_cluster``  The timestamp of the last failure of the remote cluster\n``remote_cluster_readiness_status``  ``source_cluster``, ``target_cluster``  The readiness status of the remote cluster\n==================================== ======================================= =================================================================\n\nKVstore\n~~~~~~~\n\n======================================== ============================================ ========================================================\nName                                     Labels                                       Description\n======================================== ============================================ ========================================================\n``kvstore_operations_duration_seconds``  ``action``, ``kind``, ``outcome``, ``scope`` Duration of kvstore operation\n``kvstore_events_queue_seconds``         ``action``, ``scope``                        Seconds waited before a received event was queued\n``kvstore_quorum_errors_total``          ``error``                                    Number of quorum errors\n``kvstore_sync_errors_total``            ``scope``, ``source_cluster``                Number of times synchronization to the kvstore failed\n``kvstore_sync_queue_size``              ``scope``, ``source_cluster``                Number of elements queued for synchronization in the kvstore\n``kvstore_initial_sync_completed``       ``scope``, ``source_cluster``, ``action``    Whether the initial synchronization from/to the kvstore has completed\n======================================== ============================================ ========================================================\n\nAPI Rate Limiting\n~~~~~~~~~~~~~~~~~\n\n============================================== ========================================== ========================================================\nName                                           Labels                                     Description\n============================================== ========================================== ========================================================\n``api_limiter_processed_requests_total``       ``api_call``, ``outcome``, ``return_code`` Total number of API requests processed\n``api_limiter_processing_duration_seconds``    ``api_call``, ``value``                    Mean and estimated processing duration in seconds\n``api_limiter_rate_limit``                     ``api_call``, ``value``                    Current rate limiting configuration (limit and burst)\n``api_limiter_requests_in_flight``             ``api_call``  ``value``                    Current and maximum allowed number of requests in flight\n``api_limiter_wait_duration_seconds``          ``api_call``, ``value``                    Mean, min, and max wait duration\n============================================== ========================================== ========================================================\n\nControllers\n~~~~~~~~~~~\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``controllers_group_runs_total``         ``status``, ``group_name``                         Enabled    Number of times that a controller process was run, labeled by controller group name\n======================================== ================================================== ========== ========================================================\n\nThe ``controllers_group_runs_total`` metric reports the success\nand failure count of each controller within the system, labeled by\ncontroller group name and completion status. Enabling this metric is\non a per-controller basis. This is configured using an allow-list\nwhich is passed as the ``controller-group-metrics`` configuration\nflag. The current default set for ``kvstoremesh`` found in the\nCilium Helm chart is the special name \"all\", which enables the metric\nfor all controller groups. The special name \"none\" is also supported.\n\nNAT\n~~~\n\n.. _nat_metrics:\n\n======================================== ================================================== ========== ========================================================\nName                                     Labels                                             Default    Description\n======================================== ================================================== ========== ========================================================\n``nat_endpoint_max_connection``          ``family``                                         Enabled    Saturation of the most saturated distinct NAT mapped connection, in terms of egress-IP and remote endpoint address.\n======================================== ================================================== ========== ========================================================\n\nThese metrics are for monitoring Cilium's NAT mapping functionality. NAT is used by features such as Egress Gateway and BPF masquerading.\n\nThe NAT map holds mappings for masqueraded connections. Connection held in the NAT table that are masqueraded with the\nsame egress-IP and are going to the same remote endpoints IP and port all require a unique source port for the mapping.\nThis means that any Node masquerading connections to a distinct external endpoint is limited by the possible ephemeral source ports.\n\nGiven a Node forwarding one or more such egress-IP and remote endpoint tuples, the ``nat_endpoint_max_connection`` metric is the most saturated such connection in terms of a percent of possible source ports available.\nThis metric is especially useful when using the egress gateway feature where it's possible to overload a Node if many connections are all going to the same endpoint.\nIn general, this metric should normally be fairly low.\nA high number here may indicate that a Node is reaching its limit for connections to one or more external endpoints.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/observability/metrics.rst",
  "extracted_at": "2025-09-03T01:13:29.331518Z"
}
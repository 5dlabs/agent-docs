{
  "url": "file:///tmp/cilium-repo/Documentation/contributing/testing/scalability.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _scalability_testing:\n\nScalability and Performance Testing\n===================================\n\nIntroduction\n~~~~~~~~~~~~\n\nCilium scalability and performance tests leverage `ClusterLoader2 <CL2_>`_.\nFor an overview of ClusterLoader2, please refer to the `Readme <CL2_README_>`_ and `Getting Started <CL2_GETTING_STARTED_>`_.\nAt a high level, ClusterLoader2 allows for specifying states of the cluster, how to transition between them\nand what metrics to measure during the test run.\nAdditionally, it allows for failing the test if the metrics are not within the expected thresholds.\n\nOverview of existing tests\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTests based on kOps and GCP VMs:\n\n* 100 nodes scale test - ``/scale-100`` `Workflow <SCALE_100_WORKFLOW_>`_ that executes two test scenarios:\n\n    * `Upstream load test <UPSTREAM_LOAD_TEST_>`_\n\n    * `Network policy scale test <NETPOL_SCALE_TEST_>`_\n\n\n* FQDN performance test - ``/fqdn-perf`` `Workflow <FQDN_PERF_WORKFLOW_>`_\n  is a simple two-node test that deploys pods with FQDN policies\n  and measures the time it takes to resolve FQDNs from a client point of view.\n\n* ClusterMesh scale test - ``/scale-clustermesh`` `Workflow <CLUSTERMESH_WORKFLOW_>`_ leverages\n  a `mock Clustermesh control plane <CLUSTERMESH_MOCK_>`_ that simulates large deployments of ClusterMesh.\n\nTest based on EKS:\n\n* Egress Gateway scale test - ``/scale-egw``. `Workflow <EGW_WORKFLOW_>`_ tests Egress Gateway on a small cluster,\n  but with synthetically created Endpoints and Nodes to simulate a large cluster.\n\nWhenever developing a new test, consider if you want to add a test to an already existing workflow,\ncreate a new one, or extend some existing test.\nIf you are unsure, you can always ask in the ``#sig-scalabilty`` `Slack channel <SLACK_CHANNEL_>`_.\nFor example, if you want to run a test on a large cluster,\nyou might consider adding it as a separate test scenario to the already existing 100-nodes scale test\nto reduce the cost of CI, because spinning up a new cluster and tearing it down is quite a long process.\nFor some use cases, it might be better to simulate only a large cluster but execute the test on a small cluster,\nlike in the case of the Egress Gateway scale test or the ClusterMesh scale test.\n\nRunning CL2 tests locally\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nEach CL2 test should be designed in a way that scales with the number of nodes.\nThis allows for running a specific test case scenario in a local environment, to validate the test case.\nFor example, let's run the network policy scale test in a local Kind cluster.\nFirst, set up a Kind cluster with Cilium, as documented in :ref:`dev_env`.\nBuild the ClusterLoader2 binary from the `perf-tests repository <CL2_>`_.\nThen you can run:\n\n.. code-block:: bash\n\n    export CL2_PROMETHEUS_PVC_ENABLED=false\n    export CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR=true\n    export CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT=true\n    export CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT_INTERVAL=5s\n\n    ./clusterloader \\\n    -v=2 \\\n    --testconfig=.github/actions/cl2-modules/netpol/config.yaml \\\n    --provider=kind \\\n    --enable-prometheus-server \\\n    --nodes=1 \\\n    --report-dir=./report \\\n    --prometheus-scrape-kube-proxy=false \\\n    --prometheus-apiserver-scrape-port=6443 \\\n    --kubeconfig=$HOME/.kube/config\n\n\nSome additional options worth mentioning are:\n\n* ``--tear-down-prometheus-server=false`` - Leaves Prometheus and Grafana running after the test finishes, this helps speed up the test run\n  when running multiple tests in a row, but also for exploring the metrics in Grafana.\n* ``--experimental-prometheus-snapshot-to-report-dir=true`` - Creates a snapshot of the Prometheus data and saves it to the report directory\n\nBy setting ``deleteAutomanagedNamespaces: false`` in the test config, you can also leave\nthe test namespaces after the test finishes. This is especially useful for checking if your test\ncreated the expected resources.\n\nAt the end of output, the test should end successfully with::\n\n    clusterloader.go:252] --------------------------------------------------------------------------------\n    clusterloader.go:253] Test Finished\n    clusterloader.go:254]   Test: .github/actions/cl2-modules/netpol/config.yaml\n    clusterloader.go:255]   Status: Success\n    clusterloader.go:259] --------------------------------------------------------------------------------\n\n\nAll the test results are saved in the report directory, ``./report`` in this case.\nMost importantly, it contains:\n\n* ``generatedConfig_netpol.yaml`` - Rendered test scenario\n* ``'GenericPrometheusQuery NetPol Average CPU Usage_netpol_.*.json'`` - ``GenericPrometheusQuery`` \n  contains results of the Prometheus queries executed during the test.\n  In this example, it contains the CPU usage of the Cilium agents. \n  All of the Prometheus Queries will be automatically visualized in :ref:`perfdash <perfdashdocs>`.\n* ``'PodPeriodicCommand.*Profiles-stdout.*'`` - Contains memory and CPU profiles gathered during the test run. \n  To understand how to interpret them, refer to the :ref:`profiling` subsection.\n\n\nAccessing Grafana and Prometheus during the test run\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nDuring the test execution, ClusterLoader2 deploys Prometheus and Grafana to the cluster.\nYou can access Grafana and Prometheus by running:\n\n.. code-block:: bash\n\n    kubectl port-forward -n monitoring svc/grafana 3000\n    kubectl port-forward -n monitoring svc/prometheus-k8s 9090\n\nThis can be especially useful for exploring the metrics and adding additional queries to the test.\n\nMetrics-based testing and alerting\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSometimes, you might want to scrape additional targets during test execution on top of the default ones.\nIn this case, you can simply create a Pod or Service monitor `example monitor <EXAMPLE_MONITOR_>`_.\nThen you need to pass it as an additional argument to ClusterLoader2:\n\n.. code-block:: bash\n\n    ./clusterloader \\\n    --prometheus-additional-monitors-path=../../.github/actions/cl2-modules/egw/prom-extra-podmons\n    ...\n\nNow you can use the additional metrics in your test, by leveraging regular ``GenericPrometheusQuery`` measurement.\nFor example, Egress Gateway ensures that various percentiles of masquerade latency observed by clients are\n`below specific thresholds <EGW_MASQ_METRICS_>`_. This can be achieved by the following measurement in ClusterLoader2:\n\n.. code-block:: yaml\n\n  - Identifier: MasqueradeDelay{{ .metricsSuffix }}\n    Method: GenericPrometheusQuery\n    Params:\n      action: {{ .action }}\n      metricName: Masquerade Delay {{ .metricsSuffix }}\n      metricVersion: v1\n      unit: s\n      enableViolations: true\n      queries:\n      - name: P95\n        query: quantile(0.95, egw_scale_test_masquerade_delay_seconds_total{k8s_instance=\"{{ .instance }}\"})\n        threshold: {{ $MASQ_DELAY_THRESHOLD }}\n\n\nRunning tests in CI\n~~~~~~~~~~~~~~~~~~~\n\nOnce you are happy with the test and validated it locally, you can create a PR with the test.\nYou can base your GitHub workflow on the existing tests, or add a test scenario to an already existing workflow.\n\n\nAccessing test results from PR or CI runs\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nYou can run the specific scalability or performance test in your PR, some example commands are::\n\n    /scale-100\n    /scale-clustermesh\n    /scale-egw\n    /fqdn-perf\n\nAfter the test run, all results will be saved in the Google Storage bucket.\nIn the workflow run, you will see a link to the test results at the bottom.\nFor example, open `test runs <TEST_RUN_>`_ and pick one of the runs.\nYou should see a link like this:\n\n::\n\n    EXPORT_DIR: gs://cilium-scale-results/logs/scale-100-main/1745287079\n\nTo see how to install gsutil check `Install gsutil <GSUTIL_INSTALL>`_ section.\nTo see the results, you can run:\n\n.. code-block:: bash\n\n    gsutil ls -r gs://cilium-scale-results/logs/scale-100-main/1745287079\n\nYou can also copy results to your local machine by running:\n\n.. code-block:: bash\n\n    gsutil -m cp -r gs://cilium-scale-results/logs/scale-100-main/1745287079 .\n\n\n.. _perfdashdocs:\n\nVisualizing results in Perfdash\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nPerfdash leverages exported results from ClusterLoader2 and visualizes them.\nCurrently, we do not host a publicly available instance of Perfdash.\nTo visualize the results, please check the `Scaffolding repository <PERFDASH_>`_.\nAs an example, you can check CPU usage of the Cilium agent:\n\n.. image:: /images/perfdash.png\n    :align: center\n\nNote that clicking on the graph redirects you to the Google Cloud Storage page containing all of the results\nfor the specific test run.\n\nAccessing Prometheus snapshot\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nEach test run creates a snapshot of the Prometheus data and saves it to the report directory.\nThis is enabled by setting ``--experimental-prometheus-snapshot-to-report-dir=true``.\nPrometheus snapshots help with debugging, give a good overview of the cluster state\nduring the test run and can be used to further improve alerting in CI based on existing metrics.\n\nFor example, a snapshot can be found in the directory\n``gs://cilium-scale-results/logs/scale-100-main/1745287079/artifacts/prometheus_snapshot.tar.gz``.\nYou need to extract it and run Prometheus locally:\n\n.. code-block:: console\n\n    $ tar xvf ./prometheus_snapshot.tar.gz\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/01JSDJB32JAM1FQ6SN8ESFNDN0/\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/01JSDJB32JAM1FQ6SN8ESFNDN0/meta.json\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/01JSDJB32JAM1FQ6SN8ESFNDN0/tombstones\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/01JSDJB32JAM1FQ6SN8ESFNDN0/index\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/01JSDJB32JAM1FQ6SN8ESFNDN0/chunks/\n    prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/01JSDJB32JAM1FQ6SN8ESFNDN0/chunks/000001\n\n    $ prometheus --storage.tsdb.path=./prometheus/snapshots/20250422T013829Z-3ee723086c84c32a/ --web.listen-address=\"0.0.0.0:9092\"\n\nTo visualize the data, you can run Grafana locally and connect it to the Prometheus instance.\n\n.. _profiling:\n\nAccessing CPU and memory profiles\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nAll of the scalability tests collect CPU and memory profiles.\nThey are collected under file names like ``PodPeriodicCommand.*Profiles-stdout.*``.\nEach profile is taken periodically during the test run.\nThe simplest way to visualize them is to leverage `pprof-merge <PPROF_MERGE_>`_.\nExample commands to aggregate CPU and memory profiles from the whole test run:\n\n.. code-block:: bash\n\n    gsutil -m cp gs://cilium-scale-results/logs/scale-100-main/1745287079/artifacts/PodPeriodicCommand*Profiles-stdout* ./\n    for file in *.txt; do mv \"$file\" \"${file%.txt}.tar.gz\"; tar xvf \"${file%.txt}.tar.gz\"; done\n    pprof-merge cilium-bugtool*/cmd/pprof-cpu && mv merged.data cpu.pprof\n    pprof-merge cilium-bugtool*/cmd/pprof-heap && mv merged.data heap.pprof\n    rm -r cilium-bugtool* PodPeriodicCommand*\n\nThen you can visualize the aggregated CPU and memory profiles by running:\n\n.. code-block:: bash\n\n    go tool pprof -http=localhost:8080 cpu.pprof\n    go tool pprof -http=localhost:8080 heap.pprof\n\n\nIf you want to compare the profiles, you can compare them against the baseline extracted from different test run:\n\n.. code-block:: bash\n\n    go tool pprof -http=localhost:8080 --base=baseline_cpu.pprof cpu.pprof\n    go tool pprof -http=localhost:8080 --base=baseline_heap.pprof heap.pprof\n\n\n.. _CL2: https://github.com/kubernetes/perf-tests/tree/master/clusterloader2\n.. _CL2_GETTING_STARTED: https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/docs/GETTING_STARTED.md\n.. _CL2_README: https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/README.md\n.. _CLUSTERMESH_MOCK: https://github.com/cilium/scaffolding/tree/main/cmapisrv-mock\n.. _CLUSTERMESH_WORKFLOW: https://github.com/cilium/cilium/blob/main/.github/workflows/scale-test-clustermesh.yaml\n.. _EGW_MASQ_METRICS: https://github.com/cilium/cilium/blob/main/.github/actions/cl2-modules/egw/modules/masq-metrics.yaml\n.. _EGW_WORKFLOW: https://github.com/cilium/cilium/blob/main/.github/workflows/scale-test-egw.yaml\n.. _EXAMPLE_MONITOR: https://github.com/cilium/cilium/blob/main/.github/actions/cl2-modules/egw/prom-extra-podmons/podmonitor.yaml\n.. _FQDN_PERF_WORKFLOW: https://github.com/cilium/cilium/blob/main/.github/workflows/fqdn-perf.yaml\n.. _GSUTIL_INSTALL: https://cloud.google.com/storage/docs/gsutil_install\n.. _NETPOL_SCALE_TEST: https://github.com/cilium/cilium/tree/main/.github/actions/cl2-modules/netpol\n.. _PERFDASH: https://github.com/cilium/scaffolding/tree/main/scale-tests\n.. _PPROF_MERGE: https://github.com/rakyll/pprof-merge\n.. _SCALE_100_WORKFLOW: https://github.com/cilium/cilium/blob/main/.github/workflows/scale-test-100-gce.yaml\n.. _SLACK_CHANNEL: https://slack.cilium.io\n.. _TEST_RUN: https://github.com/cilium/cilium/actions/workflows/scale-test-100-gce.yaml\n.. _UPSTREAM_LOAD_TEST: https://github.com/kubernetes/perf-tests/tree/master/clusterloader2/testing/load\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/contributing/testing/scalability.rst",
  "extracted_at": "2025-09-03T01:13:28.845079Z"
}
{
  "url": "file:///tmp/cilium-repo/Documentation/security/kafka.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _gs_kafka:\n\n************************\nSecuring a Kafka Cluster\n************************\n\nThis document serves as an introduction to using Cilium to enforce Kafka-aware\nsecurity policies.  It is a detailed walk-through of getting a single-node\nCilium environment running on your machine. It is designed to take 15-30\nminutes.\n\n.. include:: gsg_requirements.rst\n\nDeploy the Demo Application\n===========================\n\nNow that we have Cilium deployed and ``kube-dns`` operating correctly we can\ndeploy our demo Kafka application.  Since our first demo of Cilium + HTTP-aware security\npolicies was Star Wars-themed we decided to do the same for Kafka.  While the\n`HTTP-aware Cilium  Star Wars demo <https://cilium.io/blog/2017/5/4/demo-may-the-force-be-with-you/>`_\nshowed how the Galactic Empire used HTTP-aware security policies to protect the Death Star from the\nRebel Alliance, this Kafka demo shows how the lack of Kafka-aware security policies allowed the\nRebels to steal the Death Star plans in the first place.\n\nKafka is a powerful platform for passing datastreams between different components of an application.\nA cluster of \"Kafka brokers\" connect nodes that \"produce\" data into a data stream, or \"consume\" data\nfrom a datastream.   Kafka refers to each datastream as a \"topic\".\nBecause scalable and highly-available Kafka clusters are non-trivial to run, the same cluster of\nKafka brokers often handles many different topics at once (read this `Introduction to Kafka\n<https://kafka.apache.org/intro>`_ for more background).\n\nIn our simple example, the Empire uses a Kafka cluster to handle two different topics:\n\n- *empire-announce* : Used to broadcast announcements to sites spread across the galaxy\n- *deathstar-plans* : Used by a small group of sites coordinating on building the ultimate battlestation.\n\nTo keep the setup small, we will just launch a small number of pods to represent this setup:\n\n- *kafka-broker* : A single pod running Kafka and Zookeeper representing the Kafka cluster\n  (label app=kafka).\n- *empire-hq* : A pod representing the Empire's Headquarters, which is the only pod that should\n  produce messages to *empire-announce* or *deathstar-plans* (label app=empire-hq).\n- *empire-backup* : A secure backup facility located in `Scarif <https://starwars.fandom.com/wiki/Scarif_vault>`_ ,\n  which is allowed to \"consume\" from the secret *deathstar-plans* topic (label app=empire-backup).\n- *empire-outpost-8888* : A random outpost in the empire.  It needs to \"consume\" messages from\n  the *empire-announce* topic (label app=empire-outpost).\n- *empire-outpost-9999* : Another random outpost in the empire that \"consumes\" messages from\n  the *empire-announce* topic (label app=empire-outpost).\n\nAll pods other than *kafka-broker* are Kafka clients, which need access to the *kafka-broker*\ncontainer on TCP port 9092 in order to send Kafka protocol messages.\n\n.. image:: images/cilium_kafka_gsg_topology.png\n\nThe file ``kafka-sw-app.yaml`` contains a Kubernetes Deployment for each of the pods described\nabove, as well as a Kubernetes Service for both Kafka and Zookeeper.\n\n.. parsed-literal::\n\n    $ kubectl create -f \\ |SCM_WEB|\\/examples/kubernetes-kafka/kafka-sw-app.yaml\n    deployment \"kafka-broker\" created\n    deployment \"zookeeper\" created\n    service \"zook\" created\n    service \"kafka-service\" created\n    deployment \"empire-hq\" created\n    deployment \"empire-outpost-8888\" created\n    deployment \"empire-outpost-9999\" created\n    deployment \"empire-backup\" created\n\nKubernetes will deploy the pods and service  in the background.\nRunning ``kubectl get svc,pods`` will inform you about the progress of the operation.\nEach pod will go through several states until it reaches ``Running`` at which\npoint the setup is ready.\n\n.. code-block:: shell-session\n\n    $ kubectl get svc,pods\n    NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\n    kafka-service   ClusterIP   None            <none>        9092/TCP   2m\n    kubernetes      ClusterIP   10.96.0.1       <none>        443/TCP    10m\n    zook            ClusterIP   10.97.250.131   <none>        2181/TCP   2m\n\n    NAME                                   READY     STATUS    RESTARTS   AGE\n    empire-backup-6f4567d5fd-gcrvg         1/1       Running   0          2m\n    empire-hq-59475b4b64-mrdww             1/1       Running   0          2m\n    empire-outpost-8888-78dffd49fb-tnnhf   1/1       Running   0          2m\n    empire-outpost-9999-7dd9fc5f5b-xp6jw   1/1       Running   0          2m\n    kafka-broker-b874c78fd-jdwqf           1/1       Running   0          2m\n    zookeeper-85f64b8cd4-nprck             1/1       Running   0          2m\n\nSetup Client Terminals\n======================\n\nFirst we will open a set of windows to represent the different Kafka clients discussed above.\nFor consistency, we recommend opening them in the pattern shown in the image below, but this is optional.\n\n.. image:: images/cilium_kafka_gsg_terminal_layout.png\n\nIn each window, use copy-paste to have each terminal provide a shell inside each pod.\n\nempire-hq terminal:\n\n.. code-block:: shell-session\n\n   $ HQ_POD=$(kubectl get pods -l app=empire-hq -o jsonpath='{.items[0].metadata.name}') && kubectl exec -it $HQ_POD -- sh -c \"PS1=\\\"empire-hq $\\\" /bin/bash\"\n\nempire-backup terminal:\n\n.. code-block:: shell-session\n\n   $ BACKUP_POD=$(kubectl get pods -l app=empire-backup -o jsonpath='{.items[0].metadata.name}') && kubectl exec -it $BACKUP_POD -- sh -c \"PS1=\\\"empire-backup $\\\" /bin/bash\"\n\noutpost-8888 terminal:\n\n.. code-block:: shell-session\n\n   $ OUTPOST_8888_POD=$(kubectl get pods -l outpostid=8888 -o jsonpath='{.items[0].metadata.name}') && kubectl exec -it $OUTPOST_8888_POD -- sh -c \"PS1=\\\"outpost-8888 $\\\" /bin/bash\"\n\noutpost-9999 terminal:\n\n.. code-block:: shell-session\n\n   $ OUTPOST_9999_POD=$(kubectl get pods -l outpostid=9999 -o jsonpath='{.items[0].metadata.name}') && kubectl exec -it $OUTPOST_9999_POD -- sh -c \"PS1=\\\"outpost-9999 $\\\" /bin/bash\"\n\n\nTest Basic Kafka Produce & Consume\n==================================\n\nFirst, let's start the consumer clients listening to their respective Kafka topics.  All of the consumer\ncommands below will hang intentionally, waiting to print data they consume from the Kafka topic:\n\nIn the *empire-backup* window, start listening on the top-secret *deathstar-plans* topic:\n\n.. code-block:: shell-session\n\n    $ ./kafka-consume.sh --topic deathstar-plans\n\nIn the *outpost-8888* window, start listening to *empire-announcement*:\n\n.. code-block:: shell-session\n\n    $ ./kafka-consume.sh --topic empire-announce\n\nDo the same in the *outpost-9999* window:\n\n.. code-block:: shell-session\n\n    $ ./kafka-consume.sh --topic empire-announce\n\nNow from the *empire-hq*, first produce a message to the *empire-announce* topic:\n\n.. code-block:: shell-session\n\n   $ echo \"Happy 40th Birthday to General Tagge\" | ./kafka-produce.sh --topic empire-announce\n\nThis message will be posted to the *empire-announce* topic, and shows up in both the *outpost-8888* and\n*outpost-9999* windows who consume that topic.   It will not show up in *empire-backup*.\n\n*empire-hq* can also post a version of the top-secret deathstar plans to the *deathstar-plans* topic:\n\n.. code-block:: shell-session\n\n   $ echo \"deathstar reactor design v3\" | ./kafka-produce.sh --topic deathstar-plans\n\nThis message shows up in the *empire-backup* window, but not for the outposts.\n\nCongratulations, Kafka is working as expected :)\n\nThe Danger of a Compromised Kafka Client\n========================================\n\nBut what if a rebel spy gains access to any of the remote outposts that act as Kafka clients?\nSince every client has access to the Kafka broker on port 9092, it can do some bad stuff.\nFor starters, the outpost container can actually switch roles from a consumer to a producer,\nsending \"malicious\" data to all other consumers on the topic.\n\nTo prove this, kill the existing ``kafka-consume.sh`` command in the outpost-9999 window\nby typing control-C and instead run:\n\n.. code-block:: shell-session\n\n  $ echo \"Vader Booed at Empire Karaoke Party\" | ./kafka-produce.sh --topic empire-announce\n\nUh oh!  Outpost-8888 and all of the other outposts in the empire have now received this fake announcement.\n\nBut even more nasty from a security perspective is that the outpost container can access any topic\non the kafka-broker.\n\nIn the outpost-9999 container, run:\n\n.. code-block:: shell-session\n\n  $ ./kafka-consume.sh --topic deathstar-plans\n  \"deathstar reactor design v3\"\n\nWe see that any outpost can actually access the secret deathstar plans.  Now we know how the rebels got\naccess to them!\n\nSecuring Access to Kafka with Cilium\n====================================\n\nObviously, it would be much more secure to limit each pod's access to the Kafka broker to be\nleast privilege (i.e., only what is needed for the app to operate correctly and nothing more).\n\nWe can do that with the following Cilium security policy.   As with Cilium HTTP policies, we can write\npolicies that identify pods by labels, and then limit the traffic in/out of this pod.  In\nthis case, we'll create a policy that identifies the exact traffic that should be allowed to reach the\nKafka broker, and deny the rest.\n\nAs an example, a policy could limit containers with label *app=empire-outpost* to only be able to consume\ntopic *empire-announce*, but would block any attempt by a compromised container (e.g., empire-outpost-9999)\nfrom producing to *empire-announce* or consuming from *deathstar-plans*.\n\n.. image:: images/cilium_kafka_gsg_attack.png\n\nHere is the *CiliumNetworkPolicy* rule that limits access of pods with label *app=empire-outpost* to\nonly consume on topic *empire-announce*:\n\n.. literalinclude:: ../../examples/policies/getting-started/kafka.yaml\n\nA *CiliumNetworkPolicy* contains a list of rules that define allowed requests, meaning that requests\nthat do not match any rules are denied as invalid.\n\nThe above rule applies to inbound (i.e., \"ingress\") connections to kafka-broker pods (as\nindicated by \"app: kafka\"\nin the \"endpointSelector\" section).  The rule will apply to connections from pods with label\n\"app: empire-outpost\" as indicated by the \"fromEndpoints\" section.   The rule explicitly matches\nKafka connections destined to TCP 9092, and allows consume/produce actions on various topics of interest.\nFor example we are allowing *consume* from topic *empire-announce* in this case.\n\nThe full policy adds two additional rules that permit the legitimate \"produce\"\n(topic *empire-announce* and topic *deathstar-plans*) from *empire-hq* and the\nlegitimate consume  (topic = \"deathstar-plans\") from *empire-backup*.  The full policy\ncan be reviewed by opening the URL in the command below in a browser.\n\nApply this Kafka-aware network security policy using ``kubectl`` in the main window:\n\n.. parsed-literal::\n\n    $ kubectl create -f \\ |SCM_WEB|\\/examples/kubernetes-kafka/kafka-sw-security-policy.yaml\n\nIf we then again try to produce a message from outpost-9999 to *empire-annnounce*, it is denied.\nType control-c and then run:\n\n.. code-block:: shell-session\n\n  $ echo \"Vader Trips on His Own Cape\" | ./kafka-produce.sh --topic empire-announce\n  >>[2018-04-10 23:50:34,638] ERROR Error when sending message to topic empire-announce with key: null, value: 27 bytes with error: (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)\n  org.apache.kafka.common.errors.TopicAuthorizationException: Not authorized to access topics: [empire-announce]\n\nThis is because the policy does not allow messages with role = \"produce\" for topic \"empire-announce\" from\ncontainers with label app = empire-outpost.  Its worth noting that we don't simply drop the message (which\ncould easily be confused with a network error), but rather we respond with the Kafka access denied error\n(similar to how HTTP would return an error code of 403 unauthorized).\n\nLikewise, if the outpost container ever tries to consume from topic *deathstar-plans*, it is denied, as\nrole = consume is only allowed for topic *empire-announce*.\n\nTo test, from the outpost-9999 terminal, run:\n\n.. code-block:: shell-session\n\n  $./kafka-consume.sh --topic deathstar-plans\n  [2018-04-10 23:51:12,956] WARN Error while fetching metadata with correlation id 2 : {deathstar-plans=TOPIC_AUTHORIZATION_FAILED} (org.apache.kafka.clients.NetworkClient)\n\nThis is blocked as well, thanks to the Cilium network policy. Imagine how different things would have been if the empire had been using\nCilium from the beginning!\n\nClean Up\n========\n\nYou have now installed Cilium, deployed a demo app, and tested both\nL7 Kafka-aware network security policies.  To clean up, run:\n\n.. parsed-literal::\n\n   $ kubectl delete -f \\ |SCM_WEB|\\/examples/kubernetes-kafka/kafka-sw-app.yaml\n   $ kubectl delete cnp secure-empire-kafka\n\n\nAfter this, you can re-run the tutorial from Step 1.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/security/kafka.rst",
  "extracted_at": "2025-09-03T01:13:28.748952Z"
}
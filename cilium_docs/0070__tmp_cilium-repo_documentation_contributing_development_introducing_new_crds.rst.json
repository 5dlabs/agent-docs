{
  "url": "file:///tmp/cilium-repo/Documentation/contributing/development/introducing_new_crds.rst",
  "content": "Introducing New CRDs\n====================\n\nCilium uses a combination of code generation tools to facilitate adding\nCRDs to the Kubernetes instance it is installed on.\n\nThese CRDs make themselves available in the generated Kubernetes client\nCilium uses.\n\nDefining And Generating CRDs\n----------------------------\n\nCurrently, two API versions exist ``v2`` and ``v2alpha1``.\n\nPaths:\n\n::\n\n   pkg/k8s/apis/cilium.io/v2/\n   pkg/k8s/apis/cilium.io/v2alpha1/\n\nCRDs are defined via Golang structures, annotated with ``marks``, and\ngenerated with Cilium make file targets.\n\nMarks\n~~~~~\n\nMarks are used to tell ``controller-gen`` *how* to generate the CRD.\nThis includes defining the CRD's various names (Singular, plural,\ngroup), its Scope (Cluster, Namespaced), Shortnames, etcâ€¦\n\nAn example:\n\n::\n\n   // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\n   // +kubebuilder:resource:categories={cilium},singular=\"ciliumendpointslice\",path=\"ciliumendpointslices\",scope=\"Cluster\",shortName={ces}\n\n   // +kubebuilder:storageversion\n\nYou can find CRD generation ``marks`` documentation\n`here <https://book.kubebuilder.io/reference/markers/crd.html>`__.\n\nMarks are also used to generate json-schema validation. You can define\nvalidation criteria such as \"format=cidr\" and \"required\" via validation\n``marks`` in your struct's comments.\n\nAn example:\n\n.. code-block:: go\n\n   type CiliumBGPPeeringConfiguration struct {\n       // PeerAddress is the IP address of the peer.\n       // This must be in CIDR notation and use a /32 to express\n       // a single host.\n       //\n       // +kubebuilder:validation:Required\n       // +kubebuilder:validation:Format=cidr\n       PeerAddress string `json:\"peerAddress\"`\n\nYou can find CRD validation ``marks`` documentation\n`here <https://book.kubebuilder.io/reference/markers/crd-validation.html>`__.\n\nDefining CRDs\n~~~~~~~~~~~~~\n\nPaths:\n\n::\n\n   pkg/k8s/apis/cilium.io/v2/\n   pkg/k8s/apis/cilium.io/v2alpha1/\n\nThe portion of the directory after ``apis/`` makes up the CRD's\n``Group`` and ``Version``. See\n`KubeBuilder-GVK <https://book.kubebuilder.io/cronjob-tutorial/gvks.html>`__\n\nYou can begin defining your ``CRD`` structure, making any subtypes you\nlike to adequately define your data model and using ``marks`` to control\nthe CRD generation process.\n\nHere is a brief example, omitting any further definitions of sub-types\nto express the CRD data model.\n\n.. code-block:: go\n\n   // +genclient\n   // +genclient:nonNamespaced\n   // +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n   // +kubebuilder:resource:categories={cilium,ciliumbgp},singular=\"ciliumbgppeeringpolicy\",path=\"ciliumbgppeeringpolicies\",scope=\"Cluster\",shortName={bgpp}\n   // +kubebuilder:printcolumn:JSONPath=\".metadata.creationTimestamp\",name=\"Age\",type=date\n   // +kubebuilder:storageversion\n\n   // CiliumBGPPeeringPolicy is a Kubernetes third-party resource for instructing\n   // Cilium's BGP control plane to create peers.\n   type CiliumBGPPeeringPolicy struct {\n       // +k8s:openapi-gen=false\n       // +deepequal-gen=false\n       metav1.TypeMeta `json:\",inline\"`\n       // +k8s:openapi-gen=false\n       // +deepequal-gen=false\n       metav1.ObjectMeta `json:\"metadata\"`\n\n       // Spec is a human readable description of a BGP peering policy\n       //\n       // +kubebuilder:validation:Required\n       Spec CiliumBGPPeeringPolicySpec `json:\"spec,omitempty\"`\n   }\n\nIntegrating CRDs Into Cilium\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOnce you've coded your CRD data model you can use Cilium's ``make``\ninfrastructure to generate and integrate your CRD into Cilium.\n\nThere are several make targets and a script which revolve around\ngenerating CRD and associated code gen (client, informers, ``DeepCopy``\nimplementations, ``DeepEqual`` implementations, etc).\n\nEach of the next sections also detail the steps you should take to\nintegrate your CRD into Cilium.\n\nGenerating CRD YAML\n~~~~~~~~~~~~~~~~~~~\n\nTo simply generate the CRDs and copy them into the correct location you\nmust perform two tasks:\n\n* Update the ``Makefile`` to edit the ``CRDS_CILIUM_V2`` or\n  ``CRDS_CILIUM_V2ALPHA1`` variable (depending on the version of your new CRD)\n  to contain the plural name of your new CRD.\n* Run ``make manifests``\n\nThis will generate your Golang structs into CRD manifests and copy them\nto ``./pkg/k8s/apis/cilium.io/client/crds/`` into the appropriate\n``Version`` directory.\n\nYou can inspect your generated ``CRDs`` to confirm they look OK.\n\nAdditionally ``./contrib/scripts/check-k8s-code-gen.sh`` is a script\nwhich will generate the CRD manifest along with generating the necessary K8s \nAPI changes to use your CRDs via K8s client in Cilium source code.\n\nGenerating Client Code\n~~~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: shell-session\n\n    make generate-k8s-api\n\nThis make target will perform the necessary code-gen to integrate your\nCRD into Cilium's ``client-go`` client, create listers, watchers, and\ninformers.\n\nAgain, multiple steps must be taken to fully integrate your CRD into\nCilium.\n\nRegister With API Scheme\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nPaths:\n\n::\n\n    pkg/k8s/apis/cilium.io/v2alpha1/register.go\n\nMake a change similar to this diff to register your CRDs with the API\nscheme.\n\n.. code-block:: diff\n\n   diff --git a/pkg/k8s/apis/cilium.io/v2alpha1/register.go b/pkg/k8s/apis/cilium.io/v2alpha1/register.go\n   index 9650e32f8d..0d85c5a233 100644\n   --- a/pkg/k8s/apis/cilium.io/v2alpha1/register.go\n   +++ b/pkg/k8s/apis/cilium.io/v2alpha1/register.go\n   @@ -55,6 +55,34 @@ const (\n    \n           // CESName is the full name of Cilium Endpoint Slice\n           CESName = CESPluralName + \".\" + CustomResourceDefinitionGroup\n   +\n   +       // Cilium BGP Peering Policy (BGPP)\n   +\n   +       // BGPPPluralName is the plural name of Cilium BGP Peering Policy\n   +       BGPPPluralName = \"ciliumbgppeeringpolicies\"\n   +\n   +       // BGPPKindDefinition is the kind name of Cilium BGP Peering Policy\n   +       BGPPKindDefinition = \"CiliumBGPPeeringPolicy\"\n   +\n   +       // BGPPName is the full name of Cilium BGP Peering Policy\n   +       BGPPName = BGPPPluralName + \".\" + CustomResourceDefinitionGroup\n   +\n   +       // Cilium BGP Load Balancer IP Pool (BGPPool)\n   +\n   +       // BGPPoolPluralName is the plural name of Cilium BGP Load Balancer IP Pool\n   +       BGPPoolPluralName = \"ciliumbgploadbalancerippools\"\n   +\n   +       // BGPPoolKindDefinition is the kind name of Cilium BGP Peering Policy\n   +       BGPPoolKindDefinition = \"CiliumBGPLoadBalancerIPPool\"\n   +\n   +       // BGPPoolName is the full name of Cilium BGP Load Balancer IP Pool\n   +       BGPPoolName = BGPPoolPluralName + \".\" + CustomResourceDefinitionGroup\n    )\n    \n    // SchemeGroupVersion is group version used to register these objects\n   @@ -102,6 +130,10 @@ func addKnownTypes(scheme *runtime.Scheme) error {\n                   &CiliumEndpointSlice{},\n                   &CiliumEndpointSliceList{},\n   +               &CiliumBGPPeeringPolicy{},\n   +               &CiliumBGPPeeringPolicyList{},\n   +               &CiliumBGPLoadBalancerIPPool{},\n   +               &CiliumBGPLoadBalancerIPPoolList{},\n           )\n    \n           metav1.AddToGroupVersion(scheme, SchemeGroupVersion)\n\nYou should also bump the ``CustomResourceDefinitionSchemaVersion``\nvariable in ``register.go`` to instruct Cilium\nthat new CRDs have been added to the system.\n\nRegister With Client\n~~~~~~~~~~~~~~~~~~~~\n\n``pkg/k8s/apis/cilium.io/client/register.go``\n\nMake a change similar to the following to register CRD types with the\nclient.\n\n.. code-block:: diff\n\n   diff --git a/pkg/k8s/apis/cilium.io/client/register.go b/pkg/k8s/apis/cilium.io/client/register.go\n   index ede134d7d9..ec82169270 100644\n   --- a/pkg/k8s/apis/cilium.io/client/register.go\n   +++ b/pkg/k8s/apis/cilium.io/client/register.go\n   @@ -60,6 +60,12 @@ const (\n    \n           // CESCRDName is the full name of the CES CRD.\n           CESCRDName = k8sconstv2alpha1.CESKindDefinition + \"/\" + k8sconstv2alpha1.CustomResourceDefinitionVersion\n   +\n   +       // BGPPCRDName is the full name of the BGPP CRD.\n   +       BGPPCRDName = k8sconstv2alpha1.BGPPKindDefinition + \"/\" + k8sconstv2alpha1.CustomResourceDefinitionVersion\n   +\n   +       // BGPPoolCRDName is the full name of the BGPPool CRD.\n   +       BGPPoolCRDName = k8sconstv2alpha1.BGPPoolKindDefinition + \"/\" + k8sconstv2alpha1.CustomResourceDefinitionVersion\n    )\n    \n    var (\n   @@ -86,6 +92,7 @@ func CreateCustomResourceDefinitions(clientset apiextensionsclient.Interface) er\n                   synced.CRDResourceName(k8sconstv2.CLRPName):       createCRD(CLRPCRDName, k8sconstv2.CLRPName),\n                   synced.CRDResourceName(k8sconstv2.CEGPName):       createCRD(CEGPCRDName, k8sconstv2.CEGPName),\n                   synced.CRDResourceName(k8sconstv2alpha1.CESName):  createCRD(CESCRDName, k8sconstv2alpha1.CESName),\n   +               synced.CRDResourceName(k8sconstv2alpha1.BGPPName): createCRD(BGPPCRDName, k8sconstv2alpha1.BGPPName),\n           }\n           for _, r := range synced.AllCiliumCRDResourceNames() {\n                   fn, ok := resourceToCreateFnMapping[r]\n   @@ -127,6 +134,12 @@ var (\n    \n           //go:embed crds/v2alpha1/ciliumendpointslices.yaml\n           crdsv2Alpha1Ciliumendpointslices []byte\n   +\n   +       //go:embed crds/v2alpha1/ciliumbgppeeringpolicies.yaml\n   +       crdsv2Alpha1Ciliumbgppeeringpolicies []byte\n   +\n   +       //go:embed crds/v2alpha1/ciliumbgploadbalancerippools.yaml\n   +       crdsv2Alpha1Ciliumbgploadbalancerippools []byte\n    )\n    \n    // GetPregeneratedCRD returns the pregenerated CRD based on the requested CRD\n\n\n``pkg/k8s/watchers/watcher.go``\n\nAlso, configure the watcher for this resource (or tell the agent not to watch it)\n\n.. code-block:: diff\n\n   diff --git a/pkg/k8s/watchers/watcher.go b/pkg/k8s/watchers/watcher.go\n   index eedf397b6b..8419eb90fd 100644\n   --- a/pkg/k8s/watchers/watcher.go\n   +++ b/pkg/k8s/watchers/watcher.go\n   @@ -398,6 +398,7 @@ var ciliumResourceToGroupMapping = map[string]watcherInfo{\n         synced.CRDResourceName(v2.CECName):           {afterNodeInit, k8sAPIGroupCiliumEnvoyConfigV2},\n         synced.CRDResourceName(v2alpha1.BGPPName):    {skip, \"\"}, // Handled in BGP control plane\n         synced.CRDResourceName(v2alpha1.BGPPoolName): {skip, \"\"}, // Handled in BGP control plane\n   +     synced.CRDResourceName(v2.CCOName):           {skip, \"\"}, // Handled by init directly\n\n\nGetting Your CRDs Installed\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYour new CRDs must be installed into Kubernetes. This is controlled in\nthe ``pkg/k8s/synced/crd.go`` file.\n\nHere is an example diff which installs the CRDs ``v2alpha1.BGPPName``\nand ``v2alpha.BGPPoolName``:\n\n.. code-block:: diff\n\n   diff --git a/pkg/k8s/synced/crd.go b/pkg/k8s/synced/crd.go\n   index 52d975c449..10c554cf8a 100644\n   --- a/pkg/k8s/synced/crd.go\n   +++ b/pkg/k8s/synced/crd.go\n   @@ -42,6 +42,11 @@ func agentCRDResourceNames() []string {\n                   CRDResourceName(v2.CCNPName),\n                   CRDResourceName(v2.CNName),\n                   CRDResourceName(v2.CIDName),\n   +               CRDResourceName(v2.CIDName),\n   +               // TODO(louis) make this a conditional install\n   +               // based on --enable-bgp-control-plane flag\n   +               CRDResourceName(v2alpha1.BGPPName),\n   +               CRDResourceName(v2alpha1.BGPPoolName),\n           }\n\nUpdating RBAC Roles\n~~~~~~~~~~~~~~~~~~~\n\nCilium is installed with a service account and this service account\nshould be given RBAC permissions to access your new CRDs. The following\nfiles should be updated to include permissions to create, read, update, and delete \nyour new CRD.\n\n::\n\n   install/kubernetes/cilium/templates/cilium-agent/clusterrole.yaml\n   install/kubernetes/cilium/templates/cilium-operator/clusterrole.yaml\n   install/kubernetes/cilium/templates/cilium-preflight/clusterrole.yaml\n\nHere is a diff of updating the Agent's cluster role template to include\nour new BGP CRDs:\n\n.. code-block:: diff\n\n   diff --git a/install/kubernetes/cilium/templates/cilium-agent/clusterrole.yaml b/install/kubernetes/cilium/templates/cilium-agent/clusterrole.yaml\n   index 9878401a81..5ba6c30cd7 100644\n   --- a/install/kubernetes/cilium/templates/cilium-agent/clusterrole.yaml\n   +++ b/install/kubernetes/cilium/templates/cilium-agent/clusterrole.yaml\n   @@ -102,6 +102,8 @@ rules:\n      - ciliumlocalredirectpolicies/finalizers\n      - ciliumendpointslices\n   +  - ciliumbgppeeringpolicies\n   +  - ciliumbgploadbalancerippools\n      verbs:\n      - '*'\n    {{- end }}\n\nIt's important to note, neither the Agent nor the Operator installs\nthese manifests to the Kubernetes clusters. This means when testing your\nCRD out the updated ``clusterrole`` must be written to the cluster\nmanually.\n\nAlso please note, you should be specific about which 'verbs' are added to the\nAgent's cluster role. \nThis ensures a good security posture and best practice.\n\nA convenient script for this follows:\n\n.. code-block:: bash\n\n   createTemplate(){\n       if [ -z \"${1}\" ]; then\n           echo \"Commit SHA not set\"\n           return\n       fi\n       ciliumVersion=${1}\n   MODIFY THIS LINE CD TO CILIUM ROOT DIR <-----\n   cd install/kubernetes\n   CILIUM_CI_TAG=\"${1}\"\n   helm template cilium ./cilium \\\n     --namespace kube-system \\\n     --set image.repository=quay.io/cilium/cilium-ci \\\n     --set image.tag=$CILIUM_CI_TAG \\\n     --set operator.image.repository=quay.io/cilium/operator \\\n     --set operator.image.suffix=-ci \\\n     --set operator.image.tag=$CILIUM_CI_TAG \\\n     --set clustermesh.apiserver.image.repository=quay.io/cilium/clustermesh-apiserver-ci \\\n     --set clustermesh.apiserver.image.tag=$CILIUM_CI_TAG \\\n     --set hubble.relay.image.repository=quay.io/cilium/hubble-relay-ci \\\n     --set hubble.relay.image.tag=$CILIUM_CI_TAG > /tmp/cilium.yaml\n   echo \"run kubectl apply -f /tmp/cilium.yaml\"\n   }\n\nThe above script with install Cilium and newest ``clusterrole``\nmanifests to anywhere your ``kubectl`` is pointed.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/contributing/development/introducing_new_crds.rst",
  "extracted_at": "2025-09-03T00:53:44.772088Z"
}
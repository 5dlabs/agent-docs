{
  "url": "file:///tmp/cilium-repo/Documentation/operations/performance/benchmark.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _performance_report:\n\n*************************\nCNI Performance Benchmark\n*************************\n\nIntroduction\n============\n\nThis chapter contains performance benchmark numbers for a variety of scenarios.\nAll tests are performed between containers running on two different bare metal\nnodes connected back-to-back by a 100Gbit/s network interface. Upon popular\nrequest we have included performance numbers for Calico for comparison.\n\n.. admonition:: Video\n  :class: attention\n\n  You can also watch Thomas Graf, Co-founder of Cilium, dive deep into this chapter\n  in `eCHO episode 5: Network performance benchmarking <https://www.youtube.com/watch?v=2lGag_j4dIw&t=377s>`__.\n\n.. tip::\n\n   To achieve these performance results, follow the :ref:`performance_tuning`.\n\nFor more information on the used system and configuration, see\n:ref:`test_hardware`. For more details on all tested configurations, see\n:ref:`test_configurations`.\n\nThe following metrics are collected and reported. Each metric represents a\ndifferent traffic pattern that can be required for workloads. See the specific\nsections for an explanation on what type of workloads are represented by each\nbenchmark.\n\nThroughput\n  Maximum transfer rate via a single TCP connection and the total transfer rate\n  of 32 accumulated connections.\n\nRequest/Response Rate\n  The number of request/response messages per second that can be transmitted over\n  a single TCP connection and over 32 parallel TCP connections.\n\nConnections Rate\n  The number of connections per second that can be established in sequence with\n  a single request/response payload message transmitted for each new connection. A\n  single process and 32 parallel processes are tested.\n\nFor the various benchmarks `netperf`_ has been used to generate the workloads\nand to collect the metrics. For spawning parallel netperf sessions,\n`super_netperf <https://raw.githubusercontent.com/borkmann/netperf_scripts/master/super_netperf>`_\nhas been used. Both netperf and super_netperf are also frequently used and well\nestablished tools for benchmarking in the Linux kernel networking community.\n\n.. _benchmark_throughput:\n\nTCP Throughput (TCP_STREAM)\n===========================\n\nThroughput testing (TCP_STREAM) is useful to understand the maximum throughput\nthat can be achieved with a particular configuration. All or most configurations\ncan achieve line-rate or close to line-rate if enough CPU resources are thrown\nat the load. It is therefore important to understand the amount of CPU resources\nrequired to achieve a certain throughput as these CPU resources will no longer\nbe available to workloads running on the machine.\n\nThis test represents bulk data transfer workloads, e.g. streaming services or\nservices performing data upload/download.\n\nSingle-Stream\n-------------\n\nIn this test, a single TCP stream is opened between the containers and maximum\nthroughput is achieved:\n\n.. image:: images/bench_tcp_stream_1_stream.png\n\nWe can see that eBPF-based solutions can outperform even the node-to-node\nbaseline on modern kernels despite performing additional work (forwarding\ninto the network namespace of the container, policy enforcement, ...). This is\nbecause eBPF is capable of bypassing the iptables layer of the node which is\nstill traversed for the node to node baseline.\n\nThe following graph shows the total CPU consumption across the entire system\nwhile running the benchmark, normalized to a 50Gbit throughput:\n\n.. image:: images/bench_tcp_stream_1_stream_cpu.png\n\n.. tip::\n\n   **Kernel wisdom:** TCP flow performance is limited by the receiver, since\n   sender can use both TSO super-packets. This can be observed in the increased\n   CPU spending on the server-side above above.\n\nMulti-Stream\n-------------\n\nIn this test, 32 processes are opening 32 parallel TCP connections. Each process\nis attempting to reach maximum throughput and the total is reported:\n\n.. image:: images/bench_tcp_stream_32_streams.png\n\nGiven multiple processes are being used, all test configurations can achieve\ntransfer rates close to the line-rate of the network interface. The main\ndifference is the CPU resources required to achieve it:\n\n.. image:: images/bench_tcp_stream_32_streams_cpu.png\n\n.. _request_response:\n\nRequest/Response Rate (TCP_RR)\n==============================\n\nThe request/response rate (TCP_RR) primarily measures the latency and\nefficiency to handle round-trip forwarding of an individual network packet.\nThis benchmark will lead to the most packets per second possible on the wire\nand stresses the cost performed by a network packet. This is the opposite of\nthe throughput test which maximizes the size of each network packet.\n\nA configuration that is doing well in this test (delivering high requests per\nsecond rates) will also deliver better (lower) network latencies.\n\nThis test represents services which maintain persistent connections and exchange\nrequest/response type interactions with other services. This is common for services\nusing REST or gRPC APIs.\n\n1 Process\n---------\n\nIn this test, a single TCP connection is opened between the containers and a\nsingle byte is sent back and forth between the containers. For each round-trip,\none request is counted:\n\n.. image:: images/bench_tcp_rr_1_process.png\n\neBPF on modern kernels can achieve almost the same request/response rate as the\nbaseline while only consuming marginally more CPU resources:\n\n.. image:: images/bench_tcp_rr_1_process_cpu.png\n\n32 Processes\n------------\n\nIn this test, 32 processes are opening 32 parallel TCP connections. Each process\nis performing single byte round-trips. The total number of requests per second\nis reported:\n\n.. image:: images/bench_tcp_rr_32_processes.png\n\nCilium can achieve close to 1M requests/s in this test while consuming about 30%\nof the system resources on both the sender and receiver:\n\n.. image:: images/bench_tcp_rr_32_processes_cpu.png\n\nConnection Rate (TCP_CRR)\n=========================\n\nThe connection rate (TCP_CRR) test measures the efficiency in handling new\nconnections. It is similar to the request/response rate test but will create a new\nTCP connection for each round-trip. This measures the cost of establishing a\nconnection, transmitting a byte in both directions, and closing the connection.\nThis is more expensive than the TCP_RR test and puts stress on the cost related\nto handling new connections.\n\nThis test represents a workload that receives or initiates a lot of TCP\nconnections. An example where this is the case is a publicly exposed service\nthat receives connections from many clients. Good examples of this are L4\nproxies or services opening many connections to external endpoints. This\nbenchmark puts the most stress on the system with the least work offloaded to\nhardware so we can expect to see the biggest difference between tested\nconfigurations.\n\nA configuration that does well in this test (delivering high connection rates)\nwill handle situations with overwhelming connection rates much better, leaving\nmore CPU resources available to workloads on the system.\n\n1 Process\n---------\n\nIn this test, a single process opens as many TCP connections as possible\nin sequence:\n\n.. image:: images/bench_tcp_crr_1_process.png\n\nThe following graph shows the total CPU consumption across the entire system\nwhile running the benchmark:\n\n.. image:: images/bench_tcp_crr_1_process_cpu.png\n\n.. tip::\n\n   **Kernel wisdom:** The CPU resources graph makes it obvious that some\n   additional kernel cost is paid at the sender as soon as network namespace\n   isolation is performed as all container workload benchmarks show signs of\n   this cost. We will investigate and optimize this aspect in a future release.\n\n32 Processes\n------------\n\nIn this test, 32 processes running in parallel open as many TCP connections in\nsequence as possible. This is by far the most stressful test for the system.\n\n.. image:: images/bench_tcp_crr_32_processes.png\n\nThis benchmark outlines major differences between the tested configurations. In\nparticular, it illustrates the overall cost of iptables which is optimized to\nperform most of the required work per connection and then caches the result.\nThis leads to a worst-case performance scenario when a lot of new connections\nare expected.\n\n.. note::\n\n   We have not been able to measure stable results for the Calico eBPF\n   datapath.  We are not sure why. The network packet flow was never steady. We\n   have thus not included the result. We invite the Calico team to work with us\n   to investigate this and then re-test.\n\nThe following graph shows the total CPU consumption across the entire system\nwhile running the benchmark:\n\n.. image:: images/bench_tcp_crr_32_processes_cpu.png\n\nEncryption (WireGuard/IPsec)\n============================\n\nCilium supports encryption via WireGuardÂ® and IPsec. This first section will\nlook at WireGuard and compare it against using Calico for WireGuard encryption.\nIf you are interested in IPsec performance and how it compares to WireGuard,\nplease see :ref:`performance_wireguard_ipsec`.\n\nWireGuard Throughput\n--------------------\n\nLooking at TCP throughput first, the following graph shows results for both\n1500 bytes MTU and 9000 bytes MTU:\n\n.. image:: images/bench_wireguard_tcp_1_stream.png\n\n.. note::\n\n   The Cilium eBPF kube-proxy replacement combined with WireGuard is currently\n   slightly slower than Cilium eBPF + kube-proxy. We have identified the\n   problem and will be resolving this deficit in one of the next releases.\n\nThe following graph shows the total CPU consumption across the entire system\nwhile running the WireGuard encryption benchmark:\n\n.. image:: images/bench_wireguard_tcp_1_stream_cpu.png\n\nWireGuard Request/Response\n--------------------------\n\nThe next benchmark measures the request/response rate while encrypting with\nWireGuard. See :ref:`request_response` for details on what this test actually\nentails.\n\n.. image:: images/bench_wireguard_rr_1_process.png\n\nAll tested configurations performed more or less the same. The following graph\nshows the total CPU consumption across the entire system while running the\nWireGuard encryption benchmark:\n\n.. image:: images/bench_wireguard_rr_1_process_cpu.png\n\n.. _performance_wireguard_ipsec:\n\nWireGuard vs IPsec\n------------------\n\nIn this section, we compare Cilium encryption using WireGuard and IPsec.\nWireGuard is able to achieve a higher maximum throughput:\n\n.. image:: images/bench_wireguard_ipsec_tcp_stream_1_stream.png\n\nHowever, looking at the CPU resources required to achieve 10Gbit/s of\nthroughput, WireGuard is less efficient at achieving the same throughput:\n\n.. image:: images/bench_wireguard_ipsec_tcp_stream_1_stream_cpu.png\n\n.. tip::\n\n   IPsec performing better than WireGuard in this test is unexpected in some\n   ways. A possible explanation is that the IPsec encryption is making use of\n   AES-NI instructions whereas the WireGuard implementation is not. This would\n   typically lead to IPsec being more efficient when AES-NI offload is\n   available and WireGuard being more efficient if the instruction set is not\n   available.\n\nLooking at the request/response rate, IPsec is outperforming WireGuard in our\ntests. Unlike for the throughput tests, the MTU does not have any effect as the\npacket sizes remain small:\n\n.. image:: images/bench_wireguard_ipsec_tcp_rr_1_process.png\n.. image:: images/bench_wireguard_ipsec_tcp_rr_1_process_cpu.png\n\nTest Environment\n================\n\n.. _test_hardware:\n\nTest Hardware\n-------------\n\nAll tests are performed using regular off-the-shelf hardware.\n\n============  ======================================================================================================================================================\nItem          Description\n============  ======================================================================================================================================================\nCPU           `AMD Ryzen 9 3950x <https://www.amd.com/en/support/cpu/amd-ryzen-processors/amd-ryzen-9-desktop-processors/amd-ryzen-9-3950x>`_, AM4 platform, 3.5GHz, 16 cores / 32 threads\nMainboard     `x570 Aorus Master <https://www.gigabyte.com/us/Motherboard/X570-AORUS-MASTER-rev-11-12/sp#sp>`_, PCIe 4.0 x16 support\nMemory        `HyperX Fury DDR4-3200 <https://www.hyperxgaming.com/us/memory/fury-ddr4>`_ 128GB, XMP clocked to 3.2GHz\nNetwork Card  `Intel E810-CQDA2 <https://ark.intel.com/content/www/us/en/ark/products/192558/intel-ethernet-network-adapter-e810-cqda2.html>`_, dual port, 100Gbit/s per port, PCIe 4.0 x16\nKernel        Linux 5.10 LTS, see also :ref:`performance_tuning`\n============  ======================================================================================================================================================\n\n.. _test_configurations:\n\nTest Configurations\n-------------------\n\nAll tests are performed using standardized configuration. Upon popular request,\nwe have included measurements for Calico for direct comparison.\n\n============================ ===================================================================\nConfiguration Name           Description\n============================ ===================================================================\nBaseline (Node to Node)      No Kubernetes\nCilium                       Cilium 1.9.6, eBPF host-routing, kube-proxy replacement, No CT\nCilium (legacy host-routing) Cilium 1.9.6, legacy host-routing, kube-proxy replacement, No CT\nCalico                       Calico 3.17.3, kube-proxy\nCalico eBPF                  Calico 3.17.3, eBPF datapath, No CT\n============================ ===================================================================\n\nHow to reproduce\n================\n\nTo ease reproducibility, this report is paired with a set of scripts that can\nbe found in `cilium/cilium-perf-networking <https://github.com/cilium/cilium-perf-networking>`_.\nAll scripts in this document refer to this repository. Specifically, we use\n`Terraform <https://www.terraform.io/>`_ and `Ansible\n<https://www.ansible.com/>`_ to setup the environment and execute benchmarks.\nWe use `Packet <https://deploy.equinix.com/>`_ bare metal servers as our hardware\nplatform, but the guide is structured so that it can be easily adapted to other\nenvironments.\n\nDownload the Cilium performance evaluation scripts:\n\n.. code-block:: shell-session\n\n  $ git clone https://github.com/cilium/cilium-perf-networking.git\n  $ cd cilium-perf-networking\n\nPacket Servers\n--------------\n\nTo evaluate both :ref:`arch_overlay` and :ref:`native_routing`, we configure\nthe Packet machines to use a `\"Mixed/Hybrid\"\n<https://deploy.equinix.com/developers/docs/metal/layer2-networking/overview/>`_ network\nmode, where the secondary interfaces of the machines share a flat L2 network.\nWhile this can be done on the Packet web UI, we include appropriate Terraform\n(version 0.13) files to automate this process.\n\n.. code-block:: shell-session\n\n  $ cd terraform\n  $ terraform init\n  $ terraform apply -var 'packet_token=API_TOKEN' -var 'packet_project_id=PROJECT_ID'\n  $ terraform output ansible_inventory  | tee ../packet-hosts.ini\n  $ cd ../\n\n\nThe above will provision two servers named ``knb-0`` and ``knb-1`` of type\n``c3.small.x86`` and configure them to use a \"Mixed/Hybrid\" network mode under a\ncommon VLAN named ``knb``.  The machines will be provisioned with an\n``ubuntu_20_04`` OS.  We also create a ``packet-hosts.ini`` file to use as an\ninventory file for Ansible.\n\nVerify that the servers are successfully provisioned by executing an ad-hoc ``uptime``\ncommand on the servers.\n\n.. code-block:: shell-session\n\n  $ cat packet-hosts.ini\n  [master]\n  136.144.55.223 ansible_python_interpreter=python3 ansible_user=root prv_ip=10.67.33.131 node_ip=10.33.33.10 master=knb-0\n  [nodes]\n  136.144.55.225 ansible_python_interpreter=python3 ansible_user=root prv_ip=10.67.33.133 node_ip=10.33.33.11\n  $ ansible -i packet-hosts.ini all -m shell -a 'uptime'\n  136.144.55.223 | CHANGED | rc=0 >>\n  09:31:43 up 33 min,  1 user,  load average: 0.00, 0.00, 0.00\n  136.144.55.225 | CHANGED | rc=0 >>\n    09:31:44 up 33 min,  1 user,  load average: 0.00, 0.00, 0.00\n\n\nNext, we use the ``packet-disbond.yaml`` playbook to configure the network\ninterfaces of the machines. This will destroy the ``bond0`` interface and\nconfigure the first physical interface with the public and private IPs\n(``prv_ip``) and the second with the node IP (``node_ip``) that will be used\nfor our evaluations (see `Packet documentation\n<https://deploy.equinix.com/developers/docs/metal/layer2-networking/overview/>`_ and our\nscripts for more info).\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -i packet-hosts.ini playbooks/packet-disbond.yaml\n\n\n.. note::\n\n    For hardware platforms other than Packet, users need to provide their own\n    inventory file (``packet-hosts.ini``) and follow the subsequent steps.\n\n\nInstall Required Software\n-------------------------\n\nInstall netperf (used for raw host-to-host measurements):\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -i packet-hosts.ini playbooks/install-misc.yaml\n\n\nInstall ``kubeadm`` and its dependencies:\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -i packet-hosts.ini playbooks/install-kubeadm.yaml\n\nWe use `kubenetbench <https://github.com/cilium/kubenetbench>`_ to execute the\n`netperf`_ benchmark in a Kubernetes environment. kubenetbench is a Kubernetes\nbenchmarking project that is agnostic to the CNI or networking plugin that the\ncluster is deployed with. In this report we focus on pod-to-pod communication\nbetween different nodes. To install kubenetbench:\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -i packet-hosts.ini playbooks/install-kubenetbench.yaml\n\n.. _netperf: https://github.com/HewlettPackard/netperf\n\nRunning Benchmarks\n------------------\n\n.. _tunneling_results:\n\nTunneling\n~~~~~~~~~\n\nConfigure Cilium in tunneling (:ref:`arch_overlay`) mode:\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -e mode=tunneling -i packet-hosts.ini playbooks/install-k8s-cilium.yaml\n  $ ansible-playbook -e conf=vxlan -i packet-hosts.ini playbooks/run-kubenetbench.yaml\n\nThe first command configures Cilium to use tunneling (``-e mode=tunneling``),\nwhich by default uses the VXLAN overlay.  The second executes our benchmark\nsuite (the ``conf`` variable is used to identify this benchmark run). Once\nexecution is done, a results directory will be copied back in a folder named\nafter the ``conf`` variable (in this case, ``vxlan``). This directory includes\nall the benchmark results as generated by kubenetbench, including netperf output\nand system information.\n\n.. _native_routing_results:\n\nNative Routing\n~~~~~~~~~~~~~~\n\nWe repeat the same operation as before, but configure Cilium to use\n:ref:`native_routing` (``-e mode=directrouting``).\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -e mode=directrouting -i packet-hosts.ini playbooks/install-k8s-cilium.yaml\n  $ ansible-playbook -e conf=routing -i packet-hosts.ini playbooks/run-kubenetbench.yaml\n\n.. _encryption_results:\n\nEncryption\n~~~~~~~~~~\n\nTo use encryption with native routing:\n\n.. code-block:: shell-session\n\n    $ ansible-playbook -e kubeproxyfree=disabled -e mode=directrouting -e encryption=yes -i packet-hosts.ini playbooks/install-k8s-cilium.yaml\n    $ ansible-playbook -e conf=encryption-routing -i packet-hosts.ini playbooks/run-kubenetbench.yaml\n\nBaseline\n~~~~~~~~\n\nTo have a point of reference for our results, we execute the same benchmarks\nbetween hosts without Kubernetes running. This provides an effective upper\nlimit to the performance achieved by Cilium.\n\n.. code-block:: shell-session\n\n  $ ansible-playbook -i packet-hosts.ini playbooks/reset-kubeadm.yaml\n  $ ansible-playbook -i packet-hosts.ini playbooks/run-rawnetperf.yaml\n\nThe first command removes Kubernetes and reboots the machines to ensure that there\nare no residues in the systems, whereas the second executes the same set of\nbenchmarks between hosts. An alternative would be to run the raw benchmark\nbefore setting up Cilium, in which case one would only need the second command.\n\nCleanup\n-------\n\nWhen done with benchmarking, the allocated Packet resources can be released with:\n\n.. code-block:: shell-session\n\n  $ cd terraform && terraform destroy -var 'packet_token=API_TOKEN' -var 'packet_project_id=PROJECT_ID'\n\n\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/operations/performance/benchmark.rst",
  "extracted_at": "2025-09-03T01:13:29.352218Z"
}
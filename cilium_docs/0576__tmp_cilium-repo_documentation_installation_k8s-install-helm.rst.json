{
  "url": "file:///tmp/cilium-repo/Documentation/installation/k8s-install-helm.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _k8s_install_helm:\n\n***********************\nInstallation using Helm\n***********************\n\nThis guide will show you how to install Cilium using `Helm\n<https://helm.sh/>`_. This involves a couple of additional steps compared to\nthe :ref:`k8s_quick_install` and requires you to manually select the best\ndatapath and IPAM mode for your particular environment.\n\nInstall Cilium\n==============\n\n.. include:: k8s-install-download-release.rst\n\n.. tabs::\n\n    .. group-tab:: Generic\n\n       These are the generic instructions on how to install Cilium into any\n       Kubernetes cluster using the default configuration options below. Please\n       see the other tabs for distribution/platform specific instructions which\n       also list the ideal default configuration for particular platforms.\n\n       **Default Configuration:**\n\n       =============== =============== ==============\n       Datapath        IPAM            Datastore\n       =============== =============== ==============\n       Encapsulation   Cluster Pool    Kubernetes CRD\n       =============== =============== ==============\n\n       .. include:: requirements-generic.rst\n\n       **Install Cilium:**\n\n       Deploy Cilium release via Helm:\n\n       .. parsed-literal::\n\n          helm install cilium |CHART_RELEASE| \\\\\n            --namespace kube-system\n\n    .. group-tab:: GKE\n\n       .. include:: requirements-gke.rst\n\n       **Install Cilium:**\n\n       Extract the Cluster CIDR to enable native-routing:\n\n       .. code-block:: shell-session\n\n          NATIVE_CIDR=\"$(gcloud container clusters describe \"${NAME}\" --zone \"${ZONE}\" --format 'value(clusterIpv4Cidr)')\"\n          echo $NATIVE_CIDR\n\n       Deploy Cilium release via Helm:\n\n       .. parsed-literal::\n\n          helm install cilium |CHART_RELEASE| \\\\\n            --namespace kube-system \\\\\n            --set nodeinit.enabled=true \\\\\n            --set nodeinit.reconfigureKubelet=true \\\\\n            --set nodeinit.removeCbrBridge=true \\\\\n            --set cni.binPath=/home/kubernetes/bin \\\\\n            --set gke.enabled=true \\\\\n            --set ipam.mode=kubernetes \\\\\n            --set ipv4NativeRoutingCIDR=$NATIVE_CIDR\n\n       The NodeInit DaemonSet is required to prepare the GKE nodes as nodes are added\n       to the cluster. The NodeInit DaemonSet will perform the following actions:\n\n       * Reconfigure kubelet to run in CNI mode\n       * Mount the eBPF filesystem\n\n    .. group-tab:: AKS\n\n       .. include:: ../installation/requirements-aks.rst\n\n       **Install Cilium:**\n\n       Deploy Cilium release via Helm:\n\n       .. parsed-literal::\n\n          helm install cilium |CHART_RELEASE| \\\\\n            --namespace kube-system \\\\\n            --set aksbyocni.enabled=true\n\n       .. note::\n\n          Installing Cilium via helm is supported only for AKS BYOCNI cluster and\n          not for Azure CNI Powered by Cilium clusters.\n\n    .. group-tab:: EKS\n\n       .. include:: requirements-eks.rst\n\n       **Patch VPC CNI (aws-node DaemonSet)**\n\n       Cilium will manage ENIs instead of VPC CNI, so the ``aws-node``\n       DaemonSet has to be patched to prevent conflict behavior.\n\n       .. code-block:: shell-session\n\n          kubectl -n kube-system patch daemonset aws-node --type='strategic' -p='{\"spec\":{\"template\":{\"spec\":{\"nodeSelector\":{\"io.cilium/aws-node-enabled\":\"true\"}}}}}'\n\n       **Install Cilium:**\n\n       Deploy Cilium release via Helm:\n\n       .. parsed-literal::\n\n          helm install cilium |CHART_RELEASE| \\\\\n            --namespace kube-system \\\\\n            --set eni.enabled=true\n\n       .. note::\n\n          This helm command sets ``eni.enabled=true``,\n          meaning that Cilium will allocate a fully-routable AWS ENI IP address\n          for each pod, similar to the behavior of the `Amazon VPC CNI plugin\n          <https://docs.aws.amazon.com/eks/latest/userguide/pod-networking.html>`_.\n\n          This mode depends on a set of :ref:`ec2privileges` from the EC2 API.\n\n          Cilium can alternatively run in EKS using an overlay mode that gives\n          pods non-VPC-routable IPs.  This allows running more pods per\n          Kubernetes worker node than the ENI limit but includes the following caveats:\n\n            1. Pod connectivity to resources outside the cluster (e.g., VMs in the VPC\n               or AWS managed services) is masqueraded (i.e., SNAT) by Cilium to use the\n               VPC IP address of the Kubernetes worker node.\n            2. The EKS API Server is unable to route packets to the overlay network. This\n               implies that any `webhook <https://kubernetes.io/docs/reference/access-authn-authz/webhook/>`_\n               which needs to be accessed must be host networked or exposed through a service\n               or ingress.\n\n          To set up Cilium overlay mode, follow the steps below:\n\n            1. Excluding the line ``eni.enabled=true`` from the helm command will configure Cilium to use\n               overlay routing mode (which is the helm default).\n            2. Flush iptables rules added by VPC CNI\n\n               .. code-block:: shell-session\n               \n                  iptables -t nat -F AWS-SNAT-CHAIN-0 \\\\\n                     && iptables -t nat -F AWS-SNAT-CHAIN-1 \\\\\n                     && iptables -t nat -F AWS-CONNMARK-CHAIN-0 \\\\\n                     && iptables -t nat -F AWS-CONNMARK-CHAIN-1\n\n    .. group-tab:: OpenShift\n\n       .. include:: requirements-openshift.rst\n\n       **Install Cilium:**\n\n       Cilium is a `Certified OpenShift CNI Plugin <https://access.redhat.com/articles/5436171>`_\n       and is best installed when an OpenShift cluster is created using the OpenShift\n       installer. Please refer to :ref:`k8s_install_openshift_okd` for more information.\n\n    .. group-tab:: RKE\n\n       .. include:: requirements-rke.rst\n\n    .. group-tab:: k3s\n\n       .. include:: requirements-k3s.rst\n\n       **Install Cilium:**\n\n       .. parsed-literal::\n\n          helm install cilium |CHART_RELEASE| \\\\\n             --namespace $CILIUM_NAMESPACE \\\\\n             --set operator.replicas=1\n\n    .. group-tab:: Rancher Desktop\n\n       **Configure Rancher Desktop:**\n\n       To install Cilium on `Rancher Desktop <https://rancherdesktop.io>`_,\n       perform the following steps:\n\n       .. include:: rancher-desktop-configure.rst\n\n       **Install Cilium:**\n\n       .. parsed-literal::\n\n          helm install cilium |CHART_RELEASE| \\\\\n             --namespace $CILIUM_NAMESPACE \\\\\n             --set operator.replicas=1 \\\\\n             --set cni.binPath=/usr/libexec/cni\n\n    .. group-tab:: Talos Linux\n\n       To install Cilium on `Talos Linux <https://www.talos.dev/>`_,\n       perform the following steps.\n\n       .. include:: k8s-install-talos-linux.rst\n\n    .. group-tab:: Alibaba ACK\n\n        .. include:: ../installation/alibabacloud-eni.rst\n\n.. admonition:: Video\n  :class: attention\n\n  If you'd like to learn more about Cilium Helm values, check out `eCHO episode 117: A Tour of the Cilium Helm Values <https://www.youtube.com/watch?v=ni0Uw4WLHYo>`__.\n\n.. include:: k8s-install-restart-pods.rst\n\n.. include:: k8s-install-validate.rst\n\n.. include:: next-steps.rst\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/installation/k8s-install-helm.rst",
  "extracted_at": "2025-09-03T01:13:29.308459Z"
}
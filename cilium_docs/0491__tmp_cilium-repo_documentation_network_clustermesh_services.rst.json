{
  "url": "file:///tmp/cilium-repo/Documentation/network/clustermesh/services.rst",
  "content": ".. _gs_clustermesh_services:\n\n**********************************\nLoad-balancing & Service Discovery\n**********************************\n\nThis tutorial will guide you to perform load-balancing and service\ndiscovery across multiple Kubernetes clusters when using Cilium.\n\nPrerequisites\n#############\n\nYou need to have a functioning Cluster Mesh setup, please follow the guide\n:ref:`gs_clustermesh` to set it up.\n\nLoad-balancing with Global Services\n###################################\n\nEstablishing load-balancing between clusters is achieved by defining a\nKubernetes service with identical name and namespace in each cluster and adding\nthe annotation ``service.cilium.io/global: \"true\"`` to declare it global.\nCilium will automatically perform load-balancing to pods in both clusters.\n\n.. code-block:: yaml\n\n  apiVersion: v1\n  kind: Service\n  metadata:\n    name: rebel-base\n    annotations:\n      service.cilium.io/global: \"true\"\n  spec:\n    type: ClusterIP\n    ports:\n    - port: 80\n    selector:\n      name: rebel-base\n\n\nDisabling Global Service Sharing\n################################\n\nBy default, a Global Service will load-balance across backends in multiple clusters.\nThis implicitly configures ``service.cilium.io/shared: \"true\"``. To prevent service\nbackends from being shared to other clusters, this option should be disabled.\n\nBelow example will expose remote endpoint without sharing local endpoints.\n\n.. code-block:: yaml\n\n   apiVersion: v1\n   kind: Service\n   metadata:\n     name: rebel-base\n     annotations:\n       service.cilium.io/global: \"true\"\n       service.cilium.io/shared: \"false\"\n   spec:\n     type: ClusterIP\n     ports:\n     - port: 80\n     selector:\n       name: rebel-base\n\n.. _endpointslicesync:\n\nSynchronizing Kubernetes EndpointSlice (Beta)\n#############################################\n\n.. include:: ../../beta.rst\n\nBy default Kubernetes EndpointSlice synchronization is disabled on non Headless Global services.\nTo have Cilium discover remote clusters endpoints of a Global Service\nfrom DNS or any third party controllers, enable synchronization by adding\nthe annotation ``service.cilium.io/global-sync-endpoint-slices: \"true\"``.\nThis will allow Cilium to create Kubernetes EndpointSlices belonging to a\nremote cluster for services that have that annotation.\nRegarding Global Headless services this option is enabled by default unless\nexplicitly opted-out by adding the annotation ``service.cilium.io/global-sync-endpoint-slices: \"false\"``.\n\nNote that this feature does not complement/is not required by any other Cilium features\nand is only required if you need to discover EndpointSlice from remote cluster on\nthird party controllers. For instance, the Cilium ingress controller works in a Cluster Mesh\nwithout enabling this feature, although if you use any other ingress controller\nyou may need to enable this.\n\nThis feature is currently disabled by default via a feature flag.\nTo install Cilium with EndpointSlice Cluster Mesh synchronization, run:\n\n.. parsed-literal::\n\n   helm install cilium |CHART_RELEASE| \\\\\n     --namespace kube-system \\\\\n     --set clustermesh.enableEndpointSliceSynchronization=true\n\nTo enable EndpointSlice Cluster Mesh synchronization on an existing Cilium installation, run:\n\n.. parsed-literal::\n\n   helm upgrade cilium |CHART_RELEASE| \\\\\n     --namespace kube-system \\\\\n     --reuse-values \\\\\n     --set clustermesh.enableEndpointSliceSynchronization=true\n   kubectl -n kube-system rollout restart deployment/cilium-operator\n\nKnown Limitations\n-----------------\n\n- This is a beta feature, you may experience bugs or shortcomings.\n- Hostnames are synchronized as is without any form of conflict resolution\n  mechanisms. This means that multiple StatefulSets with a single governing\n  Service that synchronize EndpointSlices across multiple clusters should have\n  different names. For instance, you can add the cluster name to the StatefulSet\n  name (``cluster1-my-statefulset`` instead of ``my-statefulset``).\n\n\nDeploying a Simple Example Service\n==================================\n\n1. In cluster 1, deploy:\n\n   .. parsed-literal::\n\n       kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/clustermesh/cluster1.yaml\n       kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/clustermesh/global-service-example.yaml\n\n2. In cluster 2, deploy:\n\n   .. parsed-literal::\n\n       kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/clustermesh/cluster2.yaml\n       kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/clustermesh/global-service-example.yaml\n\n3. From either cluster, access the global service:\n\n   .. code-block:: shell-session\n\n      kubectl exec -ti deployment/x-wing -- curl rebel-base\n\n   You will see replies from pods in both clusters.\n\n4. In cluster 1, add ``service.cilium.io/shared=\"false\"`` to existing global service\n\n   .. code-block:: shell-session\n\n      kubectl annotate service rebel-base service.cilium.io/shared=\"false\" --overwrite\n\n5. From cluster 1, access the global service one more time:\n\n   .. code-block:: shell-session\n\n      kubectl exec -ti deployment/x-wing -- curl rebel-base\n\n   You will still see replies from pods in both clusters.\n\n6. From cluster 2, access the global service again:\n\n   .. code-block:: shell-session\n\n      kubectl exec -ti deployment/x-wing -- curl rebel-base\n\n   You will see replies from pods only from cluster 2, as the global service in cluster 1 is no longer shared.\n\n7. In cluster 1, remove ``service.cilium.io/shared`` annotation of existing global service\n\n   .. code-block:: shell-session\n\n      kubectl annotate service rebel-base service.cilium.io/shared-\n\n8. From either cluster, access the global service:\n\n   .. code-block:: shell-session\n\n      kubectl exec -ti deployment/x-wing -- curl rebel-base\n\n   You will see replies from pods in both clusters again.\n\nGlobal and Shared Services Reference\n####################################\n\nThe flow chart below summarizes the overall behavior considering a service present\nin two clusters (i.e., Cluster1 and Cluster2), and different combinations of the\n``service.cilium.io/global`` and ``service.cilium.io/shared`` annotation values.\nThe terminating nodes represent the endpoints used in each combination by the two\nclusters for the service under examination.\n\n.. image:: images/services_flowchart.svg\n\n..\n   The flow chart was generated on https://mermaid.live with code:\n\n   flowchart LR\n      Cluster1Global{Cluster1\\nGlobal?}-->|yes|Cluster2Global{Cluster2\\nGlobal?}\n      Cluster2Global-->|yes|Cluster1Shared{Cluster1\\nShared?}\n\n      Cluster1Shared-->|yes|Cluster2Shared{Cluster2\\nShared?}\n      Cluster2Shared-->|yes|Cluster1BothCluster2Both[Cluster1: Local + Remote\\nCluster2: Local + Remote]\n      Cluster2Shared-->|no|Cluster1SelfClusterBoth[Cluster1: Local only\\nCluster2: Local + Remote]\n\n      Cluster1Shared-->|no|Cluster2Shared2{Cluster2\\nShared?}\n      Cluster2Shared2-->|yes|Cluster1BothCluster2Self[Cluster1: Local + Remote\\nCluster2: Local only]\n      Cluster2Shared2-->|no|Cluster1SelfCluster2Self[Cluster1: Local only\\nCluster2: Local only]\n\n      Cluster1Global-->|no|Cluster1SelfCluster2Self\n      Cluster2Global-->|no|Cluster1SelfCluster2Self\n\nLimitations\n###########\n\n* Global NodePort services load balance across both local and remote backends only\n  if Cilium is configured to replace kube-proxy (``kubeProxyReplacement=true``).\n  Otherwise, only local backends are eligible for\n  load balancing when accessed through the NodePort.\n\n* Global services accessed by a Node, or a Pod running in host network, load\n  balance across both local and remote backends only if Cilium is configured\n  to replace kube-proxy (``kubeProxyReplacement=true``). This limitation can be\n  overcome enabling SocketLB in the host namespace: ``socketLB.enabled=true``,\n  ``socketLB.hostNamespaceOnly=true``. Otherwise, only local backends are eligible\n  for load balancing.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/network/clustermesh/services.rst",
  "extracted_at": "2025-09-03T01:13:29.195779Z"
}
{
  "url": "file:///tmp/cilium-repo/Documentation/network/servicemesh/mutual-authentication/mutual-authentication-example.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _gs_mutual_authentication_example:\n\n*****************************\nMutual Authentication Example\n*****************************\n\nThis example shows you how to enforce mutual authentication between two Pods. \n\nDeploy a client (pod-worker) and a server (echo) using the following manifest:\n\n.. parsed-literal::\n\n    $ kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/servicemesh/mutual-auth-example.yaml\n    $ kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/servicemesh/cnp-without-mutual-auth.yaml\n    service/echo created\n    deployment.apps/echo created\n    pod/pod-worker created\n    ciliumnetworkpolicy.cilium.io/no-mutual-auth-echo created \n\nVerify that the Pods have been successfully deployed:\n\n.. code-block:: shell-session\n\n    $ kubectl get svc echo\n    NAME   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE\n    echo   ClusterIP   10.96.16.90   <none>        3000/TCP   42m\n    $ kubectl get pod pod-worker \n    NAME         READY   STATUS    RESTARTS   AGE\n    pod-worker   1/1     Running   0          40m\n\nVerify that the network policy has been deployed successfully and filters the traffic as expected. \n\nRun the following commands:\n\n.. code-block:: shell-session\n\n    $ kubectl exec -it pod-worker -- curl -s -o /dev/null -w \"%{http_code}\" http://echo:3000/headers\n    200\n    $ kubectl exec -it pod-worker -- curl http://echo:3000/headers-1\n    Access denied\n\nThe first request should be successful (the *pod-worker* Pod is able to connect to the *echo* Service over a specific HTTP path and the HTTP status code is ``200``).\nThe second one should be denied (the *pod-worker* Pod is unable to connect to the *echo* Service over a specific HTTP path other than '/headers').\n\nBefore we enable mutual authentication between ``pod-worker`` and ``echo``, let's verify that the SPIRE server is healthy.\n\nAssuming you have followed the installation instructions and have a SPIRE server serving Cilium, adding mutual authentication simply requires \nadding ``authentication.mode: \"required\"`` in the ingress/egress block in your network policies.\n\n\nVerify SPIRE Health\n===================\n\n.. note::\n\n    This example assumes a default SPIRE installation.\n\nLet's first verify that the SPIRE server and agents automatically deployed are working as expected.\n\nThe SPIRE server is deployed as a StatefulSet and the SPIRE agents are deployed as a DaemonSet (you should therefore see one SPIRE agent per node).\n\n.. code-block:: shell-session\n\n    $ kubectl get all -n cilium-spire\n    NAME                    READY   STATUS    RESTARTS   AGE\n    pod/spire-agent-27jd7   1/1     Running   0          144m\n    pod/spire-agent-qkc8l   1/1     Running   0          144m\n    pod/spire-server-0      2/2     Running   0          144m\n\n    NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\n    service/spire-server   ClusterIP   10.96.124.177   <none>        8081/TCP   144m\n\n    NAME                         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\n    daemonset.apps/spire-agent   2         2         2       2            2           <none>          144m\n\n    NAME                            READY   AGE\n    statefulset.apps/spire-server   1/1     144m\n        \nRun a healthcheck on the SPIRE server.\n\n.. code-block:: shell-session\n\n    $ kubectl exec -n cilium-spire spire-server-0 -c spire-server -- /opt/spire/bin/spire-server healthcheck\n    Server is healthy.\n\nVerify the list of attested agents:\n\n.. code-block:: shell-session\n\n    $ kubectl exec -n cilium-spire spire-server-0 -c spire-server -- /opt/spire/bin/spire-server agent list\n    Found 2 attested agents:\n\n    SPIFFE ID         : spiffe://spiffe.cilium/spire/agent/k8s_psat/default/64745bf2-bd9d-4e42-bb2b-e095a6b65121\n    Attestation type  : k8s_psat\n    Expiration time   : 2023-07-04 18:39:50 +0000 UTC\n    Serial number     : 110848236251310359782141595494072495768\n\n    SPIFFE ID         : spiffe://spiffe.cilium/spire/agent/k8s_psat/default/d4a8a6da-d808-4993-b67a-bed250bbc53e\n    Attestation type  : k8s_psat\n    Expiration time   : 2023-07-04 18:39:55 +0000 UTC\n    Serial number     : 7806033782886940845084156064765627978\n\nNotice that the SPIRE Server uses Kubernetes Projected Service Account Tokens (PSATs) to verify \nthe Identity of a SPIRE Agent running on a Kubernetes Cluster. \nProjected Service Account Tokens provide additional security guarantees over traditional Kubernetes\nService Account Tokens and when supported by a Kubernetes cluster, PSAT is the recommended attestation strategy.\n\nVerify SPIFFE Identities\n========================\n\nNow that we know the SPIRE service is healthy, let's verify that the Cilium and SPIRE integration has been successful:\n\n- The Cilium agent and operator should have a registered delegate Identity with the SPIRE Server.\n- The Cilium operator should have registered Identities with the SPIRE server on behalf of the workloads (Kubernetes Pods).\n\nVerify that the Cilium agent and operator have Identities on the SPIRE server:\n\n.. code-block:: shell-session\n\n    $ kubectl exec -n cilium-spire spire-server-0 -c spire-server -- /opt/spire/bin/spire-server entry show -parentID spiffe://spiffe.cilium/ns/cilium-spire/sa/spire-agent\n    Found 2 entries\n    Entry ID         : b6424c87-4323-4d64-98dd-cd5b51a1fcbb\n    SPIFFE ID        : spiffe://spiffe.cilium/cilium-agent\n    Parent ID        : spiffe://spiffe.cilium/ns/cilium-spire/sa/spire-agent\n    Revision         : 0\n    X509-SVID TTL    : default\n    JWT-SVID TTL     : default\n    Selector         : k8s:ns:kube-system\n    Selector         : k8s:sa:cilium\n\n    Entry ID         : 8aa91d65-16c4-48a0-bc1f-c9bf26e6a25f\n    SPIFFE ID        : spiffe://spiffe.cilium/cilium-operator\n    Parent ID        : spiffe://spiffe.cilium/ns/cilium-spire/sa/spire-agent\n    Revision         : 0\n    X509-SVID TTL    : default\n    JWT-SVID TTL     : default\n    Selector         : k8s:ns:kube-system\n    Selector         : k8s:sa:cilium-operator\n\n\nNext, verify that the *echo* Pod has an Identity registered with the SPIRE server.\n\nTo do this, you must first construct the Pod's SPIFFE ID. The SPIFFE ID for a workload is \nbased on the ``spiffe://spiffe.cilium/identity/$IDENTITY_ID`` format, where ``$IDENTITY_ID`` is a workload's Cilium Identity.\n\nGrab the Cilium Identity for the *echo* Pod;\n\n.. code-block:: shell-session\n\n    $ IDENTITY_ID=$(kubectl get cep -l app=echo -o=jsonpath='{.items[0].status.identity.id}')\n    $ echo $IDENTITY_ID\n    17947\n\nUse the Cilium Identity for the *echo* pod to construct its SPIFFE ID and check it is registered on the SPIRE server:\n\n.. code-block:: shell-session\n\n    $ kubectl exec -n cilium-spire spire-server-0 -c spire-server -- /opt/spire/bin/spire-server entry show -spiffeID spiffe://spiffe.cilium/identity/$IDENTITY_ID\n    Found 1 entry\n    Entry ID         : 9fc13971-fb19-4814-b9f0-737b30e336c6\n    SPIFFE ID        : spiffe://spiffe.cilium/identity/17947\n    Parent ID        : spiffe://spiffe.cilium/cilium-operator\n    Revision         : 0\n    X509-SVID TTL    : default\n    JWT-SVID TTL     : default\n    Selector         : cilium:mutual-auth\n\nYou can see the that the *cilium-operator* was listed in the ``Parent ID``. \nThat is because the Cilium operator creates SPIRE entries for Cilium Identities as they are created.\n\nTo get all registered entries, execute the following command:\n\n.. code-block:: shell-session\n\n    kubectl exec -n cilium-spire spire-server-0 -c spire-server -- /opt/spire/bin/spire-server entry show -selector cilium:mutual-auth\n\nThere are as many entries as there are identities. Verify that these match by running the command:\n\n.. code-block:: shell-session\n    \n    kubectl get ciliumidentities\n\nThe identify ID listed under ``NAME`` should match with the digits at the end of the SPIFFE ID executed in the previous command.\n\n\nEnforce Mutual Authentication\n=============================\n\nRolling out mutual authentication with Cilium is as simple as adding the following block to an existing or new CiliumNetworkPolicy egress or ingress rules:\n\n.. code-block:: yaml\n\n    authentication:\n        mode: \"required\"\n\nUpdate the existing rule to only allow ingress access to mutually authenticated workloads to access *echo* using:\n\n.. parsed-literal::\n\n    $ kubectl apply -f \\ |SCM_WEB|\\/examples/kubernetes/servicemesh/cnp-with-mutual-auth.yaml\n\nVerify Mutual Authentication\n============================\n\nStart by enabling debug level:\n\n.. code-block:: shell-session\n\n    cilium config set debug true\n\nRe-try your connectivity tests. They should give similar results as before:\n\n.. code-block:: shell-session\n\n    $ kubectl exec -it pod-worker -- curl -s -o /dev/null -w \"%{http_code}\" http://echo:3000/headers\n    200\n    $ kubectl exec -it pod-worker -- curl http://echo:3000/headers-1\n    Access denied\n\nVerify that mutual authentication has happened by accessing the logs on the agent. \n\nExamine the logs on the Cilium agent located in the same node as the *echo* Pod. \nFor brevity, you can search for some specific log messages by label:\n\n.. code-block:: shell-session\n\n    $ kubectl -n kube-system -c cilium-agent logs -l k8s-app=cilium --timestamps=true | grep \"Policy is requiring authentication\\|Validating Server SNI\\|Validated certificate\\|Successfully authenticated\"\n    2023-07-04T17:58:28.795760597Z level=debug msg=\"Policy is requiring authentication\" key=\"localIdentity=17947, remoteIdentity=39239, remoteNodeID=54264, authType=spire\" subsys=auth\n    2023-07-04T17:58:28.800509503Z level=debug msg=\"Validating Server SNI\" SNI ID=39239 subsys=auth\n    2023-07-04T17:58:28.800525190Z level=debug msg=\"Validated certificate\" subsys=auth uri-san=\"[spiffe://spiffe.cilium/identity/39239]\"\n    2023-07-04T17:58:28.801441968Z level=debug msg=\"Successfully authenticated\" key=\"localIdentity=17947, remoteIdentity=39239, remoteNodeID=54264, authType=spire\" remote_node_ip=10.0.1.175 subsys=auth\n\nWhen you apply a mutual authentication policy, the agent retrieves the identity of the source Pod, \nconnects to the node where the destination Pod is running and performs a mutual TLS handshake (with \nthe log above showing one side of the mutual TLS handshake).\nAs the handshake succeeded, the connection was authenticated and the traffic protected by policy could proceed. \n\nPackets between the two Pods can flow until the network policy is removed or the entry expires.\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/network/servicemesh/mutual-authentication/mutual-authentication-example.rst",
  "extracted_at": "2025-09-03T01:13:29.142634Z"
}
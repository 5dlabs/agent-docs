{
  "url": "file:///tmp/cilium-repo/Documentation/gettingstarted/k8s-install-default.rst",
  "content": ".. only:: not (epub or latex or html) \n WARNING: You are looking at unreleased Cilium documentation.\nPlease use the official rendered version released here:\nhttps://docs.cilium.io\n \n .. _k8s_install_quick:\n.. _k8s_quick_install:\n.. _k8s_install_standard: \n \n Cilium Quick Installation \n \n This guide will walk you through the quick default installation. It will\nautomatically detect and use the best configuration possible for the Kubernetes\ndistribution you are using. All state is stored using Kubernetes custom resource definitions (CRDs). \n This is the best installation method for most use cases.  For large\nenvironments (> 500 nodes) or if you want to run specific datapath modes, refer\nto the :ref: getting_started  guide. \n Should you encounter any issues during the installation, please refer to the\n:ref: troubleshooting_k8s  section and/or seek help on  Cilium Slack _. \n .. _create_cluster: \n Create the Cluster \n If you don't have a Kubernetes Cluster yet, you can use the instructions below\nto create a Kubernetes cluster locally or using a managed Kubernetes service: \n .. tabs:: \n .. group-tab:: GKE\n\n   The following commands create a Kubernetes cluster using `Google\n   Kubernetes Engine <https://cloud.google.com/kubernetes-engine>`_.  See\n   `Installing Google Cloud SDK <https://cloud.google.com/sdk/install>`_\n   for instructions on how to install ``gcloud`` and prepare your\n   account.\n\n   .. code-block:: bash\n\n       export NAME=\"$(whoami)-$RANDOM\"\n       # Create the node pool with the following taint to guarantee that\n       # Pods are only scheduled/executed in the node when Cilium is ready.\n       # Alternatively, see the note below.\n       gcloud container clusters create \"${NAME}\" \\\n        --node-taints node.cilium.io/agent-not-ready=true:NoExecute \\\n        --zone us-west2-a\n       gcloud container clusters get-credentials \"${NAME}\" --zone us-west2-a\n\n   .. note::\n\n      Please make sure to read and understand the documentation page on :ref:`taint effects and unmanaged pods<taint_effects>`.\n\n.. group-tab:: AKS\n\n   The following commands create a Kubernetes cluster using `Azure\n   Kubernetes Service <https://docs.microsoft.com/en-us/azure/aks/>`_ with\n   no CNI plugin pre-installed (BYOCNI). See `Azure Cloud CLI\n   <https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest>`_\n   for instructions on how to install ``az`` and prepare your account, and\n   the `Bring your own CNI documentation\n   <https://docs.microsoft.com/en-us/azure/aks/use-byo-cni?tabs=azure-cli>`_\n   for more details about BYOCNI prerequisites / implications.\n\n   .. code-block:: bash\n\n       export NAME=\"$(whoami)-$RANDOM\"\n       export AZURE_RESOURCE_GROUP=\"${NAME}-group\"\n       az group create --name \"${AZURE_RESOURCE_GROUP}\" -l westus2\n\n       # Create AKS cluster\n       az aks create \\\n         --resource-group \"${AZURE_RESOURCE_GROUP}\" \\\n         --name \"${NAME}\" \\\n         --network-plugin none \\\n         --generate-ssh-keys\n\n       # Get the credentials to access the cluster with kubectl\n       az aks get-credentials --resource-group \"${AZURE_RESOURCE_GROUP}\" --name \"${NAME}\"\n\n.. group-tab:: EKS\n\n   The following commands create a Kubernetes cluster with ``eksctl``\n   using `Amazon Elastic Kubernetes Service\n   <https://aws.amazon.com/eks/>`_.  See `eksctl Installation\n   <https://github.com/weaveworks/eksctl>`_ for instructions on how to\n   install ``eksctl`` and prepare your account.\n\n   .. code-block:: none\n\n       export NAME=\"$(whoami)-$RANDOM\"\n       cat <<EOF >eks-config.yaml\n       apiVersion: eksctl.io/v1alpha5\n       kind: ClusterConfig\n\n       metadata:\n         name: ${NAME}\n         region: eu-west-1\n\n       managedNodeGroups:\n       - name: ng-1\n         desiredCapacity: 2\n         privateNetworking: true\n         # taint nodes so that application pods are\n         # not scheduled/executed until Cilium is deployed.\n         # Alternatively, see the note below.\n         taints:\n          - key: \"node.cilium.io/agent-not-ready\"\n            value: \"true\"\n            effect: \"NoExecute\"\n       EOF\n       eksctl create cluster -f ./eks-config.yaml\n\n   .. note::\n\n      Please make sure to read and understand the documentation page on :ref:`taint effects and unmanaged pods<taint_effects>`.\n\n.. group-tab:: kind\n\n   Install ``kind`` >= v0.7.0 per kind documentation:\n   `Installation and Usage <https://kind.sigs.k8s.io/#installation-and-usage>`_\n\n   .. parsed-literal::\n\n      curl -LO \\ |SCM_WEB|\\/Documentation/installation/kind-config.yaml\n      kind create cluster --config=kind-config.yaml\n\n   .. note::\n\n     Cilium may fail to deploy due to too many open files in one or more\n     of the agent pods. If you notice this error, you can increase the\n     ``inotify`` resource limits on your host machine (see\n     `Pod errors due to \"too many open files\" <https://kind.sigs.k8s.io/docs/user/known-issues/#pod-errors-due-to-too-many-open-files>`__).\n\n.. group-tab:: minikube\n\n   Install minikube ≥ v1.28.0 as per minikube documentation:\n   `Install Minikube <https://kubernetes.io/docs/tasks/tools/install-minikube/>`_.\n   The following command will bring up a single node minikube cluster prepared for installing cilium.\n\n   .. code-block:: shell-session\n\n      minikube start --cni=cilium\n\n   .. note::\n\n      - This may not install the latest version of cilium.\n      - It might be necessary to add ``--host-dns-resolver=false`` if using the Virtualbox provider,\n        otherwise DNS resolution may not work after Cilium installation.\n\n.. group-tab:: Kubespray\n\n   `Kubespray <https://github.com/kubernetes-sigs/kubespray>`_ requires Python ≥ 3.10 for recent versions. \n   For environment setup and dependencies installation, see the `Kubespray Ansible documentation <https://github.com/kubernetes-sigs/kubespray/blob/master/docs/ansible/ansible.md#installing-ansible>`_.\n\n   **Configure cluster:**\n\n   .. code-block:: bash\n\n       # Enter the already cloned kubespray directory\n       cd kubespray/\n       \n       # Copy sample inventory\n       cp -rfp inventory/sample inventory/mycluster\n       \n       # Configure your inventory\n       vi inventory/mycluster/inventory.ini\n       \n       # Configure Kubernetes networking:\n       # Use CNI without any network plugin\n       sed -e 's/^kube_network_plugin:.*$/kube_network_plugin: cni/' \\\n           -e 's/^kube_owner:.*$/kube_owner: root/' \\\n           inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml > k8s-cluster.tmp\n       mv k8s-cluster.tmp inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml\n\n   Setting ``kube_network_plugin: cni`` ensures the cluster deploys without any network plugin, allowing Cilium to be installed separately afterward.\n\n   **Deploy cluster:**\n\n   .. code-block:: bash\n\n       ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b -v \\\n         --private-key=~/.ssh/private_key\n\n   (Adjust the path to your private SSH key.)\n\n   .. note::\n\n      For more detailed configuration options, refer to the `Kubespray documentation <https://github.com/kubernetes-sigs/kubespray/blob/master/docs/ansible/vars.md>`_.\n\n.. group-tab:: Rancher Desktop\n\n   Install Rancher Desktop >= v1.1.0 as per Rancher Desktop documentation:\n   `Install Rancher Desktop <https://docs.rancherdesktop.io/getting-started/installation>`_.\n\n   Next you need to configure Rancher Desktop to disable the built-in CNI so you can install Cilium.\n\n   .. include:: ../installation/rancher-desktop-configure.rst\n\n.. group-tab:: Alibaba ACK\n\n    .. include:: ../beta.rst\n\n    .. note::\n\n        The AlibabaCloud ENI integration with Cilium is subject to the following limitations:\n\n        - It is currently only enabled for IPv4.\n        - It only works with instances supporting ENI. Refer to `Instance families <https://www.alibabacloud.com/help/doc-detail/25378.htm>`_ for details.\n\n    Setup a Kubernetes on AlibabaCloud. You can use any method you prefer.\n    The quickest way is to create an ACK (Alibaba Cloud Container Service for\n    Kubernetes) cluster and to replace the CNI plugin with Cilium.\n    For more details on how to set up an ACK cluster please follow\n    the `official documentation <https://www.alibabacloud.com/help/doc-detail/86745.htm>`_.\n \n .. _install_cilium_cli: \n Install the Cilium CLI \n .. include:: ../installation/cli-download.rst \n .. admonition:: Video\n:class: attention \n To learn more about the Cilium CLI, check out  eCHO episode 8: Exploring the Cilium CLI <https://www.youtube.com/watch?v=ndjmaM1i0WQ&t=1136s> __. \n Install Cilium \n You can install Cilium on any Kubernetes cluster. Pick one of the options below: \n .. tabs:: \n .. group-tab:: Generic\n\n   These are the generic instructions on how to install Cilium into any\n   Kubernetes cluster. The installer will attempt to automatically pick the\n   best configuration options for you. Please see the other tabs for\n   distribution/platform specific instructions which also list the ideal\n   default configuration for particular platforms.\n\n   .. include:: ../installation/requirements-generic.rst\n\n   **Install Cilium**\n\n   Install Cilium into the Kubernetes cluster pointed to by your current kubectl context:\n\n   .. parsed-literal::\n\n      cilium install |CHART_VERSION|\n\n.. group-tab:: GKE\n\n   .. include:: ../installation/requirements-gke.rst\n\n   **Install Cilium:**\n\n   Install Cilium into the GKE cluster:\n\n   .. parsed-literal::\n\n       cilium install |CHART_VERSION|\n\n.. group-tab:: AKS\n   \n   .. include:: ../installation/requirements-aks.rst\n\n   **Install Cilium:**\n\n   Install Cilium into the AKS cluster:\n\n   .. parsed-literal::\n\n       cilium install |CHART_VERSION| --set azure.resourceGroup=\"${AZURE_RESOURCE_GROUP}\"\n       \n.. group-tab:: EKS\n\n   .. include:: ../installation/requirements-eks.rst\n\n   **Install Cilium:**\n\n   Install Cilium into the EKS cluster.\n\n   .. parsed-literal::\n\n       cilium install |CHART_VERSION|\n       cilium status --wait\n\n   .. note::\n\n       If you have to uninstall Cilium and later install it again, that could cause\n       connectivity issues due to ``aws-node`` DaemonSet flushing Linux routing tables.\n       The issues can be fixed by restarting all pods, alternatively to avoid such issues\n       you can delete ``aws-node`` DaemonSet prior to installing Cilium.\n\n.. group-tab:: OpenShift\n\n   .. include:: ../installation/requirements-openshift.rst\n\n   **Install Cilium:**\n\n   Cilium is a `Certified OpenShift CNI Plugin <https://access.redhat.com/articles/5436171>`_\n   and is best installed when an OpenShift cluster is created using the OpenShift\n   installer. Please refer to :ref:`k8s_install_openshift_okd` for more information.\n\n.. group-tab:: RKE\n\n   .. include:: ../installation/requirements-rke.rst\n\n   **Install Cilium:**\n\n   Install Cilium into your newly created RKE cluster:\n\n   .. parsed-literal::\n\n       cilium install |CHART_VERSION|\n\n.. group-tab:: k3s\n\n   .. include:: ../installation/requirements-k3s.rst\n\n   **Install Cilium:**\n\n   Install Cilium into your newly created Kubernetes cluster:\n\n   .. parsed-literal::\n\n       cilium install |CHART_VERSION|\n\n.. group-tab:: Alibaba ACK\n\n   You can install Cilium using Helm on Alibaba ACK, refer to `k8s_install_helm` for details.\n \n If the installation fails for some reason, run  cilium status  to retrieve\nthe overall status of the Cilium deployment and inspect the logs of whatever\npods are failing to be deployed. \n .. tip:: \n You may be seeing  cilium install  print something like this: \n .. code-block:: shell-session \n    ♻️  Restarted unmanaged pod kube-system/event-exporter-gke-564fb97f9-rv8hg\n   ♻️  Restarted unmanaged pod kube-system/kube-dns-6465f78586-hlcrz\n   ♻️  Restarted unmanaged pod kube-system/kube-dns-autoscaler-7f89fb6b79-fsmsg\n   ♻️  Restarted unmanaged pod kube-system/l7-default-backend-7fd66b8b88-qqhh5\n   ♻️  Restarted unmanaged pod kube-system/metrics-server-v0.3.6-7b5cdbcbb8-kjl65\n   ♻️  Restarted unmanaged pod kube-system/stackdriver-metadata-agent-cluster-level-6cc964cddf-8n2rt\n \n This indicates that your cluster was already running some pods before Cilium\nwas deployed and the installer has automatically restarted them to ensure\nall pods get networking provided by Cilium. \n Validate the Installation \n .. include:: ../installation/cli-status.rst\n.. include:: ../installation/cli-connectivity-test.rst \n .. include:: ../installation/next-steps.rst",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/gettingstarted/k8s-install-default.rst",
  "extracted_at": "2025-09-03T01:13:29.364850Z"
}
{
  "url": "file:///tmp/cilium-repo/Documentation/security/network/proxy/envoy.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n.. _envoy:\n\n=====\nEnvoy\n=====\n\nEnvoy proxy shipped with Cilium is built with minimal Envoy extensions and custom policy enforcement filters.\nCilium uses this minimal distribution as its host proxy for enforcing HTTP and other L7 policies as specified in network policies\nfor the cluster. Cilium proxy is distributed within the Cilium images.\n\nFor more information on the version compatibility matrix, see `Cilium Proxy documentation <https://github.com/cilium/proxy#version-compatibility-matrix>`_.\n\n***********************\nDeployment as DaemonSet\n***********************\n\nBackground\n==========\n\nWhen Cilium L7 functionality (Ingress, Gateway API, Network Policies with L7 functionality, L7 Protocol Visibility)\nis enabled or installed in a Kubernetes cluster, the Cilium agent starts an Envoy proxy as separate process within\nthe Cilium agent pod.\n\nThat Envoy proxy instance becomes responsible for proxying all matching L7 requests on that node.\nAs a result, L7 traffic targeted by policies depends on the availability of the Cilium agent pod.\n\nAlternatively, it's possible to deploy the Envoy proxy as independently life-cycled DaemonSet called ``cilium-envoy``\ninstead of running it from within the Cilium Agent Pod.\n\nThe communication between Cilium agent and Envoy proxy takes place via UNIX domain sockets in both deployment modes.\nBe that streaming the access logs (e.g. L7 Protocol Visibility), updating the configuration via\n`xDS <https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol>`_ or accessing the admin interface.\nDue to the use of UNIX domain sockets, Envoy DaemonSet and the Cilium Agent need to have compatible types when SELinux is enabled on the host. This is the case if not specified otherwise, both using the highly privileged type: ``spc_t``. SELinux is enabled by default on Red Hat OpenShift Container Platform.\n\nEnable and configure Envoy DaemonSet\n====================================\n\nTo enable the dedicated Envoy proxy DaemonSet, install Cilium with the Helm value ``envoy.enabled`` set to ``true``.\n\nPlease see the :ref:`helm_reference` (keys with ``envoy.*``) for detailed information on how to configure the Envoy proxy DaemonSet.\n\nPotential Benefits\n==================\n\n- Cilium Agent restarts (e.g. for upgrades) without impacts for the live traffic proxied via Envoy.\n- Envoy patch release upgrades without impacts for the Cilium Agent.\n- Separate CPU and memory limits for Envoy and Cilium Agent for performance isolation.\n- Envoy application log not mixed with the one of the Cilium Agent.\n- Dedicated health probes for the Envoy proxy.\n- Explicit deployment of Envoy proxy during Cilium installation (compared to on demand in the embedded mode).\n\n.. admonition:: Video\n :class: attention\n\n  If you'd like to see Cilium Envoy in action, check out `eCHO episode 127: Cilium & Envoy <https://www.youtube.com/watch?v=HEwruycGbCU>`__.\n\n*************\nGo Extensions\n*************\n\n.. note:: This feature is currently in beta phase.\n\n.. note:: The Go extensions proxylib framework is residing in cilium/proxy repository.\n\nThis is a guide for developers who are interested in writing a Go extension to the \nEnvoy proxy as part of Cilium.   \n\n.. image:: _static/proxylib_logical_flow.png\n\nAs depicted above, this framework allows a developer to write a small amount of Go\ncode (green box) focused on parsing a new API protocol, and this Go code is able to  \ntake full advantage of Cilium features including high-performance redirection to/from Envoy, \nrich L7-aware policy language\nand access logging, and visibility into encrypted traffic via kTLS (coming soon!).\nIn sum, you as the developer need only worry about the logic of parsing the protocol, \nand Cilium + Envoy + eBPF do the heavy-lifting.  \n\nThis guide uses simple examples based on a hypothetical \"r2d2\" protocol \n(see `proxylib/r2d2/r2d2parser.go <https://github.com/cilium/proxy/blob/main/proxylib/r2d2/r2d2parser.go>`_)\nthat might be used to talk to a simple protocol droid a long time ago in a galaxy far, far away.   \nBut it also points to other real protocols like Memcached and Cassandra that already exist in the cilium/proxylib \ndirectory.  \n\nStep 1: Decide on a Basic Policy Model\n======================================\n\nTo get started, take some time to think about what it means to provide protocol-aware security\nin the context of your chosen protocol.   Most protocols follow a common pattern of a client \nwho performs an ''operation'' on a ''resource''.   For example: \n\n- A standard RESTful HTTP request has a GET/POST/PUT/DELETE methods (operation) and URLs (resource).\n- A database protocol like MySQL has SELECT/INSERT/UPDATE/DELETE actions (operation) on a combined database + table name (resource).   \n- A queueing protocol like Kafka has produce/consume (operation) on a particular queue (resource).    \n\nA common policy model is to allow the user to whitelist certain operations on one or more resources.   \nIn some cases, the resources need to support regexes to avoid explicit matching on variable content \nlike ids (e.g., /users/<uuid> would match /users/.*) \n\nIn our examples, the ''r2d2'' example, we'll use a basic set of operations (READ/WRITE/HALT/RESET). \nThe READ and WRITE commands also support a 'filename' resource, while HALT and RESET have no resource.  \n\nStep 2: Understand Protocol, Encoding, Framing and Types\n========================================================\n\nNext, get your head wrapped around how a protocol looks terms of the raw data, as this is what you'll be parsing. \n\nTry looking for official definitions of the protocol or API.   Official docs will not only help you quickly \nlearn how the protocol works, but will also help you by documenting tricky corner cases that wouldn't be \nobvious just from regular use of the protocol.   For example, here are example specs for \n`Redis Protocol <https://redis.io/topics/protocol>`_ , `Cassandra Protocol <https://github.com/apache/cassandra/blob/trunk/doc/native_protocol_v4.spec>`_,  \nand `AWS SQS <https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html>`_ .  \n\nThese specs help you understand protocol aspects like: \n\n- **encoding / framing** : how to recognize the beginning/end of individual requests/replies within a TCP stream. \n  This typically involves reading a header that encodes the overall request length, though some simple \n  protocols use a delimiter like ''\\r\\n\\'' to separate messages.  \n\n- **request/reply fields** : for most protocols, you will need to parse out fields at various offsets\n  into the request data in order to extract security-relevant values for visibility + filtering.  In some cases, access\n  control requires filtering requests from clients to servers, but in some cases, parsing replies will also be required\n  if reply data is required to understand future requests (e.g., prepared-statements in database protocols).  \n\n- **message flow** : specs often describe various dependencies between different requests.  Basic protocols tend to \n  follow a simple serial request/reply model, but more advanced protocols will support pipelining (i.e., sending \n  multiple requests before any replies have been received).  \n\n- **protocol errors** : when a Cilium proxy denies a request based on policy, it should return a protocol-specific\n  error to the client (e.g., in HTTP, a proxy should return a ''403 Access Denied'' error).  Looking at the protocol\n  spec will typically indicate how you should return an equivalent ''Access Denied'' error.    \n  \nSometimes, the protocol spec does not give you a full sense of the set of commands that can be sent over the protocol.  In that \ncase, looking at higher-level user documentation can fill in some of these knowledge gaps.  Here are examples for \n`Redis Commands <https://redis.io/commands>`_ and `Cassandra CQL Commands <https://docs.datastax.com/en/archived/cql/3.1/cql/cql_reference/cqlCommandsTOC.html>`_ .\n \nAnother great trick is to use `Wireshark <https://www.wireshark.org>`_  to capture raw packet data between\na client and server.   For many protocols, the `Wireshark Sample Captures <https://wiki.wireshark.org/SampleCaptures>`_ \nhas already saved captures for us.  Otherwise, you can easily use tcpdump to capture a file.  For example, for \nMySQL traffic on port 3306, you could run the following in a container running the MySQL client or server: \n“tcpdump -s 0 port 3306 -w mysql.pcap”.  `More Info <https://linuxexplore.com/2012/06/07/use-tcpdump-to-capture-in-a-pcap-file-wireshark-dump/>`_    \n\nIn our example r2d2 protocol, we'll keep the spec as simple as possible.  It is a text-only based protocol, \nwith each request being a line terminated by ''\\r\\n''.  A request starts with a case-insensitive string \ncommand (\"READ\",\"WRITE\",\"HALT\",\"RESET\").   If the command is \"READ\" or \"WRITE\", the command must be followed\nby a space, and a non-empty filename that contains only non whitespace ASCII characters.  \n\nStep 3: Search for Existing Parser Code / Libraries\n===================================================\n\nLook for open source Go library/code that can help.    \nIs there existing open source Go code that parse your protocol that you can leverage, \neither directly as library or a motivating example?  For example, the `tidwall/recon library \n<https://github.com/tidwall/redcon>`_ parses Redis in Go, and `Vitess \n<https://github.com/vitessio/vitess>`_ parses MySQL in Go.   `Wireshark dissectors \n<https://github.com/boundary/wireshark/tree/master/epan/dissectors>`_ also has a wealth of \nprotocol parsers written in C that can serve as useful guidance.    Note:  finding client-only \nprotocol parsing code is typically less helpful than finding a proxy implementation, or a full \nparser library.   This is because the set of requests a client parsers is typically the inverse\nset of the requests a Cilium proxy needs to parse, since the proxy mimics the server rather than \nthe client.   Still, viewing a Go client can give you a general idea of how to parse the \ngeneral serialization format of the protocol.  \n\nStep 4: Follow the Cilium Developer Guide\n=========================================\n\nIt is easiest to start Cilium development by following the :ref:`dev_guide`\n\nAfter cloning cilium/proxy repo:\n\n.. code-block:: shell-session\n\n    $ cd proxy\n    $ vagrant up\n    $ cd proxylib\n\nWhile this dev VM is running, you can open additional terminals to the cilium/proxy dev VM\nby running ``vagrant ssh`` from within the cilium/proxy source directory.\n\n\nStep 5: Create New Proxy Skeleton \n=================================\n\nFrom inside the proxylib directory, copy the rd2d directory and rename the files. \nReplace ''newproto'' with your protocol: \n\n.. code-block:: shell-session\n\n    $ mkdir newproto\n    $ cd newproto\n    $ cp ../r2d2/r2d2parser.go newproto.go\n    $ cp ../r2d2/r2d2parser_test.go newproto_test.go\n\n\nWithin both newproto.go and newproto_test.go update references to r2d2 with\nyour protocol name.   Search for both ''r2d2'' and ''R2D2''.  \n\nAlso, edit proxylib.go and add the following import line: \n\n:: \n\n       _ \"github.com/cilium/proxy/proxylib/newproto\"\n\n\nStep 6: Update OnData Method \n============================\n\nImplementing a parser requires you as the developer to implement three primary functions,\nshown as blue in the diagram below.   We will cover OnData() in this section, and \nthe other functions in section `Step 9:  Add Policy Loading and Matching`_.  \n\n.. image:: _static/proxylib_key_functions.png\n\nThe beating heart of your parsing is implementing the onData function.  You can think of any \nproxy as have two data streams, one in the request direction (i.e., client to server) and one in \nthe reply direction (i.e., server to client).   OnData is called when there is data to process, \nand the value of the boolean 'reply' parameter indicates the direction of the stream for a given \ncall to OnData.   The data passed to OnData is a slice of byte slices (i.e., an array of byte arrays).  \n\nThe return values of the OnData function tell the Go framework tell how data in the stream\nshould be processed, with four primary outcomes:  \n\n- **PASS x** :  The next x bytes in the data stream passed to OnData represent a request/reply that should be\n  passed on to the server/client.   The common case here is that this is a request that should be \n  allowed by policy, or that no policy is applied.  Note: x bytes may be less than the total amount\n  of data passed to OnData, in which case the remaining bytes will still be in the data stream when\n  onData is invoked next.  x bytes may also be more than the data that has been passed to OnData. \n  For example, in the case of a protocol where the parser filters only on values in a protocol header, \n  it is often possible to make a filtering decision, and then pass (or drop) the size of the full \n  request/reply without having the entire request passed to Go.  \n\n- **MORE x** :  The buffers passed to OnData to do not represent all of the data required to frame and\n  filter the request/reply.  Instead, the parser \n  needs to see at least x additional bytes beyond the current data to make a decision.  \n  In some cases, the full request must be read to understand framing and filtering, but in others a decision \n  can be made simply by reading a protocol header.   When parsing data, be defensive, and recognize that it is technically possible that \n  data arrives one byte at a time. Two common scenarios exist here:\n\n  - **Text-based Protocols** : For text-based protocols\n    that use a delimiter like \"\\r\\n\", it is common to simply check if the delimiter exists, and return \n    MORE 1 if it does not, as technically one more character could result in the delimiter being present.\n    See the sample r2d2 parser as a basic example of this.    \n\n  - **Binary-based protocols** : Many binary protocols  \n    have a fixed header length, which containers a field that then indicates the remaining length\n    of the request.  In the binary case, first check to make sure a full header is received.  Typically\n    the header will indicate both the full request length (i.e., framing), as well as the request type, \n    which indicates how much of the full request must be read in order to perform filtering (in many cases, this is less than \n    the full request).  A binary parser will typically return MORE if the data passed to OnData is less than \n    the header length.   After reading a full header, the simple approach is for the parser to return MORE to wait \n    for the full request to be received and parsed  (see the existing CassandraParser as an example).\n    However, as an optimization, the parser can attempt to only \n    request the minimum number of bytes required beyond the header to make a policy decision, and then PASS or DROP\n    the remaining bytes without requiring them to be passed to the Go parser. \n\n- **DROP x** :  Remove the first x bytes from the data stream passed to OnData, as they represent a request/reply\n  that should not be forwarded to the client or server based on policy.  Don't worry about making onData return \n  a drop right away, as we'll return to DROP in a later step below.  \n\n- **ERROR y** : The connection contains data that does not match the protocol spec, and prevents you from further \n  parsing the data stream.   The framework will terminate the connection.   An example would be a request length\n  that falls outside the min/max specified by the protocol spec, or values for a field that fall outside the values\n  indicated by the spec (e.g., wrong versions, unknown commands).  If you are still able to properly frame the \n  requests, you can also choose to simply drop the request and return a protocol error (e.g., similar to an \n  ''HTTP 400 Bad Request'' error.   But in all cases, you should write your parser defensively, such that you \n  never forward a request that you do not understand, as such a request could become an avenue for subverting \n  the intended security visibility and filtering policies.  See proxylib/types.h for the set of valid error codes.   \n\nSee proxylib/proxylib/parserfactory.go for the official OnData interface definition.   \n\nKeep it simple, and work iteratively.  Start out just getting the framing right.  Can you write a parser that just \nprints out the length and contents of a request, and then PASS each request with no policy enforcement?   \n\nOne simple trick is to comment out the r2d2 parsing logic in OnData, but leave it in the file as a reference, as your protocol will likely\nrequire similar code as we add more functionality below.  \n\nStep 7: Use Unit Testing To Drive Development\n=============================================\n\nUse unit tests to drive your development.    Its tempting to want to first test your parser by firing up a\nclient and server and developing on the fly.   But in our experience you’ll iterate faster by using the \ngreat unit test framework created along with the Go proxy framework.   This framework lets you pass\nin an example set of requests as byte arrays to a CheckOnDataOK method, which are passed to the parser's OnData method.\nCheckOnDataOK takes a set of expected return values, and compares them to the actual return values from OnData \nprocessing the byte arrays.  \n\nTake some time to look at the unit tests for the r2d2 parser, and then for more complex parsers like Cassandra\nand Memcached.   For simple text-based protocols, you can simply write ASCII strings to represent protocol messages, \nand convert them to []byte arrays and pass them to CheckOnDataOK.   For binary protocols, one can either create \nbyte arrays directly, or use a mechanism to convert a hex string to byte[] array using a helper function like \nhexData in cassandra/cassandraparser_test.go\n\nA great way to get the exact data to pass in is to copy the data from the Wireshark captures mentioned\nabove in Step #2.   You can see the full application layer data streams in Wireshark by right-clicking\non a packet and selecting “Follow As… TCP Stream”.  If the protocol is text-based, you can copy the data \nas ASCII (see r2d2/r2d2parser_test.go as an example of this).   For binary data, it can be easier to instead \nselect “raw” in the drop-down, and use a basic utility to convert from ascii strings to binary raw data (see \ncassandra/cassandraparser_test.go for an example of this). \n\nTo run the unit tests, go to proxylib/newproto and run: \n\n.. code-block:: shell-session\n\n  $ go test\n\nThis will build the latest version of your parser and unit test files and run the unit tests.   \n\nStep 8: Add More Advanced Parsing\n=================================\n\nThinking back to step #1, what are the critical fields to parse out of the request in order to \nunderstand the “operation” and “resource” of each request.  Can you print those out for each request?\n\nUse the unit test framework to pass in increasingly complex requests, and confirm that the parser prints out the right values, and that the \nunit tests are properly slicing the datastream into requests and parsing out the required fields. \n\nA couple scenarios to make sure your parser handles properly via unit tests: \n\n- data chunks that are less than a full request (return MORE) \n- requests that are spread across multiple data chunks. (return MORE ,then PASS) \n- multiple requests that are bundled into a single data chunk (return PASS, then another PASS)\n- rejection of malformed requests (return ERROR). \n\nFor certain advanced cases, it is required for a parser to store state across requests. \nIn this case, data can be stored using data structures that\nare included as part of the main parser struct.  See CassandraParser in cassandra/cassandraparser.go as an example \nof how the parser uses a string to store the current 'keyspace' in use, and uses Go maps to keep \nstate required for handling prepared queries.   \n\nStep 9:  Add Policy Loading and Matching\n========================================\n\nOnce you have the parsing of most protocol messages ironed out, its time to start enforcing policy. \n\nFirst, create a Go object that will represent a single rule in the policy language. For example,\nthis is the rule for the r2d2 protocol, which performs exact match on the command string, and a regex\non the filename:  \n\n.. code-block:: go\n\n    type R2d2Rule struct {\n       cmdExact   string\n       fileRegexCompiled *regexp.Regexp\n    }\n\nThere are two key methods to update: \n\n- Matches :   This function implements the basic logic of comparing data from a single request \n  against a single policy rule, and return true if that rule matches (i.e., allows) that request.  \n\n- <NewProto>RuleParser : Reads key value pairs from policy, validates those entries, and stores\n  them as a <NewProto>Rule object.   \n\nSee r2d2/r2d2parser.go for examples of both functions for the r2d2 protocol.  \n\nYou'll also need to update OnData to call p.connection.Matches(), and if this function return false, \nreturn DROP for a request.  Note: despite the similar names between the Matches() function you \ncreate in your newprotoparser.go and p.connection.Matches(), do not confuse\nthe two.  Your OnData function should always call p.connection.Matches() rather than invoking your\nown Matches() directly, as p.connection.Matches()\ncalls the parser's Matches() function only on the subset of L7 rules that apply for the given \nCilium source identity for this particular connection.  \n\nOnce you add the logic to call Matches() and return DROP in OnData, you will need to update\nunit tests to have policies that allow the traffic you expect to be passed.   The following \nis an example of how r2d2/r2d2parser_test.go adds an allow-all policy for a given test: \n\n.. code-block:: go\n\n    s.ins.CheckInsertPolicyText(c, \"1\", []string{`\n        name: \"cp1\"\n        policy: 2\n        ingress_per_port_policies: <\n          port: 80\n          rules: <\n            l7_proto: \"r2d2\"\n          >\n        >\n        `})\n\nThe following is an example of a policy that would allow READ commands with a file \nregex of \".*\": \n\n.. code-block:: go\n\n    s.ins.CheckInsertPolicyText(c, \"1\", []string{`\n        name: \"cp2\"\n        policy: 2\n        ingress_per_port_policies: <\n          port: 80\n          rules: <\n            l7_proto: \"r2d2\"\n            l7_rules: <\n            rule: <\n              key: \"cmd\"\n              value: \"READ\"\n            >\n            rule: <\n              key: \"file\"\n              value: \".*\"\n            >\n              >\n            >\n          >\n        >\n        `})\n\n\nStep 10: Inject Error Response\n==============================\n\nSimply dropping the request from the request data stream prevents the request from reaching the server, but it would \nleave the client hanging, waiting for a response that would never come since the server did not see the request. \n\nInstead, the proxy should return an application-layer reply indicating that access was denied, similar to how\nan HTTP proxy would return a ''403 Access Denied'' error.  Look back at the protocol spec discussed in Step 2 to \nunderstand what an access denied message looks like for this protocol, and use the p.connection.Inject() method \nto send this error reply back to the client.   See r2d2/r2d2parser.go for an example. \n\n.. code-block:: go\n\n    p.connection.Inject(true, []byte(\"ERROR\\r\\n\"))\n\nNote:  p.connection.Inject() will inject the data it is passed into the reply datastream.  In order for the client \nto parse this data correctly, it must be injected at a proper framing boundary (i.e., in between other reply messages\nthat may be in the reply data stream).  If the client is following a basic serial request/reply model per connection, this is \nessentially guaranteed as at the time of a request that is denied, there are no other replies potentially in the \nreply datastream.   But if the protocol supports pipelining (i.e., multiple requests in flight) replies must be properly \nframed and PASSed on a per request basis, and the timing of the call to p.connection.Inject() must be controlled\nsuch that the client will properly match the Error response with the correct request.   See the Memcached parser\nas an example of how to accomplish this.  \n\nStep 11: Add Access Logging\n===========================\n\nCilium also has the notion of an ''Access Log'', which records each request handled by the proxy \nand indicates whether the request was allowed or denied.  \n\nA call to ``p.connection.Log()`` implements access logging. See the OnData function in r2d2/r2d2parser.go \nas an example: \n\n.. code-block:: go\n\n      p.connection.Log(access_log_entry_type,\n        &cilium.LogEntry_GenericL7{\n            &cilium.L7LogEntry{\n                Proto: \"r2d2\",\n                Fields: map[string]string{\n                    \"cmd\":  reqData.cmd,\n                    \"file\": reqData.file,\n                },\n            },\n      })  \n\nStep 12: Manual Testing\n=======================\n\nFind the standard docker container for running the protocol server.  Often the same image also has a CLI client that you can use as a client. \n\nStart both a server and client container running in the cilium dev VM, and attach them to the already created “cilium-net”.  For example, with Cassandra, we run:\n\n.. code-block:: shell-session\n\n    docker run --name cass-server -l id=cass-server -d --net cilium-net cassandra\n\n    docker run --name cass-client -l id=cass-client -d --net cilium-net cassandra sh -c 'sleep 3000' \n \n\nNote that we run both containers with labels that will make it easy to refer to these containers in a cilium \nnetwork policy.   Note that we have the client container run the sleep command, as we will use 'docker exec' to \naccess the client CLI.  \n\nUse ``cilium-dbg endpoint list`` to identify the IP address of the protocol server.  \n\n.. code-block:: shell-session\n\n  $ cilium-dbg endpoint list\n  ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])   IPv6                 IPv4            STATUS   \n             ENFORCEMENT        ENFORCEMENT                                                                                     \n  2987       Disabled           Disabled          31423      container:id=cass-server      f00d::a0b:0:0:bab    10.11.51.247    ready   \n  27333      Disabled           Disabled          4          reserved:health               f00d::a0b:0:0:6ac5   10.11.92.46     ready   \n  50923      Disabled           Disabled          18253      container:id=cass-client      f00d::a0b:0:0:c6eb   10.11.175.191   ready \n\nOne can then invoke the client CLI using that server IP address (10.11.51.247 in the above example):\n\n.. code-block:: shell-session\n\n    docker exec -it cass-client sh -c 'cqlsh 10.11.51.247 -e \"select * from system.local\"'\n\nNote that in the above example, ingress policy is not enforced for the Cassandra server endpoint, so no data will flow through the\nCassandra parser.  A simple ''allow all'' L7 Cassandra policy can be used to send all data to the Cassandra server through the \nGo Cassandra parser.  This policy has a single empty rule, which matches all requests.  An allow all policy looks like: \n\n.. code-block:: json\n\n  [ { \n    \"endpointSelector\": {\"matchLabels\":{\"id\":\"cass-server\"}}, \n    \"ingress\": [ {\n\t  \"toPorts\": [{\n\t\t  \"ports\": [{\"port\": \"9042\", \"protocol\": \"TCP\"}],\n            \t\t\"rules\": {\n                \t\t\"l7proto\": \"cassandra\",\n                \t\t\"l7\": [{}]\n            \t\t}\n\t\t}]\n\t  } ] \n  }]\n\n\nA policy can be imported into cilium using ``cilium policy import``, after which another call to ``cilium-dbg endpoint list``\nconfirms that ingress policy is now in place on the server.  If the above policy was saved to a file cass-allow-all.json, \none would run: \n\n.. code-block:: shell-session\n\n    $ cilium-dbg policy import cass-allow-all.json\n    Revision: 1\n    $ cilium-dbg endpoint list\n    ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])   IPv6                 IPv4            STATUS   \n               ENFORCEMENT        ENFORCEMENT                                                                                     \n    2987       Enabled            Disabled          31423      container:id=cass-server      f00d::a0b:0:0:bab    10.11.51.247    ready   \n    27333      Disabled           Disabled          4          reserved:health               f00d::a0b:0:0:6ac5   10.11.92.46     ready   \n    50923      Disabled           Disabled          18253      container:id=cass-client      f00d::a0b:0:0:c6eb   10.11.175.191   ready \n\nNote that policy is now showing as ''Enabled'' for the Cassandra server on ingress. \n\nTo remove this or any other policy, run: \n\n.. code-block:: shell-session\n\n    $ cilium-dbg policy delete --all \n\nTo install a new policy, first delete, and then run ``cilium policy import`` again.  For example, the following policy would allow\nselect statements on a specific set of tables to this Cassandra server, but deny all other queries. \n\n.. code-block:: json\n\n  [ {\n    \"endpointSelector\": {\"matchLabels\":{\"id\":\"cass-server\"}},\n    \"ingress\": [ {\n          \"toPorts\": [{\n                  \"ports\": [{\"port\": \"9042\", \"protocol\": \"TCP\"}],\n                        \"rules\": {\n                                \"l7proto\": \"cassandra\",\n                                \"l7\": [\n                                       { \"query_action\" : \"select\", \"query_table\": \"^system.*\"},\n                                       { \"query_action\" : \"select\", \"query_table\" : \"^posts_db.posts$\"}\n\n                                ]}\n                        }]\n         }]\n  } ]\n\nWhen performing manual testing, remember that each time you change your Go proxy code, you must\nre-run ``make`` and ``sudo make install`` and then restart the cilium-agent process.  If the only changes\nyou have made since last compiling cilium are in your cilium/proxylib directory, you can safely \njust run ``make`` and ``sudo make install``  in that directory, which saves time.  \nFor example: \n\n.. code-block:: shell-session\n\n  $ cd proxylib  // only safe is this is the only directory that has changed\n  $ make  \n    <snip> \n  $ sudo make install \n    <snip> \n\nIf you rebase or other files change, you need to run both commands from the top level directory.  \n\nCilium agent default to running as a service in the development VM.  However, the default options do not include \nthe ``--debug-verbose=flow`` flag, which is critical to getting visibility in troubleshooting Go proxy frameworks. \nSo it is easiest to stop the cilium service and run the cilium-agent directly as a command in a terminal window, \nand adding the ``--debug-verbose=flow`` flag. \n\n.. code-block:: shell-session\n\n  $ sudo service cilium stop \n  \n  $ sudo /usr/bin/cilium-agent --debug --ipv4-range 10.11.0.0/16 --kvstore-opt etcd.address=192.168.60.11:4001 --kvstore etcd -t vxlan --fixed-identity-mapping=128=kv-store --fixed-identity-mapping=129=kube-dns --debug-verbose=flow\n\n\nStep 13: Add Runtime Tests\n==========================\n\nBefore submitting this change to the Cilium community, it is recommended that you add runtime tests that will run as\npart of Cilium's continuous integration testing.   Usually these runtime test can be based on the same container \nimages and test commands you used for manual testing.   \n\nThe best approach for adding runtime tests is typically to start out by copying-and-pasting an existing L7 protocol runtime\ntest and then updating it to run the container images and CLI commands specific to the new protocol.   \nSee cilium/test/runtime/cassandra.go as an example that matches the use of Cassandra described above in the manual testing\nsection.   Note that the json policy files used by the runtime tests are stored in cilium/test/runtime/manifests, and \nthe Cassandra example policies in those directories are easy to use as a based for similar policies you may create for your\nnew protocol.  \n\nStep 14: Review Spec for Corner Cases\n=====================================\n\nMany protocols have advanced features or corner cases that will not manifest themselves as part of basic testing.   \nOnce you have written a first rev of the parser, it is a good idea to go back and review the protocol's spec or list of \ncommands to see what if any aspects may fall outside the scope of your initial parser.    \nFor example, corner cases like the handling of empty or nil lists may not show up in your testing, but may cause your\nparser to fail.   Add more unit tests to cover these corner cases.  \nIt is OK for the first rev of your parser not to handle all types of requests, or to have a simplified policy structure \nin terms of which fields can be matched.   However, it is \nimportant to know what aspects of the protocol you are not parsing, and ensure that it does not lead to any security concerns. \nFor example, failing to parse prepared statements in a database protocol and instead just passing PREPARE and EXECUTE\ncommands through would lead to gaping security whole that would render your other filtering meaningless in the face of\na sophisticated attacker.   \n\nStep 15: Write Docs or Getting Started Guide (optional) \n=======================================================\n\nAt a minimum, the policy examples included as part of the runtime tests serve\nas basic documentation of the policy and its expected behavior.  But we also \nencourage adding more user friendly examples and documentation, for example, \nGetting Started Guides. For a good example to follow, see :gh-issue:`5661`.\nAlso be sure to update ``Documentation/security/index.rst`` with a link\nto this new getting started guide.\n\nWith that, you are ready to post this change for feedback from the Cilium community. Congrats!\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/security/network/proxy/envoy.rst",
  "extracted_at": "2025-09-03T00:53:44.695066Z"
}
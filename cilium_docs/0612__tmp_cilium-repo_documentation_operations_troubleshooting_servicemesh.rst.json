{
  "url": "file:///tmp/cilium-repo/Documentation/operations/troubleshooting_servicemesh.rst",
  "content": "Service Mesh Troubleshooting \n Install the Cilium CLI \n .. include:: /installation/cli-download.rst \n Generic \n #. Validate that the  ds/cilium  as well as the  deployment/cilium-operator  pods\nare healthy and ready. \n .. code-block:: shell-session\n\n   $ cilium status\n \n Manual Verification of Setup \n #. Validate that  kubeProxyReplacement  is true. \n .. code-block:: shell-session\n\n    $ kubectl exec -n kube-system ds/cilium -- cilium-dbg status\n    ...\n    KubeProxyReplacement:    True\n    ...\n \n #. Validate that runtime the values of  enable-envoy-config  and  enable-ingress-controller \nare true. Ingress controller flag is optional if customer only uses  CiliumEnvoyConfig  or\n CiliumClusterwideEnvoyConfig  CRDs. \n .. code-block:: shell-session\n\n    $ kubectl -n kube-system get cm cilium-config -o json | egrep \"enable-ingress-controller|enable-envoy-config\"\n            \"enable-envoy-config\": \"true\",\n            \"enable-ingress-controller\": \"true\",\n \n Ingress Troubleshooting \n Internally, the Cilium Ingress controller will create one Load Balancer service, one\n CiliumEnvoyConfig  and one dummy Endpoint resource for each Ingress resource. \n .. code-block:: shell-session\n\n    $ kubectl get ingress\n    NAME            CLASS    HOSTS   ADDRESS        PORTS   AGE\n    basic-ingress   cilium   *       10.97.60.117   80      16m\n\n    # For dedicated Load Balancer mode\n    $ kubectl get service cilium-ingress-basic-ingress\n    NAME                           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)        AGE\n    cilium-ingress-basic-ingress   LoadBalancer   10.97.60.117   10.97.60.117   80:31911/TCP   17m\n\n    # For dedicated Load Balancer mode\n    $ kubectl get cec cilium-ingress-default-basic-ingress\n    NAME                                   AGE\n    cilium-ingress-default-basic-ingress   18m\n\n    # For shared Load Balancer mode\n    $ kubectl get services -n kube-system cilium-ingress\n    NAME             TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                      AGE\n    cilium-ingress   LoadBalancer   10.111.109.99   10.111.109.99   80:32690/TCP,443:31566/TCP   38m\n\n    # For shared Load Balancer mode\n    $ kubectl get cec -n kube-system cilium-ingress\n    NAME             AGE\n    cilium-ingress   15m\n \n #. Validate that the Load Balancer service has either an external IP or FQDN assigned.\nIf it's not available after a long time, please check the Load Balancer related\ndocumentation from your respective cloud provider. \n #. Check if there is any warning or error message while Cilium is trying to provision\nthe  CiliumEnvoyConfig  resource. This is unlikely to happen for CEC resources\noriginating from the Cilium Ingress controller. \n .. include:: /network/servicemesh/warning.rst\n \n Connectivity Troubleshooting \n This section is for troubleshooting connectivity issues mainly for Ingress resources, but\nthe same steps can be applied to manually configured  CiliumEnvoyConfig  resources as well. \n It's best to have  debug  and  debug-verbose  enabled with below values. Kindly\nnote that any change of Cilium flags requires a restart of the Cilium agent and operator. \n .. code-block:: shell-session\n\n    $ kubectl get -n kube-system cm cilium-config -o json | grep \"debug\"\n            \"debug\": \"true\",\n            \"debug-verbose\": \"flow\",\n \n .. note:: \n The originating source IP is used for enforcing ingress traffic.\n \n The request normally traverses from LoadBalancer service to pre-assigned port of your\nnode, then gets forwarded to the Cilium Envoy proxy, and finally gets proxied to the actual\nbackend service. \n #. The first step between cloud Load Balancer to node port is out of Cilium scope. Please\ncheck related documentation from your respective cloud provider to make sure your\nclusters are configured properly. \n #. The second step could be checked by connecting with SSH to your underlying host, and\nsending the similar request to localhost on the relevant port: \n .. code-block:: shell-session\n\n    $ kubectl get service cilium-ingress-basic-ingress\n    NAME                           TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)        AGE\n    cilium-ingress-basic-ingress   LoadBalancer   10.97.60.117   10.97.60.117   80:31911/TCP   17m\n\n    # After ssh to any of k8s node\n    $ curl -v http://localhost:31911/\n    *   Trying 127.0.0.1:31911...\n    * TCP_NODELAY set\n    * Connected to localhost (127.0.0.1) port 31911 (#0)\n    > GET / HTTP/1.1\n    > Host: localhost:31911\n    > User-Agent: curl/7.68.0\n    > Accept: */*\n    >\n    * Mark bundle as not supporting multiuse\n    < HTTP/1.1 503 Service Unavailable\n    < content-length: 19\n    < content-type: text/plain\n    < date: Thu, 07 Jul 2022 12:25:56 GMT\n    < server: envoy\n    <\n    * Connection #0 to host localhost left intact\n\n    # Flows for world identity\n    $ kubectl -n kube-system exec ds/cilium -- hubble observe -f --identity 2\n    Jul  7 12:28:27.970: 127.0.0.1:54704 <- 127.0.0.1:13681 http-response FORWARDED (HTTP/1.1 503 0ms (GET http://localhost:31911/))\n\nAlternatively, you can also send a request directly to the Envoy proxy port. For\nIngress, the proxy port is randomly assigned by the Cilium Ingress controller. For\nmanually configured ``CiliumEnvoyConfig`` resources, the proxy port is retrieved\ndirectly from the spec.\n\n.. code-block:: shell-session\n\n    $  kubectl logs -f -n kube-system ds/cilium --timestamps | egrep \"envoy|proxy\"\n    ...\n    2022-07-08T08:05:13.986649816Z level=info msg=\"Adding new proxy port rules for cilium-ingress-default-basic-ingress:19672\" proxy port name=cilium-ingress-default-basic-ingress subsys=proxy\n\n    # After ssh to any of k8s node, send request to Envoy proxy port directly\n    $ curl -v  http://localhost:19672\n    *   Trying 127.0.0.1:19672...\n    * TCP_NODELAY set\n    * Connected to localhost (127.0.0.1) port 19672 (#0)\n    > GET / HTTP/1.1\n    > Host: localhost:19672\n    > User-Agent: curl/7.68.0\n    > Accept: */*\n    >\n    * Mark bundle as not supporting multiuse\n    < HTTP/1.1 503 Service Unavailable\n    < content-length: 19\n    < content-type: text/plain\n    < date: Fri, 08 Jul 2022 08:12:35 GMT\n    < server: envoy\n\nIf you see a response similar to the above, it means that the request is being\nredirected to proxy successfully. The http response will have one special header\n``server: envoy`` accordingly. The same can be observed from ``hubble observe``\ncommand :ref:`hubble_troubleshooting`.\n\nThe most common root cause is either that the Cilium Envoy proxy is not running\non the node, or there is some other issue with CEC resource provisioning.\n\n.. code-block:: shell-session\n\n    $ kubectl exec -n kube-system ds/cilium -- cilium-dbg status\n    ...\n    Controller Status:       49/49 healthy\n    Proxy Status:            OK, ip 10.0.0.25, 6 redirects active on ports 10000-20000\n    Global Identity Range:   min 256, max 65535\n \n #. Assuming that the above steps are done successfully, you can proceed to send a request via\nan external IP or via FQDN next. \n Double-check whether your backend service is up and healthy. The Envoy Discovery Service\n(EDS) has a name that follows the convention ``<namespace>/<service-name>:<port>``.\n\n.. code-block:: shell-session\n\n    $ LB_IP=$(kubectl get ingress basic-ingress -o json | jq '.status.loadBalancer.ingress[0].ip' | jq -r .)\n    $ curl -s http://$LB_IP/details/1\n    no healthy upstream\n\n    $ kubectl get cec cilium-ingress-default-basic-ingress -o json | jq '.spec.resources[] | select(.type==\"EDS\")'\n    {\n      \"@type\": \"type.googleapis.com/envoy.config.cluster.v3.Cluster\",\n      \"connectTimeout\": \"5s\",\n      \"name\": \"default/details:9080\",\n      \"outlierDetection\": {\n        \"consecutiveLocalOriginFailure\": 2,\n        \"splitExternalLocalOriginErrors\": true\n      },\n      \"type\": \"EDS\",\n      \"typedExtensionProtocolOptions\": {\n        \"envoy.extensions.upstreams.http.v3.HttpProtocolOptions\": {\n          \"@type\": \"type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\",\n          \"useDownstreamProtocolConfig\": {\n            \"http2ProtocolOptions\": {}\n          }\n        }\n      }\n    }\n    {\n      \"@type\": \"type.googleapis.com/envoy.config.cluster.v3.Cluster\",\n      \"connectTimeout\": \"5s\",\n      \"name\": \"default/productpage:9080\",\n      \"outlierDetection\": {\n        \"consecutiveLocalOriginFailure\": 2,\n        \"splitExternalLocalOriginErrors\": true\n      },\n      \"type\": \"EDS\",\n      \"typedExtensionProtocolOptions\": {\n        \"envoy.extensions.upstreams.http.v3.HttpProtocolOptions\": {\n          \"@type\": \"type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\",\n          \"useDownstreamProtocolConfig\": {\n            \"http2ProtocolOptions\": {}\n          }\n        }\n      }\n    }\n\nIf everything is configured correctly, you will be able to see the flows from ``world`` (identity 2),\n``ingress`` (identity 8) and your backend pod as per below.\n\n.. code-block:: shell-session\n\n    # Flows for world identity\n    $ kubectl exec -n kube-system ds/cilium -- hubble observe --identity 2 -f\n    Defaulted container \"cilium-agent\" out of: cilium-agent, mount-cgroup (init), apply-sysctl-overwrites (init), mount-bpf-fs (init), clean-cilium-state (init)\n    Jul  7 13:07:46.726: 192.168.49.1:59608 -> default/details-v1-5498c86cf5-cnt9q:9080 http-request FORWARDED (HTTP/1.1 GET http://10.97.60.117/details/1)\n    Jul  7 13:07:46.727: 192.168.49.1:59608 <- default/details-v1-5498c86cf5-cnt9q:9080 http-response FORWARDED (HTTP/1.1 200 1ms (GET http://10.97.60.117/details/1))\n\n    # Flows for Ingress identity (e.g. envoy proxy)\n    $ kubectl exec -n kube-system ds/cilium -- hubble observe --identity 8 -f\n    Defaulted container \"cilium-agent\" out of: cilium-agent, mount-cgroup (init), apply-sysctl-overwrites (init), mount-bpf-fs (init), clean-cilium-state (init)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: SYN)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 <- default/details-v1-5498c86cf5-cnt9q:9080 to-stack FORWARDED (TCP Flags: SYN, ACK)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: ACK)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: ACK, PSH)\n    Jul  7 13:07:46.727: 10.0.0.95:42509 <- default/details-v1-5498c86cf5-cnt9q:9080 to-stack FORWARDED (TCP Flags: ACK, PSH)\n\n    # Flows for backend pod, the identity can be retrieved via cilium identity list command\n    $ kubectl exec -n kube-system ds/cilium -- hubble observe --identity 48847 -f\n    Defaulted container \"cilium-agent\" out of: cilium-agent, mount-cgroup (init), apply-sysctl-overwrites (init), mount-bpf-fs (init), clean-cilium-state (init)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: SYN)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 <- default/details-v1-5498c86cf5-cnt9q:9080 to-stack FORWARDED (TCP Flags: SYN, ACK)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: ACK)\n    Jul  7 13:07:46.726: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: ACK, PSH)\n    Jul  7 13:07:46.726: 192.168.49.1:59608 -> default/details-v1-5498c86cf5-cnt9q:9080 http-request FORWARDED (HTTP/1.1 GET http://10.97.60.117/details/1)\n    Jul  7 13:07:46.727: 10.0.0.95:42509 <- default/details-v1-5498c86cf5-cnt9q:9080 to-stack FORWARDED (TCP Flags: ACK, PSH)\n    Jul  7 13:07:46.727: 192.168.49.1:59608 <- default/details-v1-5498c86cf5-cnt9q:9080 http-response FORWARDED (HTTP/1.1 200 1ms (GET http://10.97.60.117/details/1))\n    Jul  7 13:08:16.757: 10.0.0.95:42509 <- default/details-v1-5498c86cf5-cnt9q:9080 to-stack FORWARDED (TCP Flags: ACK, FIN)\n    Jul  7 13:08:16.757: 10.0.0.95:42509 -> default/details-v1-5498c86cf5-cnt9q:9080 to-endpoint FORWARDED (TCP Flags: ACK, FIN)\n\n    # Sample output of cilium-dbg monitor\n    $ ksysex ds/cilium -- cilium-dbg monitor\n    level=info msg=\"Initializing dissection cache...\" subsys=monitor\n    -> endpoint 212 flow 0x3000e251 , identity ingress->61131 state new ifindex lxcfc90a8580fd6 orig-ip 10.0.0.192: 10.0.0.192:34219 -> 10.0.0.164:9080 tcp SYN\n    -> stack flow 0x2481d648 , identity 61131->ingress state reply ifindex 0 orig-ip 0.0.0.0: 10.0.0.164:9080 -> 10.0.0.192:34219 tcp SYN, ACK\n    -> endpoint 212 flow 0x3000e251 , identity ingress->61131 state established ifindex lxcfc90a8580fd6 orig-ip 10.0.0.192: 10.0.0.192:34219 -> 10.0.0.164:9080 tcp ACK\n    -> endpoint 212 flow 0x3000e251 , identity ingress->61131 state established ifindex lxcfc90a8580fd6 orig-ip 10.0.0.192: 10.0.0.192:34219 -> 10.0.0.164:9080 tcp ACK\n    -> Request http from 0 ([reserved:world]) to 212 ([k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=minikube k8s:io.cilium.k8s.policy.serviceaccount=bookinfo-details k8s:io.kubernetes.pod.namespace=default k8s:version=v1 k8s:app=details]), identity 2->61131, verdict Forwarded GET http://10.99.74.157/details/1 => 0\n    -> stack flow 0x2481d648 , identity 61131->ingress state reply ifindex 0 orig-ip 0.0.0.0: 10.0.0.164:9080 -> 10.0.0.192:34219 tcp ACK\n    -> Response http to 0 ([reserved:world]) from 212 ([k8s:io.kubernetes.pod.namespace=default k8s:version=v1 k8s:app=details k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=minikube k8s:io.cilium.k8s.policy.serviceaccount=bookinfo-details]), identity 61131->2, verdict Forwarded GET http://10.99.74.157/details/1 => 200",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/operations/troubleshooting_servicemesh.rst",
  "extracted_at": "2025-09-03T01:13:29.336597Z"
}
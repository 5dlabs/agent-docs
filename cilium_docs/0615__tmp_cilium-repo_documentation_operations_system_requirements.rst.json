{
  "url": "file:///tmp/cilium-repo/Documentation/operations/system_requirements.rst",
  "content": ".. only:: not (epub or latex or html) \n WARNING: You are looking at unreleased Cilium documentation.\nPlease use the official rendered version released here:\nhttps://docs.cilium.io\n \n .. _admin_system_reqs: \n \n System Requirements \n \n Before installing Cilium, please ensure that your system meets the minimum\nrequirements below. Most modern Linux distributions already do. \n Summary \n When running Cilium using the container image  cilium/cilium , the host\nsystem must meet these requirements: \n \n Hosts with either AMD64 or AArch64 architecture \n Linux kernel _ >= 5.10 or equivalent (e.g., 4.18 on RHEL 8.6) \n \n When running Cilium as a native process on your host (i.e.  not  running the\n cilium/cilium  container image) these additional requirements must be met: \n \n clang+LLVM _ >= 18.1 \n \n .. _ clang+LLVM : https://llvm.org \n When running Cilium without Kubernetes these additional requirements\nmust be met: \n \n :ref: req_kvstore  etcd >= 3.1.0 \n \n ======================== ============================== ===================\nRequirement              Minimum Version                In cilium container\n======================== ============================== ===================\n Linux kernel _          >= 5.10 or >= 4.18 on RHEL 8.6 no\nKey-Value store (etcd)   >= 3.1.0                       no\nclang+LLVM               >= 18.1                        yes\n======================== ============================== =================== \n Architecture Support \n Cilium images are built for the following platforms: \n \n AMD64 \n AArch64 \n \n Linux Distribution Compatibility & Considerations \n The following table lists Linux distributions that are known to work\nwell with Cilium. Some distributions require a few initial tweaks. Please make\nsure to read each distribution's specific notes below before attempting to\nrun Cilium. \n ========================== ====================\nDistribution               Minimum Version\n========================== ====================\n Amazon Linux 2 _          all\n Bottlerocket OS _         all\n CentOS _                  >= 8.6\n Container-Optimized OS _  >= 85\nDebian_                    >= 10 Buster\n Fedora CoreOS _           >= 31.20200108.3.0\nFlatcar_                   all\nLinuxKit_                  all\nOpensuse_                  Tumbleweed, >=Leap 15.4\n RedHat Enterprise Linux _ >= 8.6\n RedHat CoreOS _           >= 4.12\n Talos Linux _             >= 1.5.0\nUbuntu_                    >= 20.04\n========================== ==================== \n .. _Amazon Linux 2: https://docs.aws.amazon.com/AL2/latest/relnotes/relnotes-al2.html\n.. _CentOS: https://centos.org\n.. _Container-Optimized OS: https://cloud.google.com/container-optimized-os/docs\n.. _Fedora CoreOS: https://fedoraproject.org/coreos/release-notes\n.. _Debian: https://www.debian.org/releases/\n.. _Flatcar: https://www.flatcar.org/releases\n.. _LinuxKit: https://github.com/linuxkit/linuxkit/tree/master/kernel\n.. _RedHat Enterprise Linux: https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux\n.. _RedHat CoreOS: https://access.redhat.com/articles/6907891\n.. _Ubuntu: https://www.releases.ubuntu.com/\n.. _Opensuse: https://en.opensuse.org/openSUSE:Roadmap\n.. _Bottlerocket OS: https://github.com/bottlerocket-os/bottlerocket\n.. _Talos Linux: https://www.talos.dev/ \n .. note:: The above list is based on feedback by users. If you find an unlisted\nLinux distribution that works well, please let us know by opening a\nGitHub issue or by creating a pull request that updates this guide. \n Flatcar on AWS EKS in ENI mode \n \nFlatcar is known to manipulate network interfaces created and managed by\nCilium. When running the official Flatcar image for AWS EKS nodes in ENI\nmode, this may cause connectivity issues and potentially prevent the Cilium\nagent from booting. To avoid this, disable DHCP on the ENI interfaces and mark\nthem as unmanaged by adding\n\n.. code-block:: text\n\n        [Match]\n        Name=eth[1-9]*\n\n        [Network]\n        DHCP=no\n\n        [Link]\n        Unmanaged=yes\n\nto ``/etc/systemd/network/01-no-dhcp.network`` and then\n\n.. code-block:: shell-session\n\n        systemctl daemon-reload\n        systemctl restart systemd-networkd\n\nUbuntu 22.04 on Raspberry Pi\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBefore running Cilium on Ubuntu 22.04 on a Raspberry Pi, please make sure to install the following package:\n\n.. code-block:: shell-session\n\n        sudo apt install linux-modules-extra-raspi\n\n.. _admin_kernel_version:\n\nLinux Kernel\n============\n\nBase Requirements\n~~~~~~~~~~~~~~~~~\n\nCilium leverages and builds on the kernel eBPF functionality as well as various\nsubsystems which integrate with eBPF. Therefore, host systems are required to\nrun a recent Linux kernel to run a Cilium agent. More recent kernels may\nprovide additional eBPF functionality that Cilium will automatically detect and\nuse on agent start. For this version of Cilium, it is recommended to use kernel\n5.10 or later (or equivalent such as 4.18 on RHEL8). For a list of features\nthat require newer kernels, see :ref:`advanced_features`.\n\nIn order for the eBPF feature to be enabled properly, the following kernel\nconfiguration options must be enabled. This is typically the case with\ndistribution kernels. When an option can be built as a module or statically\nlinked, either choice is valid.\n\n::\n\n        CONFIG_BPF=y\n        CONFIG_BPF_SYSCALL=y\n        CONFIG_NET_CLS_BPF=y\n        CONFIG_BPF_JIT=y\n        CONFIG_NET_CLS_ACT=y\n        CONFIG_NET_SCH_INGRESS=y\n        CONFIG_CRYPTO_SHA1=y\n        CONFIG_CRYPTO_USER_API_HASH=y\n        CONFIG_CGROUPS=y\n        CONFIG_CGROUP_BPF=y\n        CONFIG_PERF_EVENTS=y\n        CONFIG_SCHEDSTATS=y\n\n\nRequirements for Iptables-based Masquerading\n \n If you are not using BPF for masquerading ( enable-bpf-masquerade=false , the\ndefault value), then you will need the following kernel configuration options. \n :: \n     CONFIG_NETFILTER_XT_SET=m\n    CONFIG_IP_SET=m\n    CONFIG_IP_SET_HASH_IP=m\n    CONFIG_NETFILTER_XT_MATCH_COMMENT=m\n \n Requirements for Tunneling and Routing \n \nCilium uses tunneling protocols like VXLAN by default for pod-to-pod communication\nacross nodes, as well as policy routing for various traffic management functionality. \nThe following kernel configuration options are required for proper operation:\n\n::\n\n        CONFIG_VXLAN=y\n        CONFIG_GENEVE=y\n        CONFIG_FIB_RULES=y\n\n\n.. note::\n\n   On some embedded or custom Linux systems, especially when cross-compiling for\n   ARM, enabling ``CONFIG_FIB_RULES=y`` directly in the kernel ``.config`` is not sufficient,\n   as it depends on other routing-related kernel options to be enabled.\n\n   The recommended approach is to use:\n\n   ::\n\n       scripts/config --enable CONFIG_FIB_RULES\n       make olddefconfig\n\n   The kernel build system uses ``Kconfig`` logic to validate and manage dependencies, \n   so direct edits to ``.config`` may be ignored or silently overridden.\n\nRequirements for L7 and FQDN Policies\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nL7 proxy redirection currently uses ``TPROXY`` iptables actions as well\nas ``socket`` matches. For L7 redirection to work as intended kernel\nconfiguration must include the following modules:\n\n::\n\n        CONFIG_NETFILTER_XT_TARGET_TPROXY=m\n        CONFIG_NETFILTER_XT_TARGET_MARK=m\n        CONFIG_NETFILTER_XT_TARGET_CT=m\n        CONFIG_NETFILTER_XT_MATCH_MARK=m\n        CONFIG_NETFILTER_XT_MATCH_SOCKET=m\n\nWhen ``xt_socket`` kernel module is missing the forwarding of\nredirected L7 traffic does not work in non-tunneled datapath\nmodes. Since some notable kernels (e.g., COS) are shipping without\n``xt_socket`` module, Cilium implements a fallback compatibility mode\nto allow L7 policies and visibility to be used with those\nkernels. Currently this fallback disables ``ip_early_demux`` kernel\nfeature in non-tunneled datapath modes, which may decrease system\nnetworking performance. This guarantees HTTP and Kafka redirection\nworks as intended.  However, if HTTP or Kafka enforcement policies are\nnever used, this behavior can be turned off by adding the following to\nthe helm configuration command line:\n\n.. parsed-literal::\n\n   helm install cilium |CHART_RELEASE| \\\\\n     ...\n     --set enableXTSocketFallback=false\n\n.. _features_kernel_matrix:\n\nRequirements for IPsec\n~~~~~~~~~~~~~~~~~~~~~~\n\nThe :ref:`encryption_ipsec` feature requires a lot of kernel configuration\noptions, most of which to enable the actual encryption. Note that the\nspecific options required depend on the algorithm. The list below\ncorresponds to requirements for GCM-128-AES.\n\n::\n\n        CONFIG_XFRM=y\n        CONFIG_XFRM_OFFLOAD=y\n        CONFIG_XFRM_STATISTICS=y\n        CONFIG_XFRM_ALGO=m\n        CONFIG_XFRM_USER=m\n        CONFIG_INET{,6}_ESP=m\n        CONFIG_INET{,6}_IPCOMP=m\n        CONFIG_INET{,6}_XFRM_TUNNEL=m\n        CONFIG_INET{,6}_TUNNEL=m\n        CONFIG_INET_XFRM_MODE_TUNNEL=m\n        CONFIG_CRYPTO_AEAD=m\n        CONFIG_CRYPTO_AEAD2=m\n        CONFIG_CRYPTO_GCM=m\n        CONFIG_CRYPTO_SEQIV=m\n        CONFIG_CRYPTO_CBC=m\n        CONFIG_CRYPTO_HMAC=m\n        CONFIG_CRYPTO_SHA256=m\n        CONFIG_CRYPTO_AES=m\n\nRequirements for the Bandwidth Manager\n \n The :ref: bandwidth-manager  requires the following kernel configuration option\nto change the packet scheduling algorithm. \n :: \n     CONFIG_NET_SCH_FQ=m\n \n Requirements for Netkit Device Mode \n \nThe :ref:`netkit` requires the following kernel configuration option\nto create netkit devices.\n\n::\n\n        CONFIG_NETKIT=y\n\n.. _advanced_features:\n\nRequired Kernel Versions for Advanced Features\n==============================================\n\nAdditional kernel features continues to progress in the Linux community. Some\nof Cilium's features are dependent on newer kernel versions and are thus\nenabled by upgrading to more recent kernel versions as detailed below.\n\n====================================================== ===============================\nCilium Feature                                         Minimum Kernel Version\n====================================================== ===============================\n:ref:`encryption_wg`                                   >= 5.6\nFull support for :ref:`session-affinity`               >= 5.7\nBPF-based proxy redirection                            >= 5.7\nSocket-level LB bypass in pod netns                    >= 5.7\nL3 devices                                             >= 5.8\nBPF-based host routing                                 >= 5.10\n:ref:`enable_multicast` (AMD64)                        >= 5.10\nIPv6 BIG TCP support                                   >= 5.19\n:ref:`enable_multicast` (AArch64)                      >= 6.0\nIPv4 BIG TCP support                                   >= 6.3\n====================================================== ===============================\n\n.. _req_kvstore:\n\nKey-Value store\n===============\n\nCilium optionally uses a distributed Key-Value store to manage,\nsynchronize and distribute security identities across all cluster\nnodes. The following Key-Value stores are currently supported:\n\n- etcd >= 3.1.0\n\nCilium can be used without a Key-Value store when CRD-based state\nmanagement is used with Kubernetes. This is the default for new Cilium\ninstallations. Larger clusters will perform better with a Key-Value\nstore backed identity management instead, see :ref:`k8s_quick_install`\nfor more details.\n\nSee :ref:`install_kvstore` for details on how to configure the\n``cilium-agent`` to use a Key-Value store.\n\nclang+LLVM\n==========\n\n\n.. note:: This requirement is only needed if you run ``cilium-agent`` natively.\n          If you are using the Cilium container image ``cilium/cilium``,\n          clang+LLVM is included in the container image.\n\nLLVM is the compiler suite that Cilium uses to generate eBPF bytecode programs\nto be loaded into the Linux kernel. The minimum supported version of LLVM\navailable to ``cilium-agent`` should be >=18.1. The version of clang installed\nmust be compiled with the eBPF backend enabled.\n\nSee https://releases.llvm.org/ for information on how to download and install\nLLVM.\n\n.. _firewall_requirements:\n\nFirewall Rules\n==============\n\nIf you are running Cilium in an environment that requires firewall rules to\nenable connectivity, you will have to add the following rules to ensure Cilium\nworks properly.\n\nIt is recommended but optional that all nodes running Cilium in a given cluster\nmust be able to ping each other so ``cilium-health`` can report and monitor\nconnectivity among nodes. This requires ICMP Type 0/8, Code 0 open among all\nnodes. TCP 4240 should also be open among all nodes for ``cilium-health``\nmonitoring. Note that it is also an option to only use one of these two methods\nto enable health monitoring. If the firewall does not permit either of these\nmethods, Cilium will still operate fine but will not be able to provide health\ninformation.\n\nFor IPsec enabled Cilium deployments, you need to ensure that the firewall\nallows ESP traffic through. For example, AWS Security Groups doesn't allow ESP\ntraffic by default.\n\nIf you are using WireGuard, you must allow UDP port 51871.\n\nIf you are using VXLAN overlay network mode, Cilium uses Linux's default VXLAN\nport 8472 over UDP, unless Linux has been configured otherwise. In this case,\nUDP 8472 must be open among all nodes to enable VXLAN overlay mode. The same\napplies to Geneve overlay network mode, except the port is UDP 6081.\n\nIf you are running in direct routing mode, your network must allow routing of\npod IPs.\n\nAs an example, if you are running on AWS with VXLAN overlay networking, here is\na minimum set of AWS Security Group (SG) rules. It assumes a separation between\nthe SG on the master nodes, ``master-sg``, and the worker nodes, ``worker-sg``.\nIt also assumes ``etcd`` is running on the master nodes.\n\nMaster Nodes (``master-sg``) Rules:\n\n======================== =============== ==================== ===============\nPort Range / Protocol    Ingress/Egress  Source/Destination   Description\n======================== =============== ==================== ===============\n2379-2380/tcp            ingress         ``worker-sg``        etcd access\n8472/udp                 ingress         ``master-sg`` (self) VXLAN overlay\n8472/udp                 ingress         ``worker-sg``        VXLAN overlay\n4240/tcp                 ingress         ``master-sg`` (self) health checks\n4240/tcp                 ingress         ``worker-sg``        health checks\nICMP 8/0                 ingress         ``master-sg`` (self) health checks\nICMP 8/0                 ingress         ``worker-sg``        health checks\n8472/udp                 egress          ``master-sg`` (self) VXLAN overlay\n8472/udp                 egress          ``worker-sg``        VXLAN overlay\n4240/tcp                 egress          ``master-sg`` (self) health checks\n4240/tcp                 egress          ``worker-sg``        health checks\nICMP 8/0                 egress          ``master-sg`` (self) health checks\nICMP 8/0                 egress          ``worker-sg``        health checks\n======================== =============== ==================== ===============\n\nWorker Nodes (``worker-sg``):\n\n======================== =============== ==================== ===============\nPort Range / Protocol    Ingress/Egress  Source/Destination   Description\n======================== =============== ==================== ===============\n8472/udp                 ingress         ``master-sg``        VXLAN overlay\n8472/udp                 ingress         ``worker-sg`` (self) VXLAN overlay\n4240/tcp                 ingress         ``master-sg``        health checks\n4240/tcp                 ingress         ``worker-sg`` (self) health checks\nICMP 8/0                 ingress         ``master-sg``        health checks\nICMP 8/0                 ingress         ``worker-sg`` (self) health checks\n8472/udp                 egress          ``master-sg``        VXLAN overlay\n8472/udp                 egress          ``worker-sg`` (self) VXLAN overlay\n4240/tcp                 egress          ``master-sg``        health checks\n4240/tcp                 egress          ``worker-sg`` (self) health checks\nICMP 8/0                 egress          ``master-sg``        health checks\nICMP 8/0                 egress          ``worker-sg`` (self) health checks\n2379-2380/tcp            egress          ``master-sg``        etcd access\n======================== =============== ==================== ===============\n\n.. note:: If you use a shared SG for the masters and workers, you can condense\n          these rules into ingress/egress to self. If you are using Direct\n          Routing mode, you can condense all rules into ingress/egress ANY\n          port/protocol to/from self.\n\nThe following ports should also be available on each node:\n\n======================== ==================================================================\nPort Range / Protocol    Description\n======================== ==================================================================\n4240/tcp                 cluster health checks (``cilium-health``)\n4244/tcp                 Hubble server\n4245/tcp                 Hubble Relay\n4250/tcp                 Mutual Authentication port\n4251/tcp                 Spire Agent health check port (listening on 127.0.0.1 or ::1)\n6060/tcp                 cilium-agent pprof server (listening on 127.0.0.1)\n6061/tcp                 cilium-operator pprof server (listening on 127.0.0.1)\n6062/tcp                 Hubble Relay pprof server (listening on 127.0.0.1)\n9878/tcp                 cilium-envoy health listener (listening on 127.0.0.1)\n9879/tcp                 cilium-agent health status API (listening on 127.0.0.1 and/or ::1)\n9890/tcp                 cilium-agent gops server (listening on 127.0.0.1)\n9891/tcp                 operator gops server (listening on 127.0.0.1)\n9893/tcp                 Hubble Relay gops server (listening on 127.0.0.1)\n9901/tcp                 cilium-envoy Admin API (listening on 127.0.0.1)\n9962/tcp                 cilium-agent Prometheus metrics\n9963/tcp                 cilium-operator Prometheus metrics\n9964/tcp                 cilium-envoy Prometheus metrics\n51871/udp                WireGuard encryption tunnel endpoint\n======================== ==================================================================\n\n.. _admin_mount_bpffs:\n\nMounted eBPF filesystem\n=======================\n\n.. Note::\n\n        Some distributions mount the bpf filesystem automatically. Check if the\n        bpf filesystem is mounted by running the command.\n\n        .. code-block:: shell-session\n\n            # mount | grep /sys/fs/bpf\n            $ # if present should output, e.g. \"none on /sys/fs/bpf type bpf\"...\n\nIf the eBPF filesystem is not mounted in the host filesystem, Cilium will\nautomatically mount the filesystem.\n\nMounting this BPF filesystem allows the ``cilium-agent`` to persist eBPF\nresources across restarts of the agent so that the datapath can continue to\noperate while the agent is subsequently restarted or upgraded.\n\nOptionally it is also possible to mount the eBPF filesystem before Cilium is\ndeployed in the cluster, the following command must be run in the host mount\nnamespace. The command must only be run once during the boot process of the\nmachine.\n\n   .. code-block:: shell-session\n\n\t# mount bpffs /sys/fs/bpf -t bpf\n\nA portable way to achieve this with persistence is to add the following line to\n``/etc/fstab`` and then run ``mount /sys/fs/bpf``. This will cause the\nfilesystem to be automatically mounted when the node boots.\n\n::\n\n     bpffs\t\t\t/sys/fs/bpf\t\tbpf\tdefaults 0 0\n\nIf you are using systemd to manage the kubelet, see the section\n:ref:`bpffs_systemd`.\n\nRouting Tables\n==============\n\nWhen running in :ref:`ipam_eni` IPAM mode, Cilium will install per-ENI routing\ntables for each ENI that is used by Cilium for pod IP allocation.\nThese routing tables are added to the host network namespace and must not be\notherwise used by the system.\nThe index of those per-ENI routing tables is computed as\n``10 + <eni-interface-index>``. The base offset of 10 is chosen as it is highly\nunlikely to collide with the main routing table which is between 253-255.\n\nCilium uses the following routing table IDs:\n\n================= =========================================================\nRoute table ID    Purpose\n================= =========================================================\n200               IPsec routing rules\n202               VTEP routing rules\n2004              Routing rules to the proxy\n2005              Routing rules from the proxy\n================= =========================================================\n\nCilium manages these routing table IDs even if none of the related features are in use.\n\nPrivileges\n==========\n\nThe following privileges are required to run Cilium. When running the standard\nKubernetes :term:`DaemonSet`, the privileges are automatically granted to Cilium.\n\n* Cilium interacts with the Linux kernel to install eBPF program which will then\n  perform networking tasks and implement security rules. In order to install\n  eBPF programs system-wide, ``CAP_SYS_ADMIN`` privileges are required. These\n  privileges must be granted to ``cilium-agent``.\n\n  The quickest way to meet the requirement is to run ``cilium-agent`` as root\n  and/or as privileged container.\n\n* Cilium requires access to the host networking namespace. For this purpose,\n  the Cilium pod is scheduled to run in the host networking namespace directly.",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/operations/system_requirements.rst",
  "extracted_at": "2025-09-03T01:13:29.351161Z"
}
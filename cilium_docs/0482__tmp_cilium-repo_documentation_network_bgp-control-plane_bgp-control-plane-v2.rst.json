{
  "url": "file:///tmp/cilium-repo/Documentation/network/bgp-control-plane/bgp-control-plane-v2.rst",
  "content": ".. only:: not (epub or latex or html) \n WARNING: You are looking at unreleased Cilium documentation.\nPlease use the official rendered version released here:\nhttps://docs.cilium.io\n \n .. _bgp_control_plane_v2: \n BGP Control Plane Resources\n########################### \n Cilium BGP control plane is managed by a set of custom resources which provide a flexible way to\nconfigure BGP peers, policies, and advertisements. \n The following resources are used to manage the BGP Control Plane: \n \n CiliumBGPClusterConfig : Defines BGP instances and peer configurations that are applied to multiple nodes. \n CiliumBGPPeerConfig : A common set of BGP peering setting. It can be used across multiple peers. \n CiliumBGPAdvertisement : Defines prefixes that are injected into the BGP routing table. \n CiliumBGPNodeConfigOverride : Defines node-specific BGP configuration to provide a finer control. \n \n The relationship between various resources is shown in the below diagram: \n .. image:: bgpv2.png\n:align: center \n BGP Cluster Configuration \n CiliumBGPClusterConfig  resource is used to define BGP configuration for one or more nodes in\nthe cluster based on its  nodeSelector  field. Each  CiliumBGPClusterConfig  defines one or\nmore BGP instances, which are uniquely identified by their  name  field. \n A BGP instance can have one or more peers. Each peer is uniquely identified by its  name  field. The Peer\nautonomous system number and peer address are defined by the  peerASN  and  peerAddress  fields,\nrespectively. The configuration of the peers is defined by the  peerConfigRef  field, which is a reference\nto a peer configuration resource.  Group  and  kind  in  peerConfigRef  are optional and default to\n cilium.io  and  CiliumBGPPeerConfig , respectively. \n By default, the BGP Control Plane instantiates each router instance without a listening port. This means\nthe BGP router can only initiate connections to the configured peers, but cannot accept incoming connections.\nThis is the default behavior because the BGP Control Plane is designed to function in environments where\nanother BGP router (such as Bird) is running on the same node. When it is required to accept incoming\nconnections, the  localPort  field can be used to specify the listening port. \n .. warning:: \n The ``CiliumBGPPeeringPolicy`` and ``CiliumBGPClusterConfig`` should not be used together. If both\nresources are present and Cilium agent matches with both based on the node selector,\n``CiliumBGPPeeringPolicy`` will take precedence.\n \n .. warning:: \n Listening on the default BGP port (179) requires ``CAP_NET_BIND_SERVICE``.\nIf you wish to use the default port, you must grant the\n``CAP_NET_BIND_SERVICE`` capability with\n``securityContext.capabilities.ciliumAgent`` Helm value.\n \n Here is an example configuration of the  CiliumBGPClusterConfig  with a BGP instance named  instance-65000 \nand two peers configured under this BGP instance. \n .. code-block:: yaml \n apiVersion: cilium.io/v2\nkind: CiliumBGPClusterConfig\nmetadata:\n  name: cilium-bgp\nspec:\n  nodeSelector:\n    matchLabels:\n      rack: rack0\n  bgpInstances:\n  - name: \"instance-65000\"\n    localASN: 65000\n    localPort: 179\n    peers:\n    - name: \"peer-65000-tor1\"\n      peerASN: 65000\n      peerAddress: fd00:10:0:0::1\n      peerConfigRef:\n        name: \"cilium-peer\"\n    - name: \"peer-65000-tor2\"\n      peerASN: 65000\n      peerAddress: fd00:11:0:0::1\n      peerConfigRef:\n        name: \"cilium-peer\"\n \n Auto-Discovery \n Cilium BGP Control Plane also supports automatic discovery of BGP peers. \n When enabled, the auto-discovery feature self-configures the BGP peer's IP address automatically. Selection of the specific address is dependent on the  mode  enabled. \n Cilium BGP Control Plane currently supports  DefaultGateway  mode for auto-discovery under  autoDiscovery  field in  CiliumBGPClusterConfig . \n Default Gateway Auto-Discovery\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n The default gateway auto-discovery mode allows Cilium to automatically discover and establish BGP session with the default gateway (typically a Top-of-Rack (ToR) switch) for a specified address family. \n To enable default gateway auto-discovery, configure the  autoDiscovery  field in the peer configuration: \n .. code-block:: yaml \n peers:\n- name: \"tor-switch\"\n  peerASN: 65000\n  autoDiscovery:\n    mode: \"DefaultGateway\"\n    defaultGateway:\n      addressFamily: ipv6  # Can be \"ipv4\" or \"ipv6\"\n  peerConfigRef:\n    name: \"cilium-peer\"\n \n Here are the ToR switch BGP configuration requirements: \n \n \n ToR switches must be configured with \"bgp listen range\" to support dynamic BGP neighbors. This configuration enables the ToR switch to accept BGP sessions from Cilium nodes by listening for connections from a specific IP prefix range, eliminating the need to know the exact peer address of each Cilium node. \n For more details, see the  FRR documentation <https://docs.frrouting.org/en/latest/bgp.html#clicmd-bgp-listen-range-A.B.C.D-M-X-X-X-X-M-peer-group-PGNAME> __. \n \n \n Configure each ToR switch with the same local ASN (Autonomous System Number) to ensure Cilium configuration remains consistent across all cluster nodes. \n \n \n For example:: \n router bgp 65100\nneighbor CILIUM peer-group\nneighbor CILIUM local-as 65000 no-prepend replace-as\nbgp listen range fd00:10:0:1::/64 peer-group CILIUM \n Once this configuration is applied: \n \n Cilium determines the default gateway for the specified address family on each node \n It automatically establishes a BGP session with the discovered gateway \n It uses the peer configuration referenced by  peerConfigRef  for session parameters \n \n .. warning:: \n Link-local address as default gateway is not supported. \n Multi-homing with Default Gateway Auto-Discovery\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n In multi-homing setups, the Cilium node connects to two different Top-of-Rack switches. It discovers both the default gateways, but it\npicks the default route with the lower metric to establish the BGP session. It's important to note that Cilium creates only one BGP session per address family\nat a time. A failure or a change of the default route with the lower metric triggers a reconciliation to establish the BGP session with the default gateway\nof the other default route. \n Example configuration: \n .. code-block:: yaml \n bgpInstances:\n- name: \"65001\"\n  localASN: 65001\n  peers:\n  - name: \"instance-65001\"\n    peerASN: 65000\n    autoDiscovery:\n      mode: \"DefaultGateway\"\n      defaultGateway:\n        addressFamily: ipv6\n    peerConfigRef:\n      name: \"cilium-peer\"\n \n Verification \n \nTo verify that BGP sessions are established with the auto-discovered peers, use the ``cilium bgp peers`` command:\n\n.. code-block:: shell-session\n\n    $ cilium bgp peers\n    Local AS   Peer AS   Peer Address         Session       Uptime   Family         Received   Advertised\n    65001      65000     fd00:10:0:1::1:179   established   21m55s   ipv4/unicast   2          2    \n                                                                     ipv6/unicast   2          2\n\nLimitations\n~~~~~~~~~~~\nAuto Discovery with ``DefaultGateway`` mode in multi-homing setup can not be used to create multiple BGP sessions for the same address family.\nCurrently, the only workaround is to configure the peer address manually for each peer.\n\n.. _bgp_peer_configuration:\n\nBGP Peer Configuration\n======================\n\nThe ``CiliumBGPPeerConfig`` resource is used to define a BGP peer configuration. Multiple peers can\nshare the same configuration and provide reference to the common ``CiliumBGPPeerConfig``\nresource.\n\nThe ``CiliumBGPPeerConfig`` resource contains configuration options for:\n\n- :ref:`MD5 Password <bgp_peer_configuration_password>`\n- :ref:`Timers <bgp_peer_configuration_timers>`\n- :ref:`EBGP Multihop <bgp_ebgp_multihop>`\n- :ref:`Graceful Restart <bgp_peer_configuration_graceful_restart>`\n- :ref:`Transport <bgp_peer_configuration_transport>`\n- :ref:`Address Families <bgp_peer_configuration_afi>`\n\nHere is an example configuration of the ``CiliumBGPPeerConfig`` resource. In the next\nsection, we will go over each configuration option.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      timers:\n        holdTimeSeconds: 9\n        keepAliveTimeSeconds: 3\n      authSecretRef: bgp-auth-secret\n      ebgpMultihop: 4\n      gracefulRestart:\n        enabled: true\n        restartTimeSeconds: 15\n      families:\n        - afi: ipv4\n          safi: unicast\n          advertisements:\n            matchLabels:\n              advertise: \"bgp\"\n\n\n.. _bgp_peer_configuration_password:\n\nMD5 Password\n------------\n\n``AuthSecretRef`` in ``CiliumBGPPeerConfig`` can be used to configure an `RFC-2385`_ TCP MD5 password\non the session with the BGP peer which references this configuration.\n\n\nHere is an example of setting ``authSecretRef``:\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      authSecretRef: bgp-auth-secret\n\n``AuthSecretRef`` should reference the name of a secret in the BGP secrets\nnamespace (if using the Helm chart this is ``kube-system`` by default). The\nsecret should contain a key with a name of ``password``.\n\nBGP secrets are limited to a configured namespace to keep the permissions\nneeded on each Cilium Agent instance to a minimum. The Helm chart will\nconfigure Cilium to be able to read from it by default.\n\nAn example of creating a secret is:\n\n.. code-block:: shell-session\n\n   $ kubectl create secret generic -n kube-system --type=string secretname --from-literal=password=my-secret-password\n\nIf you wish to change the namespace, you can set the\n``bgpControlPlane.secretNamespace.name`` Helm chart value. To have the\nnamespace created automatically, you can set the\n``bgpControlPlane.secretNamespace.create`` Helm chart value  to ``true``.\n\nBecause TCP MD5 passwords sign the header of the packet they cannot be used if\nthe session is address-translated by Cilium (in other words, the Cilium Agent's pod\nIP address must be the address that the BGP peer sees).\n\nIf the password is incorrect, or if the header is otherwise changed, then the TCP\nconnection will not succeed. This will appear as ``dial: i/o timeout`` in the\nCilium Agent's logs rather than a more specific error message.\n\n.. _RFC-2385 : https://www.rfc-editor.org/rfc/rfc2385.html\n\nIf a ``CiliumBGPPeerConfig`` is deployed with an ``authSecretRef`` that Cilium cannot find,\nthe BGP session will use an empty password and the agent will log an error such as in the following example::\n\n    level=error msg=\"Failed to fetch secret \\\"secretname\\\": not found (will continue with empty password)\" component=manager.fetchPeerPassword subsys=bgp-control-plane\n\n.. _bgp_peer_configuration_timers:\n\nTimers\n------\n\nBGP Control Plane supports modifying the following BGP timer parameters. For\nmore detailed description for each timer parameters, please refer to `RFC4271\n<https://datatracker.ietf.org/doc/html/rfc4271>`__.\n\n================= ============================ ==========\nName              Field                        Default\n----------------- ---------------------------- ----------\nConnectRetryTimer ``connectRetryTimeSeconds``  120\nHoldTimer         ``holdTimeSeconds``          90\nKeepaliveTimer    ``keepAliveTimeSeconds``     30\n================= ============================ ==========\n\nIn datacenter networks where Kubernetes clusters are deployed, it is generally\nrecommended to set the ``HoldTimer`` and ``KeepaliveTimer`` to a lower value\nfor faster possible failure detection. For example, you can set the minimum\npossible values ``holdTimeSeconds=9`` and ``keepAliveTimeSeconds=3``.\n\nTo ensure a fast reconnection after losing connectivity with the peer,\nreduce the ``connectRetryTimeSeconds`` (for example to ``5`` or less).\nAs random jitter is applied to the configured value internally, the actual value used for the\n``ConnectRetryTimer`` is within the interval ``[ConnectRetryTimeSeconds, 2 * ConnectRetryTimeSeconds)``.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      timers:\n        connectRetryTimeSeconds: 5\n        holdTimeSeconds: 9\n        keepAliveTimeSeconds: 3\n\n.. _bgp_ebgp_multihop:\n\nEBGP Multihop\n-------------\n\nBy default, IP TTL of the BGP packets is set to 1 in eBGP. Generally, it is\nencouraged to not change the TTL, but in some cases, you may need to change the\nTTL value. For example, when the BGP peer is a Route Server and located in a\ndifferent subnet, you may need to set the TTL value to more than 1.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      ebgpMultihop: 4 # <-- specify the TTL value\n\n.. _bgp_peer_configuration_graceful_restart:\n\nGraceful Restart\n----------------\n\nThe Cilium BGP Control Plane can be configured to act as a graceful restart\n``Restarting Speaker``. When you enable graceful restart, the BGP session restarts\nand the \"graceful restart\" capability is advertised in the BGP OPEN message.\n\nIn the event of a Cilium Agent restart, the peering BGP router does not withdraw\nroutes received from the Cilium BGP control plane immediately. The datapath\ncontinues to forward traffic during Agent restart, so there is no traffic\ndisruption.\n\nOptionally, you can use the ``restartTimeSeconds`` parameter. ``RestartTime`` is the time\nadvertised to the peer within which Cilium BGP control plane is expected to re-establish\nthe BGP session after a restart. On expiration of ``RestartTime``, the peer removes\nthe routes previously advertised by the Cilium BGP control plane.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      gracefulRestart:\n        enabled: true\n        restartTimeSeconds: 15\n\nWhen the Cilium Agent restarts, it closes the BGP TCP socket, causing the emission of a\nTCP FIN packet. On receiving this TCP FIN, the peer changes its BGP state to ``Idle`` and\nstarts its ``RestartTime`` timer.\n\nThe Cilium agent boot up time varies depending on the deployment. If using ``RestartTime``,\nyou should set it to a duration greater than the time taken by the Cilium Agent to boot up.\n\nDefault value of ``RestartTime`` is 120 seconds. More details on graceful restart and\n``RestartTime`` can be found in `RFC-4724`_ and `RFC-8538`_.\n\n.. _RFC-4724 : https://www.rfc-editor.org/rfc/rfc4724.html\n.. _RFC-8538 : https://www.rfc-editor.org/rfc/rfc8538.html\n\n\n.. _bgp_peer_configuration_transport:\n\nTransport\n---------\n\nThe transport section of ``CiliumBGPPeerConfig`` can be used to configure a custom\ndestination port for a peer's BGP session.\n\nBy default, when BGP is operating in `active mode <https://datatracker.ietf.org/doc/html/rfc4271#section-8.2.1>`_\n(with the Cilium agent initiating the TCP connection), the destination port is 179 and the source port is ephemeral.\n\nHere is an example of setting the transport configuration:\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      transport:\n        peerPort: 179\n\n\n.. _bgp_peer_configuration_afi:\n\nAddress Families\n----------------\n\nThe ``families`` field is a list of AFI (Address Family Identifier), SAFI (Subsequent Address\nFamily Identifier) pairs, and advertisement selector. The only AFI/SAFI options currently supported are\n``{afi: ipv4, safi: unicast}`` and ``{afi: ipv6, safi: unicast}``.\n\nBy default, if no address families are specified, BGP Control Plane sends both IPv4 Unicast and IPv6 Unicast\nMultiprotocol Extensions Capability (`RFC-4760`_) to the peer.\n\nIn each address family, you can control the route publication via the ``advertisements`` label selector.\nVarious advertisements types are defined :ref:`here <bgp-adverts>`.\n\n.. note::\n\n    Without matching advertisements, no prefix will be advertised to the peer.\n    Default configuration is to not advertise any prefix.\n\n.. _RFC-4760 : https://www.rfc-editor.org/rfc/rfc4760.html\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPPeerConfig\n    metadata:\n      name: cilium-peer\n    spec:\n      families:\n        - afi: ipv4\n          safi: unicast\n          advertisements:\n            matchLabels:\n              advertise: \"bgp\"\n        - afi: ipv6\n          safi: unicast\n          advertisements:\n            matchLabels:\n              advertise: \"bgp\"\n\n\n.. _bgp-adverts:\n\nBGP Advertisements\n==================\n\nThe ``CiliumBGPAdvertisement`` resource is used to define various advertisement types and attributes\nassociated with them. The ``advertisements`` label selector defined in the ``families`` field of a\n:ref:`peer configuration <bgp_peer_configuration_afi>` may match with one or more of the ``CiliumBGPAdvertisement``\nresources.\n\nBGP Attributes\n--------------\nYou can configure BGP path attributes for the prefixes advertised by Cilium BGP\ncontrol plane using ``attributes`` field in ``advertisements[*]``. There are two types of Path\nAttributes that can be advertised: ``Communities`` and ``LocalPreference``.\n\nHere is an example configuration of the ``CiliumBGPAdvertisement`` resource that advertises\npod prefixes with the community value of \"65000:99\" and local preference of 99.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: bgp-advertisements\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"PodCIDR\"\n          attributes:\n            communities:\n              standard: [ \"65000:99\" ]\n            localPreference: 99\n\n\nCommunity\n^^^^^^^^^\n\n``Communities`` defines a set of community values advertised in the supported BGP Communities\nPath Attributes.\n\nThe values can be of three types:\n\n - ``Standard``: represents a value of the \"standard\" 32-bit BGP Communities Attribute (`RFC-1997`_)\n   as a 4-byte decimal number or two 2-byte decimal numbers separated by a colon (for example: ``64512:100``).\n - ``WellKnown``: represents a value of the \"standard\" 32-bit BGP Communities Attribute (`RFC-1997`_)\n   as a well-known string alias to its numeric value. Allowed values and their mapping to the numeric values\n   are displayed in the following table:\n\n    =============================== ================= =================\n    Well-Known Value                Hexadecimal Value 16-bit Pair Value\n    ------------------------------- ----------------- -----------------\n    ``internet``                    ``0x00000000``    ``0:0``\n    ``planned-shut``                ``0xffff0000``    ``65535:0``\n    ``accept-own``                  ``0xffff0001``    ``65535:1``\n    ``route-filter-translated-v4``  ``0xffff0002``    ``65535:2``\n    ``route-filter-v4``             ``0xffff0003``    ``65535:3``\n    ``route-filter-translated-v6``  ``0xffff0004``    ``65535:4``\n    ``route-filter-v6``             ``0xffff0005``    ``65535:5``\n    ``llgr-stale``                  ``0xffff0006``    ``65535:6``\n    ``no-llgr``                     ``0xffff0007``    ``65535:7``\n    ``blackhole``                   ``0xffff029a``    ``65535:666``\n    ``no-export``                   ``0xffffff01``    ``65535:65281``\n    ``no-advertise``                ``0xffffff02``    ``65535:65282``\n    ``no-export-subconfed``         ``0xffffff03``    ``65535:65283``\n    ``no-peer``                     ``0xffffff04``    ``65535:65284``\n    =============================== ================= =================\n\n - ``Large``: represents a value of the BGP Large Communities Attribute (`RFC-8092`_),\n   as three 4-byte decimal numbers separated by colons (for example: ``64512:100:50``).\n\n.. _RFC-1997 : https://www.rfc-editor.org/rfc/rfc1997.html\n.. _RFC-8092 : https://www.rfc-editor.org/rfc/rfc8092.html\n\nLocal Preference\n^^^^^^^^^^^^^^^^\n\n``LocalPreference`` defines the preference value advertised in the BGP Local Preference Path Attribute.\nAs Local Preference is only valid for ``iBGP`` peers, this value will be ignored for ``eBGP`` peers\n(no Local Preference Path Attribute will be advertised).\n\nAdvertisement Types\n-------------------\n\nThe following advertisement types are supported by Cilium:\n\n- :ref:`Pod CIDR ranges <bgp-adverts-podcidr>`\n- :ref:`Service Virtual IPs <bgp-adverts-service>`\n\n.. _bgp-adverts-podcidr:\n\nPod CIDR Ranges\n^^^^^^^^^^^^^^^\n\nThe BGP Control Plane can advertise the Pod CIDR prefixes of the nodes. This allows the BGP peers and\nthe connected network to reach the Pods directly without involving load balancers or NAT. There are\ntwo ways to advertise PodCIDRs depending on the IPAM mode setting.\n\n.. note::\n\n    Cilium BGP control plane advertises pod CIDR allocated to the node and not the entire range.\n\nKubernetes and ClusterPool IPAM\n \n When :ref: Kubernetes <k8s_hostscope>  or :ref: ClusterPool <ipam_crd_cluster_pool>  IPAM is used, set advertisement type to  PodCIDR . \n .. code-block:: yaml \n apiVersion: cilium.io/v2\nkind: CiliumBGPAdvertisement\nmetadata:\n  name: bgp-advertisements\n  labels:\n    advertise: bgp\nspec:\n  advertisements:\n    - advertisementType: \"PodCIDR\"\n \n With this configuration, the BGP instance on the node advertises the\nPod CIDR prefixes assigned to the local node. \n .. _bgp-adverts-multipool: \n MultiPool IPAM \n \nWhen :ref:`MultiPool IPAM <ipam_crd_multi_pool>` is used, specify the\n``advertisementType`` field to ``CiliumPodIPPool``. The ``selector`` field\nis a label selector that selects ``CiliumPodIPPool`` matching the specified ``.matchLabels``\nor ``.matchExpressions``.\n\n.. code-block:: yaml\n\n    ---\n    apiVersion: cilium.io/v2\n    kind: CiliumPodIPPool\n    metadata:\n      name: default\n      labels:\n        pool: blue\n\n    ---\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: pod-ip-pool-advert\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"CiliumPodIPPool\"\n          selector:\n            matchLabels:\n              pool: \"blue\"\n\nThis configuration advertises the PodCIDR prefixes allocated from the selected\nCilium pod IP pools. Note that the CIDR must be allocated to a ``CiliumNode`` resource.\n\nIf you wish to announce *all* CiliumPodIPPool CIDRs within the cluster, a ``NotIn`` match\nexpression with a dummy key and value can be used like this:\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: pod-ip-pool-advert\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"CiliumPodIPPool\"\n          selector:\n            matchExpressions:\n            - {key: somekey, operator: NotIn, values: ['never-used-value']}\n\n\nThere are two special-purpose selector fields that match CiliumPodIPPools based on ``name`` and/or\n``namespace`` metadata instead of labels:\n\n=============================== ===================\nSelector                        Field\n------------------------------- -------------------\nio.cilium.podippool.namespace   ``.meta.namespace``\nio.cilium.podippool.name        ``.meta.name``\n=============================== ===================\n\nFor additional details regarding CiliumPodIPPools, see the :ref:`ipam_crd_multi_pool` section.\n\nOther IPAM Types\n \n When using other IPAM types, the BGP Control Plane does not support advertising\nPodCIDRs and specifying  advertisementType: \"PodCIDR\"  doesn't have any\neffect. \n .. _bgp-adverts-service: \n Service Virtual IPs\n^^^^^^^^^^^^^^^^^^^ \n In Kubernetes, a Service can have multiple virtual IP addresses,\nsuch as  .spec.clusterIP ,  .spec.clusterIPs ,  .status.loadBalancer.ingress[*].ip \nor  .spec.externalIPs . \n The BGP control plane can advertise the virtual IP address of the Service to BGP peers.\nThis allows you to directly access the Service from outside the cluster. \n .. note::\nCilium BGP Control Plane advertises exact routes for the VIPs ( /32 or /128 prefixes ). \n To advertise the service virtual IPs, specify the  advertisementType  field to  Service \nand the  service.addresses  field to  LoadBalancerIP ,  ClusterIP  or  ExternalIP . \n The  .selector  field is a label selector that selects Services matching the specified  .matchLabels \nor  .matchExpressions . \n .. code-block:: yaml \n apiVersion: cilium.io/v2\nkind: CiliumBGPAdvertisement\nmetadata:\n  name: bgp-advertisements\n  labels:\n    advertise: bgp\nspec:\n  advertisements:\n    - advertisementType: \"Service\"\n      service:\n        addresses:\n          - ClusterIP\n          - ExternalIP\n          - LoadBalancerIP\n      selector:\n        matchExpressions:\n          - { key: bgp, operator: In, values: [ blue ] }\n \n When your upstream router supports Equal Cost Multi Path (ECMP), you can use\nthis feature to load-balance traffic to the Service across multiple nodes by\nadvertising the same virtual IPs from multiple nodes. \n .. warning:: \n Many routers have a limit on the number of ECMP paths they can hold in their\nrouting table ( Juniper    <https://www.juniper.net/documentation/us/en/software/junos/cli-reference/topics/ref/statement/maximum-ecmp-edit-chassis.html> __).\nWhen advertising the Service VIPs from many nodes, you may exceed this\nlimit. We recommend checking the limit with your network administrator\nbefore using this feature. \n ExternalIP \n \nIf you wish to use this together with ``kubeProxyReplacement`` feature  (see :ref:`kubeproxy-free` docs),\nplease make sure the ExternalIP support is enabled.\n\nIf you only wish to advertise the ``.spec.externalIPs`` of a Service, you can specify the\n``service.addresses`` field as ``ExternalIP``.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: bgp-advertisements\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"Service\"\n          service:\n            addresses:                  # <-- specify the service types to advertise\n              - ExternalIP\n          selector:                     # <-- select Services to advertise\n            matchExpressions:\n              - { key: bgp, operator: In, values: [ blue ] }\n\n\n\nClusterIP\n~~~~~~~~~\n\nIf you wish to use this together with ``kubeProxyReplacement`` feature  (see :ref:`kubeproxy-free` docs),\nspecific BPF parameters need to be enabled.\nSee :ref:`External Access To ClusterIP Services <external_access_to_clusterip_services>` section\nfor how to enable it.\n\nIf you only wish to advertise the ``.spec.clusterIP`` and ``.spec.clusterIPs`` of a Service,\nyou can specify the ``virtualRouters[*].serviceAdvertisements`` field as ``ClusterIP``.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: bgp-advertisements\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"Service\"\n          service:\n            addresses:          # <-- specify the service types to advertise\n              - ClusterIP\n          selector:             # <-- select Services to advertise\n            matchExpressions:\n              - { key: bgp, operator: In, values: [ blue ] }\n\n\nLoad Balancer IP\n \n You must first allocate ingress IPs to advertise them. By default, Kubernetes\ndoesn't provide a way to assign ingress IPs to a Service. The cluster\nadministrator is responsible for preparing a controller that assigns ingress\nIPs. Cilium supports assigning ingress IPs with the :ref: Load Balancer IPAM <lb_ipam>  feature. \n .. code-block:: yaml \n apiVersion: cilium.io/v2\nkind: CiliumBGPAdvertisement\nmetadata:\n  name: bgp-advertisements\n  labels:\n    advertise: bgp\nspec:\n  advertisements:\n    - advertisementType: \"Service\"\n      service:\n        addresses:          # <-- specify the service types to advertise\n          - LoadBalancerIP\n      selector:             # <-- select Services to advertise\n        matchExpressions:\n          - { key: bgp, operator: In, values: [ blue ] }\n \n This advertises the ingress IPs of all Services matching the  .selector . \n If you wish to announce  all  services within the cluster, a  NotIn  match expression\nwith a dummy key and value can be used like this: \n .. code-block:: yaml \n apiVersion: cilium.io/v2\nkind: CiliumBGPAdvertisement\nmetadata:\n  name: bgp-advertisements\n  labels:\n    advertise: bgp\nspec:\n  advertisements:\n    - advertisementType: \"Service\"\n      service:\n        addresses:          # <-- specify the service types to advertise\n          - LoadBalancerIP\n      selector:             # <-- select all services\n        matchExpressions:\n         - {key: somekey, operator: NotIn, values: ['never-used-value']}\n \n There are a few special purpose selector fields that don't match on labels but\ninstead on other metadata like  .meta.name  or  .meta.namespace . \n =============================== ===================\nSelector                        Field \n \n io.kubernetes.service.namespace  .meta.namespace \nio.kubernetes.service.name       .meta.name \n=============================== =================== \n Load Balancer Class \n \nCilium supports the `loadBalancerClass\n<https://kubernetes.io/docs/concepts/services-networking/service/#load-balancer-class>`__.\nWhen the load balancer class is set to ``io.cilium/bgp-control-plane`` or unspecified,\nCilium announces the ingress IPs of the Service. Otherwise, Cilium does not announce\nthe ingress IPs of the Service.\n\nExternalTrafficPolicy/InternalTrafficPolicy\n \n In the case of a load-balancer ingress IP or external IP advertisements,\nif the Service has  externalTrafficPolicy: Cluster , BGP Control Plane\nunconditionally advertises the IPs of the selected Service. When the\nService has  externalTrafficPolicy: Local , BGP Control Plane keeps track of\nthe endpoints for the service on the local node and stops advertisement when\nthere's no local endpoint. \n Similarly,  internalTrafficPolicy  is considered for  ClusterIP  advertisements. \n .. note:: \n It is worth noting that when you configure ``service.addresses`` as ``ClusterIP``,\nthe BGP Control Plane only considers the configuration of the matching service's ``.spec.internalTrafficPolicy``\nand ignores the configuration of ``.spec.externalTrafficPolicy``. For ``ExternalIP`` and\n``LoadBalancerIP``, it only considers the configuration of the service's ``.spec.externalTrafficPolicy``\nand ignores the configuration of ``.spec.internalTrafficPolicy``.\n \n Overlapping Advertisements \n \nWhen configuring ``CiliumBGPAdvertisement``, it is possible that two or more\nadvertisements match the same Service. Prior to Cilium 1.18, overlapping matches \nwere not expected and the last sequential match was used. Today, overlapping \nadvertisement selectors are supported. Overlap handling varies by attribute:\n\n* Communities: the union of elements is taken across all matches\n* Local Preference: the largest value is selected\n\nAs an example, below we have two advertisements which each define a selector \nmatch. One matches on the label ``vpc1`` while the other on ``vpc2``.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: bgp-advertisements\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"Service\"\n          service:\n            addresses:\n              - LoadBalancerIP\n          selector:\n            matchExpressions:\n              - { key: vpc1, operator: In, values: [ \"true\" ] }\n          attributes:\n            communities:\n              large: [ \"1111:1111:1111\" ]\n        - advertisementType: \"Service\"\n          service:\n            addresses:\n              - LoadBalancerIP\n          selector:\n            matchExpressions:\n              - { key: vpc2, operator: In, values: [ \"true\" ] }\n          attributes:\n            communities:\n              large: [ \"2222:2222:2222\" ]\n\nWe have a deployment named ``hello-world`` which exposes a ``LoadBalancer`` \nService. Initially, there were no labels configured. This resulted in no matches, and\nno BGP advertisements.\n\n.. code-block:: shell-session\n\n    kubectl get deployment\n    NAME          READY   UP-TO-DATE   AVAILABLE   AGE\n    hello-world   1/1     1            1           42m\n\n    kubectl get service hello-world --show-labels\n    NAME          TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE   LABELS\n    hello-world   LoadBalancer   10.2.65.71   <pending>     8080:30569/TCP   43m   app=hello-world\n\n\nLabels were then configured using:\n\n.. code-block:: shell-session\n\n    kubectl label service hello-world vpc1=true\n    kubectl label service hello-world vpc1=true\n\nThe resulting BGP advertisement set both communities ``1111:1111:1111`` and ``2222:2222:2222``.\nAll possible combinations of communities (``Standard``, ``Large``, ``WellKnown``) are \nsupported. Had Local Preference been set, it would have been the largest value observed \nacross all matches. This is in line with `RFC4271 <https://datatracker.ietf.org/doc/rfc4271/>`_ \nwhich states *The higher degree of preference MUST be preferred.*\n\n\nPrefix Aggregation\n~~~~~~~~~~~~~~~~~~\n\nBy default, the Cilium BGP Control Plane advertises exact routes for service\nVIPs (/32 or /128 prefixes). You can modify the advertised prefix length with\nthe ``.service.aggregationLengthIPv4`` and/or ``.service.aggregationLengthIPv6``\nfields (for IPv4 and/or IPv6 prefixes respectively) as in the following example:\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPAdvertisement\n    metadata:\n      name: bgp-advertisements\n      labels:\n        advertise: bgp\n    spec:\n      advertisements:\n        - advertisementType: \"Service\"\n          service:\n            aggregationLengthIPv4: 24\n            aggregationLengthIPv6: 120\n            addresses:\n              - ClusterIP\n              - ExternalIP\n              - LoadBalancerIP\n          selector:\n            matchExpressions:\n              - { key: bgp, operator: In, values: [ blue ] }\n\n.. note::\n\n    The ``.service.aggregationLengthIPv4`` / ``.service.aggregationLengthIPv6``\n    fields are ignored when advertising ``ExternalIP`` or ``LoadBalancerIP`` of\n    services with ``externalTrafficPolicy: Local``. Similarly, they are\n    ignored when advertising ``ClusterIP`` of services with\n    ``internalTrafficPolicy: Local``.\n\nThere are some known issues for using this feature:\n\n* Prefix aggregation in general has a risk of creating black holes or routing\n  loops when you advertise routes that cannot be handled well by the\n  datapath. In Cilium, there's a known issue where sending traffic to a VIP\n  range not assigned to a Service causes a routing loop (see `this issue\n  <https://github.com/cilium/cilium/pull/37623>`__ for more details). This means\n  that if you advertise an aggregated prefix, and part of the address range is not\n  assigned to a Service, then traffic sent to that address will end up\n  in a routing loop.\n\n* The behavior is undefined when multiple Service advertisements\n  end up advertising the same prefix through aggregation, but with different path\n  attributes. You can track `this issue\n  <https://github.com/cilium/cilium/issues/40585>`__ for updates.\n\n.. _bgp-override:\n\nBGP Configuration Override\n==========================\n\nThe ``CiliumBGPNodeConfigOverride`` resource can be used to override some of the auto-generated configuration\non a per-node basis.\n\nHere is an example of the ``CiliumBGPNodeConfigOverride`` resource, that sets Router ID, local address and\nlocal autonomous system number used in each peer for the node with a name ``bgpv2-cplane-dev-multi-homing-worker``.\n\n.. code-block:: yaml\n\n    apiVersion: cilium.io/v2\n    kind: CiliumBGPNodeConfigOverride\n    metadata:\n      name: bgpv2-cplane-dev-multi-homing-worker\n    spec:\n      bgpInstances:\n        - name: \"instance-65000\"\n          routerID: \"192.168.10.1\"\n          localPort: 1790\n          localASN: 65010\n          peers:\n            - name: \"peer-65000-tor1\"\n              localAddress: fd00:10:0:2::2\n            - name: \"peer-65000-tor2\"\n              localAddress: fd00:11:0:2::2\n\n\n.. note::\n    The name of ``CiliumBGPNodeConfigOverride`` resource must match the name of the node for which the\n    configuration is intended. Similarly, the names of the BGP instance and peers must match with what\n    is defined under ``CiliumBGPClusterConfig``.\n\n    This is a per node configuration.\n\nRouterID\n--------\n\nThere is ``bgpControlPlane.routerIDAllocation.mode`` Helm chart value, which stipulates how the \nRouter ID is allocated. Currently, ``default`` and ``ip-pool`` are supported. The default allocation mode\nis ``default``.\n\nIn ``default`` mode, when Cilium runs on an IPv4 single-stack or a dual-stack, the BGP Control Plane \ncan use the IPv4 address assigned to the node as the BGP Router ID because the Router ID is 32 bit-long, \nand we can rely on the uniqueness of the IPv4 address to make the Router ID unique. When running in an IPv6 single-stack, \nthe lower 32 bits of MAC address of ``cilium_host`` interface are used as Router ID. \n\nIn ``ip-pool`` mode, you must provide an IPv4 IP pool like ``10.0.0.0/24`` to Cilium through the helm value \n``bgpControlPlane.routerIDAllocation.ipPool``. Cilium will then assign Router IDs to BGP instances from this configured pool.\n\nIf the auto assignment of the Router ID is not desired, you must manually define it.\nIn order to configure custom Router ID, you can set ``routerID`` field in an IPv4 address format. In ``default`` mode, \nyou can manually set any Router ID, and Cilium does not validate it. In ``ip-pool`` mode, if the Router ID is within the pool range, \nyou must ensure it does not conflict with others. If the Router ID is outside the pool, you can set it freely.\n\n\nListening Port\n--------------\n\nThe ``localPort`` field in the ``CiliumBGPClusterConfig`` can be used to\nspecify the listening port. If you wish to override it on a per-node basis, you\ncan set the ``localPort`` field in the ``CiliumBGPNodeConfigOverride``\nresource. This also works even if the ``localPort`` field is not set in the\n``CiliumBGPClusterConfig``.\n\nLocal Peering Address\n---------------------\n\nThe source interface and the address used by the BGP Control Plane in order to setup peering with the\nneighbor are based on a route lookup of the peer address defined in ``CiliumBGPClusterConfig``. There may be\nuse cases where multiple links are present on the node and you want tighter control over which link\nBGP peering should be setup.\n\nTo configure the source address, the ``peers[*].localAddress`` field can be set. It should be an\naddress configured on one of the links on the node.\n\nLocal ASN\n---------\n\nIt is possible to override the Autonomous System Number (ASN) of a node using the field ``LocalASN`` of the\n``CiliumBGPNodeConfigOverride`` resource. When this field is not defined, the ``LocalASN`` from the matching\n``CiliumBGPClusterConfig`` is used as local ASN for the node. This customization allows individual nodes to\noperate with a different ASN when required by the network design.\n\nSample Configurations\n=====================\n\nPlease refer to container lab examples in Cilium repository under `contrib/containerlab/bgpv2\n<https://github.com/cilium/cilium/tree/main/contrib/containerlab/bgpv2>`_.",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/network/bgp-control-plane/bgp-control-plane-v2.rst",
  "extracted_at": "2025-09-03T01:13:29.179803Z"
}
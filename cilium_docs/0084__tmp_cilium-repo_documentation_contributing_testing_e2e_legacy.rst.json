{
  "url": "file:///tmp/cilium-repo/Documentation/contributing/testing/e2e_legacy.rst",
  "content": ".. only:: not (epub or latex or html) \n WARNING: You are looking at unreleased Cilium documentation.\nPlease use the official rendered version released here:\nhttps://docs.cilium.io\n \n .. _testsuite-legacy: \n End-To-End Testing Framework (Legacy) \n .. warning::\nThe Ginkgo end-to-end testing framework is deprecated. New end-to-end\ntests should be implemented using the  cilium-cli    <https://github.com/cilium/cilium-cli/#connectivity-check> _ connectivity\ntesting framework. For more information, see :ref: testsuite . \n Introduction \n \nThis section provides an overview of the two modes available for running\nCilium's end-to-end tests locally: Kubeconfig and similar to GitHub Actions (GHA).\nIt offers instructions on setting up and running tests in these modes.\n\nBefore proceeding, it is recommended to familiarize yourself with Ginkgo by\nreading the `Ginkgo Getting-Started Guide\n<https://onsi.github.io/ginkgo/#getting-started>`_. You\ncan also run the `example tests\n<https://github.com/onsi/composition-ginkgo-example>`_ to get a feel for the\nGinkgo workflow.\n\nThe tests in the ``test`` directory are built on top of Ginkgo and utilize the\nGinkgo ``focus`` concept to determine which Kubernetes nodes are necessary to\nrun specific tests. All test names must begin with one of the following\nprefixes:\n\n- ``Runtime``: Tests Cilium in a runtime environment running on a single node.\n- ``K8s``: Sets up a small multi-node Kubernetes environment for testing features\n  beyond a single host and Kubernetes-specific functionalities.\n\n\nRunning Tests with GitHub Actions (GHA)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGitHub Actions provide an alternative mode for running Cilium's end-to-end tests.\nThe configuration is set up to closely match the environment used in GHA. Refer\nto the relevant documentation for instructions on running tests using GHA.\n\nRunning End-To-End Tests\n \n Running Locally Ginkgo Tests based on Ginkgo's GitHub Workflow\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n Although it is not possible to run  conformance-ginkgo.yaml  or\n conformance-runtime.yaml  locally, it is possible to setup an environment\nsimilar to the one used on GitHub. \n The following example will provide the steps to run one of the tests of the\nfocus  f09-datapath-misc-2  on Kubernetes  1.27  with the kernel  net-next \nfor the commit SHA  7b368923823e63c9824ea2b5ee4dc026bc4d5cd8 . \n You can also perform these steps automatically using the script\n contrib/scripts/run-gh-ginkgo-workflow.sh . Run this script with  -h  for\nusage information. \n #. Download dependencies locally ( helm ,  ginkgo ). \n For  helm , the instructions can be found  here <https://helm.sh/docs/intro/install/> _ \n .. code-block:: shell-session \n   $ HELM_VERSION=v3.13.1\n  $ wget \"https://get.helm.sh/helm-${HELM_VERSION}-linux-amd64.tar.gz\"\n  $ tar -xf \"helm-v${HELM_VERSION}-linux-amd64.tar.gz\"\n  $ mv linux-amd64/helm ./helm\n \n Store these dependencies under a specific directory that will be used to run\nQemu in the next steps. \n For  ginkgo , we will be using the same version used on GitHub action: \n .. code-block:: shell-session \n   $ cd ~/\n  $ go install github.com/onsi/ginkgo/ginkgo@v1.16.5\n  $ ${GOPATH}/bin/ginkgo version\n  Ginkgo Version 1.16.5\n \n #. Build the Ginkgo tests locally. This will create a binary named  test.test \nwhich we can use later on to run our tests. \n .. code-block:: shell-session \n   $ cd github.com/cilium/cilium/test\n  $ ${GOPATH}/bin/ginkgo build\n \n #. Provision VMs using Qemu: \n \n \n Retrieve the image tag for the k8s and kernel versions that will be used for\ntesting by checking the file  .github/actions/ginkgo/main-k8s-versions.yaml . \n For example: \n \n kernel:  bpf-next-20230526.105339@sha256:4133d4e09b1e86ac175df8d899873180281bb4220dc43e2566c47b0241637411 \n k8s:  kindest/node:v1.27.1@sha256:b7d12ed662b873bd8510879c1846e87c7e676a79fefc93e17b2a52989d3ff42b \n \n \n \n Store the compressed VM image under a directory ( /tmp/_images ). \n \n \n .. code-block:: shell-session \n   $ mkdir -p /tmp/_images\n  $ kernel_tag=\"bpf-next-20230526.105339@sha256:4133d4e09b1e86ac175df8d899873180281bb4220dc43e2566c47b0241637411\"\n  $ docker run -v /tmp/_images:/mnt/images \\\n     \"quay.io/lvh-images/kind:${kernel_tag}\" \\\n     cp -r /data/images/. /mnt/images/\n \n \n Uncompress the VM image into a directory. \n \n .. code-block:: shell-session \n   $ zstd -d /tmp/_images/kind_*.qcow2.zst -o /tmp/_images/datapath-conformance.qcow2\n \n \n Provision the VM.  Qemu will use the current terminal to provision the VM\nand will mount the current directory into the VM under   /host . \n \n .. code-block:: shell-session \n   $ qemu-system-x86_64 \\\n      -nodefaults \\\n      -no-reboot \\\n      -smp 4 \\\n      -m 12G \\\n      -enable-kvm \\\n      -cpu host \\\n      -drive file=/tmp/_images/datapath-conformance.qcow2,if=virtio,index=0,media=disk \\\n      -netdev user,id=user.0,hostfwd=tcp::2222-:22 \\\n      -device virtio-net-pci,netdev=user.0 \\\n      -fsdev local,id=host_id,path=./,security_model=none \\\n      -device virtio-9p-pci,fsdev=host_id,mount_tag=host_mount \\\n      -serial mon:stdio\n \n #. Installing dependencies in the VM ( helm ). \n .. code-block:: shell-session \n   $ ssh -p 2222 -o \"StrictHostKeyChecking=no\" root@localhost\n  # echo \"nameserver 8.8.8.8\" > /etc/resolv.conf\n  # git config --global --add safe.directory /host\n  # cp /host/helm /usr/bin\n \n .. _install_kind: \n #. The VM is ready to be used for tests. Similarly to the GitHub Action, Kind\nwill also be used to run the CI. The provisioning of Kind is different\ndepending on the kernel version that is used, i.e., ginkgo tests are meant\nto run on differently when running on bpf-next. \n .. code-block:: shell-session \n   $ ssh -p 2222 -o \"StrictHostKeyChecking=no\" root@localhost\n  # cd /host/\n  # kernel_tag=\"bpf-next-20230526.105339@sha256:4133d4e09b1e86ac175df8d899873180281bb4220dc43e2566c47b0241637411\"\n  # kubernetes_image=\"kindest/node:v1.27.1@sha256:b7d12ed662b873bd8510879c1846e87c7e676a79fefc93e17b2a52989d3ff42b\"\n  # ip_family=\"dual\" # replace with \"ipv4\" if k8s 1.19\n  #\n  # if [[ \"${kernel_tag}\" == bpf-next-* ]]; then\n  #  ./contrib/scripts/kind.sh \"\" 2 \"\" \"${kubernetes_image}\" \"none\" \"${ip_family}\"\n  #  kubectl label node kind-worker2 cilium.io/ci-node=kind-worker2\n  #  # Avoid re-labeling this node by setting \"node-role.kubernetes.io/controlplane\"\n  #  kubectl label node kind-worker2 node-role.kubernetes.io/controlplane=\n  # else\n  #   ./contrib/scripts/kind.sh \"\" 1 \"\" \"${kubernetes_image}\" \"iptables\" \"${ip_family}\"\n  # fi\n  # git config --global --add safe.directory /cilium\n \n Verify that kind is running inside the VM: \n .. code-block:: shell-session \n   $ ssh -p 2222 -o \"StrictHostKeyChecking=no\" root@localhost\n  # kubectl get pods -A\n  NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE\n  kube-system          coredns-787d4945fb-hqzpb                     0/1     Pending   0          42s\n  kube-system          coredns-787d4945fb-tkq86                     0/1     Pending   0          42s\n  kube-system          etcd-kind-control-plane                      1/1     Running   0          57s\n  kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          57s\n  kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          56s\n  kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          56s\n  local-path-storage   local-path-provisioner-6bd6454576-648bk      0/1     Pending   0          42s\n \n #. Now that Kind is provisioned, the tests can be executed inside the VM.\nLet us first retrieve the focus regex, under  cliFocus , of\n f09-datapath-misc-2  from  .github/actions/ginkgo/main-focus.yaml . \n \n cliFocus=\"K8sDatapathConfig Check|K8sDatapathConfig IPv4Only|K8sDatapathConfig High-scale|K8sDatapathConfig Iptables|K8sDatapathConfig IPv4Only|K8sDatapathConfig IPv6|K8sDatapathConfig Transparent\" \n \n Run the binary  test.test  that was compiled in the previous step. The\nfollowing code block is exactly the same as used on the GitHub workflow with\none exception: the flag  -cilium.holdEnvironment=true . This flag\nwill hold the testing environment in case the test fails to allow for further\ndiagnosis of the current cluster. \n .. code-block:: shell-session \n   $ ssh -p 2222 -o \"StrictHostKeyChecking=no\" root@localhost\n  # cd /host/test\n  # kernel_tag=\"bpf-next-20230526.105339@sha256:4133d4e09b1e86ac175df8d899873180281bb4220dc43e2566c47b0241637411\"\n  # k8s_version=\"1.27\"\n  #\n  # export K8S_NODES=2\n  # export NETNEXT=0\n  # export K8S_VERSION=\"${k8s_version}\"\n  # export CNI_INTEGRATION=kind\n  # export INTEGRATION_TESTS=true\n  #\n  # if [[ \"${kernel_tag}\" == bpf-next-* ]]; then\n  #    export KERNEL=net-next\n  #    export NETNEXT=1\n  #    export KUBEPROXY=0\n  #    export K8S_NODES=3\n  #    export NO_CILIUM_ON_NODES=kind-worker2\n  # elif [[ \"${kernel_tag}\" == 5.4-* ]]; then\n  #    export KERNEL=54\n  # fi\n  #\n  # # GitHub actions do not support IPv6 connectivity to outside\n  # # world. If the infrastructure environment supports it, then\n  # # this line can be removed\n  # export CILIUM_NO_IPV6_OUTSIDE=true\n  #\n  # commit_sha=\"7b368923823e63c9824ea2b5ee4dc026bc4d5cd8\"\n  # cliFocus=\"K8sDatapathConfig Check|K8sDatapathConfig IPv4Only|K8sDatapathConfig High-scale|K8sDatapathConfig Iptables|K8sDatapathConfig IPv4Only|K8sDatapathConfig IPv6|K8sDatapathConfig Transparent\"\n  # quay_org=\"cilium\"\n  #\n  # ./test.test \\\n    --ginkgo.focus=\"${cliFocus}\" \\\n    --ginkgo.skip=\"\" \\\n    --ginkgo.seed=1679952881 \\\n    --ginkgo.v -- \\\n    -cilium.image=quay.io/${quay_org}/cilium-ci \\\n    -cilium.tag=${commit_sha}  \\\n    -cilium.operator-image=quay.io/${quay_org}/operator \\\n    -cilium.operator-tag=${commit_sha} \\\n    -cilium.hubble-relay-image=quay.io/${quay_org}/hubble-relay-ci \\\n    -cilium.hubble-relay-tag=${commit_sha} \\\n    -cilium.kubeconfig=/root/.kube/config \\\n    -cilium.operator-suffix=-ci \\\n    -cilium.holdEnvironment=true\n  Using CNI_INTEGRATION=\"kind\"\n  Running Suite: Suite-k8s-1.27\n  =============================\n  Random Seed: 1679952881\n  Will run 7 of 132 specs\n \n #. Wait until the test execution completes. \n .. code-block:: shell-session \n   Ran 7 of 132 Specs in 721.007 seconds\n  SUCCESS! -- 7 Passed | 0 Failed | 0 Pending | 125 Skipped\n \n #. Clean up. \n Once tests are performed, terminate qemu to halt the VM: \n .. code-block:: shell-session \n   $ pkill qemu-system-x86\n \n The VM state is kept in  /tmp/_images/datapath-conformance.qcow2  and the\ndependencies are installed. Thus steps up to and excluding step\n:ref: installing kind <install_kind>  can be skipped next time and the VM\nstate can be re-used from step :ref: installing kind <install_kind>  onwards. \n Running Runtime Tests\n^^^^^^^^^^^^^^^^^^^^^ \n To run all of the runtime tests, execute the following command from the  test  directory: \n .. code-block:: shell-session \n INTEGRATION_TESTS=true ginkgo --focus=\"Runtime\"\n \n Ginkgo searches for all tests in all subdirectories that are \"named\" beginning\nwith the string \"Runtime\" and contain any characters after it. For instance,\nhere is an example showing what tests will be ran using Ginkgo's dryRun option: \n .. code-block:: shell-session \n $ INTEGRATION_TESTS=true ginkgo --focus=\"Runtime\" -dryRun\nRunning Suite: runtime\n======================\nRandom Seed: 1516125117\nWill run 42 of 164 specs\n................\nRuntimePolicyEnforcement Policy Enforcement Always\n  Always to Never with policy\n  /Users/ianvernon/go/src/github.com/cilium/cilium/test/runtime/Policies.go:258\n•\n------------------------------\nRuntimePolicyEnforcement Policy Enforcement Always\n  Always to Never without policy\n  /Users/ianvernon/go/src/github.com/cilium/cilium/test/runtime/Policies.go:293\n•\n------------------------------\nRuntimePolicyEnforcement Policy Enforcement Never\n  Container creation\n  /Users/ianvernon/go/src/github.com/cilium/cilium/test/runtime/Policies.go:332\n•\n------------------------------\nRuntimePolicyEnforcement Policy Enforcement Never\n  Never to default with policy\n  /Users/ianvernon/go/src/github.com/cilium/cilium/test/runtime/Policies.go:349\n.................\nRan 42 of 164 Specs in 0.002 seconds\nSUCCESS! -- 0 Passed | 0 Failed | 0 Pending | 122 Skipped PASS\n\nGinkgo ran 1 suite in 1.830262168s\nTest Suite Passed\n \n The output has been truncated. For more information about this functionality,\nconsult the aforementioned Ginkgo documentation. \n Available CLI Options\n^^^^^^^^^^^^^^^^^^^^^ \n For more advanced workflows, check the list of available custom options for the Cilium\nframework in the  test/  directory and interact with ginkgo directly: \n .. code-block:: shell-session \n $ cd test/\n$ ginkgo . -- -cilium.help\n  -cilium.SSHConfig string\n        Specify a custom command to fetch SSH configuration (eg: 'vagrant ssh-config')\n  -cilium.help\n        Display this help message.\n  -cilium.holdEnvironment\n        On failure, hold the environment in its current state\n  -cilium.hubble-relay-image string\n        Specifies which image of hubble-relay to use during tests\n  -cilium.hubble-relay-tag string\n        Specifies which tag of hubble-relay to use during tests\n  -cilium.image string\n        Specifies which image of cilium to use during tests\n  -cilium.kubeconfig string\n        Kubeconfig to be used for k8s tests\n  -cilium.multinode\n        Enable tests across multiple nodes. If disabled, such tests may silently pass (default true)\n  -cilium.operator-image string\n        Specifies which image of cilium-operator to use during tests\n  -cilium.operator-tag string\n        Specifies which tag of cilium-operator to use during tests\n  -cilium.passCLIEnvironment\n        Pass the environment invoking ginkgo, including PATH, to subcommands\n  -cilium.showCommands\n        Output which commands are ran to stdout\n  -cilium.skipLogs\n        skip gathering logs if a test fails\n  -cilium.tag string\n        Specifies which tag of cilium to use during tests\n  -cilium.testScope string\n        Specifies scope of test to be ran (k8s, runtime)\n  -cilium.timeout duration\n        Specifies timeout for test run (default 24h0m0s)\n\nGinkgo ran 1 suite in 4.312100241s\nTest Suite Failed\n \n For more information about other built-in options to Ginkgo, consult the\n ginkgo-documentation _. \n .. _ginkgo-documentation: \n Running Specific Tests Within a Test Suite\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n If you want to run one specified test, there are a few options: \n \n \n By modifying code: add the prefix \"FIt\" on the test you want to run; this\nmarks the test as focused. Ginkgo will skip other tests and will only run the\n\"focused\" test. For more information, consult the  Focused Specs _\ndocumentation from Ginkgo. \n .. code-block:: go \n It(\"Example test\", func(){\n    Expect(true).Should(BeTrue())\n})\n\nFIt(\"Example focused test\", func(){\n    Expect(true).Should(BeTrue())\n})\n \n \n \n From the command line: specify a more granular focus if you want to focus on, say, Runtime L7 tests: \n .. code-block:: shell-session \n INTEGRATION_TESTS=true ginkgo --focus \"Runtime.*L7\"\n \n \n \n This will focus on tests that contain \"Runtime\", followed by any\nnumber of any characters, followed by \"L7\".  --focus  is a regular\nexpression and quotes are required if it contains spaces and to escape\nshell expansion of  * . \n .. _Focused Specs: https://onsi.github.io/ginkgo/#focused-specs \n Compiling the tests without running them\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n To validate that the Go code you've written for testing is correct without\nneeding to run the full test, you can build the test directory: \n .. code-block:: shell-session \n make -C test/ build\n \n Updating Cilium images for Kubernetes tests\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n Sometimes when running the CI suite for a feature under development, it's common\nto re-run the CI suite on the CI VMs running on a local development machine after\napplying some changes to Cilium. For this the new Cilium images have to be\nbuilt, and then used by the CI suite. To do so, one can run the following\ncommands on the  k8s1  VM: \n .. code-block:: shell-session \n cd go/src/github.com/cilium/cilium \n make LOCKDEBUG=1 docker-cilium-image\ndocker tag quay.io/cilium/cilium:latest  \nk8s1:5000/cilium/cilium-dev:latest\ndocker push k8s1:5000/cilium/cilium-dev:latest \n make -B LOCKDEBUG=1 docker-operator-generic-image\ndocker tag quay.io/cilium/operator-generic:latest  \nk8s1:5000/cilium/operator-generic:latest\ndocker push k8s1:5000/cilium/operator-generic:latest \n The commands were adapted from the  test/provision/compile.sh  script. \n Test Reports \n \nThe Cilium Ginkgo framework formulates JUnit reports for each test. The\nfollowing files currently are generated depending upon the test suite that is ran:\n\n* runtime.xml\n* K8s.xml\n\nBest Practices for Writing Tests\n \n \n Provide informative output to console during a test using the  By construct <https://onsi.github.io/ginkgo/#documenting-complex-specs-by> _. This helps with debugging and gives those who did not write the test a good idea of what is going on. The lower the barrier of entry is for understanding tests, the better our tests will be! \n Leave the testing environment in the same state that it was in when the test started by deleting resources, resetting configuration, etc. \n Gather logs in the case that a test fails. If a test fails while running on Ginkgo, a postmortem needs to be done to analyze why. So, dumping logs to a location where Ginkgo can pick them up is of the highest imperative. Use the following code in an  AfterFailed  method: \n \n .. code-block:: go \n AfterFailed(func() {\n\tvm.ReportFailed()\n})\n \n Ginkgo Extensions \n \nIn Cilium, some Ginkgo features are extended to cover some uses cases that are\nuseful for testing Cilium.\n\nBeforeAll\n^^^^^^^^^\n\nThis function will run before all `BeforeEach`_ within a `Describe or Context`_.\nThis method is an equivalent to ``SetUp`` or initialize functions in common\nunit test frameworks.\n\n.. _BeforeEach: https://onsi.github.io/ginkgo/#extracting-common-setup-beforeeach\n.. _Describe or Context: https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes\n\nAfterAll\n^^^^^^^^\n\nThis method will run after all `AfterEach`_ functions defined in a `Describe or Context`_.\nThis method is used for tearing down objects created which are used by all\n``Its`` within the given ``Context`` or ``Describe``. It is ran after all Its\nhave ran, this method is a equivalent to ``tearDown`` or ``finalize`` methods in\ncommon unit test frameworks.\n\nA good use case for using ``AfterAll`` method is to remove containers or pods\nthat are needed for multiple ``Its`` in the given ``Context`` or ``Describe``.\n\n.. _AfterEach: BeforeEach_\n\nJustAfterEach\n^^^^^^^^^^^^^\n\nThis method will run just after each test and before ``AfterFailed`` and\n``AfterEach``. The main reason of this method is to perform some assertions\nfor a group of tests.  A good example of using a global ``JustAfterEach``\nfunction is for deadlock detection, which checks the Cilium logs for deadlocks\nthat may have occurred in the duration of the tests.\n\nAfterFailed\n^^^^^^^^^^^\n\nThis method will run before all ``AfterEach`` and after ``JustAfterEach``. This\nfunction is only called when the test failed.This construct is used to gather\nlogs, the status of Cilium, etc, which provide data for analysis when tests\nfail.\n\nExample Test Layout\n^^^^^^^^^^^^^^^^^^^\n\nHere is an example layout of how a test may be written with the aforementioned\nconstructs:\n\nTest description diagram::\n\n    Describe\n        BeforeAll(A)\n        AfterAll(A)\n        AfterFailed(A)\n        AfterEach(A)\n        JustAfterEach(A)\n        TESTA1\n        TESTA2\n        TESTA3\n        Context\n            BeforeAll(B)\n            AfterAll(B)\n            AfterFailed(B)\n            AfterEach(B)\n            JustAfterEach(B)\n            TESTB1\n            TESTB2\n            TESTB3\n\n\nTest execution flow::\n\n    Describe\n        BeforeAll\n        TESTA1; JustAfterEach(A), AfterFailed(A), AfterEach(A)\n        TESTA2; JustAfterEach(A), AfterFailed(A), AfterEach(A)\n        TESTA3; JustAfterEach(A), AfterFailed(A), AfterEach(A)\n        Context\n            BeforeAll(B)\n            TESTB1:\n               JustAfterEach(B); JustAfterEach(A)\n               AfterFailed(B); AfterFailed(A);\n               AfterEach(B) ; AfterEach(A);\n            TESTB2:\n               JustAfterEach(B); JustAfterEach(A)\n               AfterFailed(B); AfterFailed(A);\n               AfterEach(B) ; AfterEach(A);\n            TESTB3:\n               JustAfterEach(B); JustAfterEach(A)\n               AfterFailed(B); AfterFailed(A);\n               AfterEach(B) ; AfterEach(A);\n            AfterAll(B)\n        AfterAll(A)\n\nDebugging:\n~~~~~~~~~~\n\nYou can retrieve all run commands and their output in the report directory\n(``./test/test_results``). Each test creates a new folder, which contains\na file called log where all information is saved, in case of a failing\ntest an exhaustive data will be added.\n\n.. code-block:: shell-session\n\n\t$ head test/test_results/RuntimeKafkaKafkaPolicyIngress/logs\n\tlevel=info msg=Starting testName=RuntimeKafka\n\tlevel=info msg=\"Vagrant: running command \\\"vagrant ssh-config runtime\\\"\"\n\tcmd: \"sudo cilium-dbg status\" exitCode: 0\n\t KVStore:            Ok         Etcd: 172.17.0.3:4001\n\tContainerRuntime:   Ok\n\tKubernetes:         Disabled\n\tKubernetes APIs:    [\"\"]\n\tCilium:             Ok   OK\n\tNodeMonitor:        Disabled\n\tAllocated IPv4 addresses:\n\n\nRunning with delve\n^^^^^^^^^^^^^^^^^^\n\n`Delve <https://github.com/derekparker/delve>`_ is a debugging tool for Go\napplications. If you want to run your test with delve,  you should add a new\nbreakpoint using\n`runtime.BreakPoint() <https://golang.org/pkg/runtime/#Breakpoint>`_ in the\ncode, and run ginkgo using ``dlv``.\n\nExample how to run ginkgo using ``dlv``:\n\n.. code-block:: shell-session\n\n\tdlv test . -- --ginkgo.focus=\"Runtime\" -ginkgo.v=true\n\nRunning End-To-End Tests In Other Environments via kubeconfig\n \n You can run the end-to-end tests with an arbitrary kubeconfig file by specifying\n --cilium.kubeconfig  parameter on the Ginkgo command line. This will skip\nprovisioning the environment and some setup tasks like labeling nodes for testing. \n This mode expects: \n \n \n The current directory is  cilium/test \n \n \n A test focus with  --focus .  --focus=\"K8s\"  selects all kubernetes tests.\nIf not passing  --focus=K8s  then you must pass  -cilium.testScope=K8s . \n \n \n Cilium images as full URLs specified with the  --cilium.image  and\n --cilium.operator-image  options. \n \n \n A working kubeconfig with the  --cilium.kubeconfig  option \n \n \n A populated K8S_VERSION environment variable set to the version of the cluster \n \n \n If appropriate, set the  CNI_INTEGRATION  environment variable set to one\nof  gke ,  eks ,  eks-chaining ,  microk8s  or  minikube . This selects\nmatching configuration overrides for cilium.\nLeaving this unset for non-matching integrations is also correct. \n For k8s environments that invoke an authentication agent, such as EKS and\n aws-iam-authenticator , set  --cilium.passCLIEnvironment=true \n \n \n An example invocation is \n .. code-block:: shell-session \n INTEGRATION_TESTS=true CNI_INTEGRATION=eks K8S_VERSION=1.16 ginkgo --focus=\"K8s\" -- -cilium.kubeconfig= echo ~/.kube/config  -cilium.image=\"quay.io/cilium/cilium-ci\" -cilium.operator-image=\"quay.io/cilium/operator\" -cilium.operator-suffix=\"-ci\" -cilium.passCLIEnvironment=true \n To run tests with Kind, try \n .. code-block:: shell-session \n K8S_VERSION=1.25 ginkgo --focus=K8s -- --cilium.image=localhost:5000/cilium/cilium-dev -cilium.tag=local  --cilium.operator-image=localhost:5000/cilium/operator -cilium.operator-tag=local -cilium.kubeconfig= echo ~/.kube/config  -cilium.testScope=K8s -cilium.operator-suffix= \n Running in GKE\n^^^^^^^^^^^^^^ \n 1- Setup a cluster as in :ref: k8s_install_quick  or utilize an existing\ncluster. \n .. note:: You do not need to deploy Cilium in this step, as the End-To-End\nTesting Framework handles the deployment of Cilium. \n .. note:: The tests require machines larger than  n1-standard-4 . This can be\nset with  --machine-type n1-standard-4  on cluster creation. \n 2- Invoke the tests from  cilium/test  with options set as explained in\n Running End-To-End Tests In Other Environments via kubeconfig _ \n .. note:: The tests require the  NATIVE_CIDR  environment variable to be set to\nthe value of the cluster IPv4 CIDR returned by the  gcloud container           clusters describe  command. \n .. code-block:: shell-session \n export CLUSTER_NAME=cluster1\nexport CLUSTER_ZONE=us-west2-a\nexport NATIVE_CIDR=\"$(gcloud container clusters describe $CLUSTER_NAME --zone $CLUSTER_ZONE --format 'value(clusterIpv4Cidr)')\" \n INTEGRATION_TESTS=true CNI_INTEGRATION=gke K8S_VERSION=1.17 ginkgo --focus=\"K8sDemo\" -- -cilium.kubeconfig= echo ~/.kube/config  -cilium.image=\"quay.io/cilium/cilium-ci\" -cilium.operator-image=\"quay.io/cilium/operator\" -cilium.operator-suffix=\"-ci\" -cilium.hubble-relay-image=\"quay.io/cilium/hubble-relay-ci\" -cilium.passCLIEnvironment=true \n .. note:: The kubernetes version defaults to 1.23 but can be configured with\nversions between 1.16 and 1.23. Version should match the server\nversion reported by  kubectl version . \n AKS (experimental)\n^^^^^^^^^^^^^^^^^^ \n .. note:: The tests require the  NATIVE_CIDR  environment variable to be set to\nthe value of the cluster IPv4 CIDR. \n \n \n Setup a cluster as in :ref: k8s_install_quick  or utilize an existing\ncluster. You do not need to deploy Cilium in this step, as the End-To-End\nTesting Framework handles the deployment of Cilium. \n \n \n Invoke the tests from  cilium/test  with options set as explained in\n Running End-To-End Tests In Other Environments via kubeconfig _ \n \n \n .. code-block:: shell-session \n export NATIVE_CIDR=\"10.241.0.0/16\"\nINTEGRATION_TESTS=true CNI_INTEGRATION=aks K8S_VERSION=1.17 ginkgo --focus=\"K8s\" -- -cilium.kubeconfig=`echo ~/.kube/config` -cilium.passCLIEnvironment=true -cilium.image=\"mcr.microsoft.com/oss/cilium/cilium\" -cilium.tag=\"1.12.1\" -cilium.operator-image=\"mcr.microsoft.com/oss/cilium/operator\" -cilium.operator-suffix=\"\"  -cilium.operator-tag=\"1.12.1\"\n \n AWS EKS (experimental)\n^^^^^^^^^^^^^^^^^^^^^^ \n Not all tests can succeed on EKS. Many do, however and may be useful.\n:gh-issue: 9678#issuecomment-749350425  contains a list of tests that are still\nfailing. \n \n \n Setup a cluster as in :ref: k8s_install_quick  or utilize an existing\ncluster. \n \n \n Source the testing integration script from  cilium/contrib/testing/integrations.sh . \n \n \n Invoke the  gks  function by passing which  cilium  docker image to run\nand the test focus. The command also accepts additional ginkgo arguments. \n \n \n .. code-block:: shell-session \n gks quay.io/cilium/cilium:latest K8sDemo\n \n Adding new Managed Kubernetes providers\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n All Managed Kubernetes test support relies on using a pre-configured kubeconfig\nfile.  This isn't always adequate, however, and adding defaults specific to\neach provider is possible. The  commit adding GKE <https://github.com/cilium/cilium/commit/c2d8445fd725c515a635c8c3ad3be901a08084eb> _\nsupport is a good reference. \n \n \n Add a map of helm settings to act as an override for this provider in\n test/helpers/kubectl.go <https://github.com/cilium/cilium/blob/26dec4c4f4311df2b1a6c909b27ff7fe6e46929f/test/helpers/kubectl.go#L80-L102> _.\nThese should be the helm settings used when generating cilium specs for this\nprovider. \n \n \n Add a unique  CI Integration constant <https://github.com/cilium/cilium/blob/26dec4c4f4311df2b1a6c909b27ff7fe6e46929f/test/helpers/kubectl.go#L66-L67> _.\nThis value is passed in when invoking ginkgo via the  CNI_INTEGRATON \nenvironment variable. \n \n \n Update the  helm overrides <https://github.com/cilium/cilium/blob/26dec4c4f4311df2b1a6c909b27ff7fe6e46929f/test/helpers/kubectl.go#L138-L147> _\nmapping with the constant and the helm settings. \n \n \n For cases where a test should be skipped use the  SkipIfIntegration . To\nskip whole contexts, use  SkipContextIf . More complex logic can be\nexpressed with functions like  IsIntegration . These functions are all\npart of the  test/helpers <https://github.com/cilium/cilium/tree/26dec4c4f4311df2b1a6c909b27ff7fe6e46929f/test/helpers> _\npackage. \n \n \n Running End-To-End Tests In Other Environments via SSH \n \nIf you want to run tests in an arbitrary environment with SSH access, you can\nuse ``--cilium.SSHConfig`` to provide the SSH configuration of the endpoint on\nwhich tests will be run. The tests presume the following on the remote\ninstance:\n\n- Cilium source code is located in the directory ``/home/$USER/go/src/github.com/cilium/cilium/``.\n- Cilium is installed and running.\n\nThe ssh connection needs to be defined as a ``ssh-config`` file and need to have\nthe following targets:\n\n- runtime: To run runtime tests\n- k8s{1..2}-${K8S_VERSION}: to run Kubernetes tests. These instances must have\n  Kubernetes installed and running as a prerequisite for running tests.\n\nAn example ``ssh-config`` can be the following:\n\n::\n\n\tHost runtime\n\t  HostName 127.0.0.1\n\t  User vagrant\n\t  Port 2222\n\t  UserKnownHostsFile /dev/null\n\t  StrictHostKeyChecking no\n\t  PasswordAuthentication no\n\t  IdentityFile /home/eloy/.go/src/github.com/cilium/cilium/test/.vagrant/machines/runtime/virtualbox/private_key\n\t  IdentitiesOnly yes\n\t  LogLevel FATAL\n\nTo run this you can use the following command:\n\n.. code-block:: shell-session\n\n    ginkgo -- --cilium.SSHConfig=\"cat ssh-config\"\n\n\nEnvironment variables\n~~~~~~~~~~~~~~~~~~~~~\n\nThere are a variety of configuration options that can be passed as environment variables:\n\n+----------------------+-------------------+--------------+------------------------------------------------------------------+\n| ENV variable         | Default Value     | Options      | Description                                                      |\n+======================+===================+==============+==================================================================+\n| K8S\\_NODES           | 2                 | 0..100       | Number of Kubernetes nodes in the cluster                        |\n+----------------------+-------------------+--------------+------------------------------------------------------------------+\n| NO_CILIUM_ON_NODE[S] | none              | \\*           | Comma-separated list of K8s nodes that should not run Cilium     |\n+----------------------+-------------------+--------------+------------------------------------------------------------------+\n| K8S\\_VERSION         | 1.18              | 1.\\*\\*       | Kubernetes version to install                                    |\n+----------------------+-------------------+--------------+------------------------------------------------------------------+\n| KUBEPROXY            | 1                 | 0-1          | If 0 the Kubernetes' kube-proxy won't be installed               |\n+----------------------+-------------------+--------------+------------------------------------------------------------------+\n\nFurther Assistance\n~~~~~~~~~~~~~~~~~~\n\nHave a question about how the tests work or want to chat more about improving the\ntesting infrastructure for Cilium? Hop on over to the ``#testing`` channel on\n`Cilium Slack`_.",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/contributing/testing/e2e_legacy.rst",
  "extracted_at": "2025-09-03T00:53:44.796089Z"
}
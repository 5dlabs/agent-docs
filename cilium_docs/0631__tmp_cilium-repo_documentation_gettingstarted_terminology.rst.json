{
  "url": "file:///tmp/cilium-repo/Documentation/gettingstarted/terminology.rst",
  "content": ".. only:: not (epub or latex or html)\n\n    WARNING: You are looking at unreleased Cilium documentation.\n    Please use the official rendered version released here:\n    https://docs.cilium.io\n\n***********\nTerminology\n***********\n\n\n.. _label:\n.. _labels:\n\nLabels\n======\n\nLabels are a generic, flexible and highly scalable way of addressing a large\nset of resources as they allow for arbitrary grouping and creation of sets.\nWhenever something needs to be described, addressed or selected, it is done\nbased on labels:\n\n- `Endpoints` are assigned labels as derived from the container runtime,\n  orchestration system, or other sources.\n- `Network policies` select pairs of `endpoints` which are allowed to\n  communicate based on labels. The policies themselves are identified by labels\n  as well.\n\nWhat is a Label?\n----------------\n\nA label is a pair of strings consisting of a ``key`` and ``value``. A label can\nbe formatted as a single string with the format ``key=value``. The key portion\nis mandatory and must be unique. This is typically achieved by using the\nreverse domain name notion, e.g. ``io.cilium.mykey=myvalue``. The value portion\nis optional and can be omitted, e.g. ``io.cilium.mykey``.\n\nKey names should typically consist of the character set ``[a-z0-9-.]``.\n\nWhen using labels to select resources, both the key and the value must match,\ne.g. when a policy should be applied to all endpoints with the label\n``my.corp.foo`` then the label ``my.corp.foo=bar`` will not match the\nselector.\n\nLabel Source\n------------\n\nA label can be derived from various sources. For example, an `endpoint`_ will\nderive the labels associated to the container by the local container runtime as\nwell as the labels associated with the pod as provided by Kubernetes. As these\ntwo label namespaces are not aware of each other, this may result in\nconflicting label keys.\n\nTo resolve this potential conflict, Cilium prefixes all label keys with\n``source:`` to indicate the source of the label when importing labels, e.g.\n``k8s:role=frontend``, ``container:user=joe``, ``k8s:role=backend``. This means\nthat when you run a Docker container using ``docker run [...] -l foo=bar``, the\nlabel ``container:foo=bar`` will appear on the Cilium endpoint representing the\ncontainer. Similarly, a Kubernetes pod started with the label ``foo: bar``\nwill be represented with a Cilium endpoint associated with the label\n``k8s:foo=bar``. A unique name is allocated for each potential source. The\nfollowing label sources are currently supported:\n\n- ``container:`` for labels derived from the local container runtime\n- ``k8s:`` for labels derived from Kubernetes\n- ``reserved:`` for special reserved labels, see :ref:`reserved_labels`.\n- ``unspec:`` for labels with unspecified source\n\nWhen using labels to identify other resources, the source can be included to\nlimit matching of labels to a particular type. If no source is provided, the\nlabel source defaults to ``any:`` which will match all labels regardless of\ntheir source. If a source is provided, the source of the selecting and matching\nlabels need to match.\n\n.. _endpoint:\n.. _endpoints:\n\nEndpoint\n=========\n\nCilium makes application containers available on the network by assigning them\nIP addresses. Multiple application containers can share the same IP address; a\ntypical example for this model is a Kubernetes :term:`Pod`. All application containers\nwhich share a common address are grouped together in what Cilium refers to as\nan endpoint.\n\nAllocating individual IP addresses enables the use of the entire Layer 4 port\nrange by each endpoint. This essentially allows multiple application containers\nrunning on the same cluster node to all bind to well known ports such as ``80``\nwithout causing any conflicts.\n\nThe default behavior of Cilium is to assign both an IPv6 and IPv4 address to\nevery endpoint. However, this behavior can be configured to only allocate an\nIPv6 address with the ``--enable-ipv4=false`` option. If both an IPv6 and IPv4\naddress are assigned, either address can be used to reach the endpoint. The\nsame behavior will apply with regard to policy rules, load-balancing, etc. See\n:ref:`address_management` for more details.\n\nIdentification\n--------------\n\nFor identification purposes, Cilium assigns an internal endpoint id to all\nendpoints on a cluster node. The endpoint id is unique within the context of\nan individual cluster node.\n\n.. _endpoint id:\n\nEndpoint Metadata\n-----------------\n\nAn endpoint automatically derives metadata from the application containers\nassociated with the endpoint. The metadata can then be used to identify the\nendpoint for security/policy, load-balancing and routing purposes.\n\nThe source of the metadata will depend on the orchestration system and\ncontainer runtime in use. The following metadata retrieval mechanisms are\ncurrently supported:\n\n+---------------------+---------------------------------------------------+\n| System              | Description                                       |\n+=====================+===================================================+\n| Kubernetes          | Pod labels (via k8s API)                          |\n+---------------------+---------------------------------------------------+\n| containerd (Docker) | Container labels (via Docker API)                 |\n+---------------------+---------------------------------------------------+\n\nMetadata is attached to endpoints in the form of `labels`.\n\nThe following example launches a container with the label ``app=benchmark``\nwhich is then associated with the endpoint. The label is prefixed with\n``container:`` to indicate that the label was derived from the container\nruntime.\n\n.. code-block:: shell-session\n\n    $ docker run --net cilium -d -l app=benchmark tgraf/netperf\n    aaff7190f47d071325e7af06577f672beff64ccc91d2b53c42262635c063cf1c\n    $ cilium-dbg endpoint list\n    ENDPOINT   POLICY        IDENTITY   LABELS (source:key[=value])   IPv6                   IPv4            STATUS\n               ENFORCEMENT\n    62006      Disabled      257        container:app=benchmark       f00d::a00:20f:0:f236   10.15.116.202   ready\n\n\nAn endpoint can have metadata associated from multiple sources. A typical\nexample is a Kubernetes cluster which uses containerd as the container runtime.\nEndpoints will derive Kubernetes pod labels (prefixed with the ``k8s:`` source\nprefix) and containerd labels (prefixed with ``container:`` source prefix).\n\n.. _identity:\n\nIdentity\n========\n\nAll `endpoints` are assigned an identity. The identity is what is used to enforce\nbasic connectivity between endpoints. In traditional networking terminology,\nthis would be equivalent to Layer 3 enforcement.\n\nAn identity is identified by `labels` and is given a cluster wide unique\nidentifier. The endpoint is assigned the identity which matches the endpoint's\n`security relevant labels`, i.e. all endpoints which share the same set of\n`security relevant labels` will share the same identity. This concept allows to\nscale policy enforcement to a massive number of endpoints as many individual\nendpoints will typically share the same set of security `labels` as applications\nare scaled.\n\nWhat is an Identity?\n--------------------\n\nThe identity of an endpoint is derived based on the `labels` associated with\nthe pod or container which are derived to the `endpoint`_. When a pod or\ncontainer is started, Cilium will create an `endpoint`_ based on the event\nreceived by the container runtime to represent the pod or container on the\nnetwork. As a next step, Cilium will resolve the identity of the `endpoint`_\ncreated. Whenever the `labels` of the pod or container change, the identity is\nreconfirmed and automatically modified as required.\n\n.. _security relevant labels:\n\nSecurity Relevant Labels\n------------------------\n\nNot all `labels` associated with a container or pod are meaningful when\nderiving the `identity`. Labels may be used to store metadata such as the\ntimestamp when a container was launched. Cilium requires to know which labels\nare meaningful and are subject to being considered when deriving the identity.\nFor this purpose, the user is required to specify a list of string prefixes of\nmeaningful labels. The standard behavior is to include all labels which start\nwith the prefix ``id.``, e.g.  ``id.service1``, ``id.service2``,\n``id.groupA.service44``. The list of meaningful label prefixes can be specified\nwhen starting the agent.\n\n.. _reserved_labels:\n\nSpecial Identities\n------------------\n\nAll endpoints which are managed by Cilium will be assigned an identity. In\norder to allow communication to network endpoints which are not managed by\nCilium, special identities exist to represent those. Special reserved\nidentities are prefixed with the string ``reserved:``.\n\n+-----------------------------+------------+---------------------------------------------------+\n| Identity                    | Numeric ID | Description                                       |\n+=============================+============+===================================================+\n| ``reserved:unknown``        | 0          | The identity could not be derived.                |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:host``           | 1          | The local host. Any traffic that originates from  |\n|                             |            | or is designated to one of the local host IPs.    |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:world``          | 2          | Any network endpoint outside of the cluster       |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:unmanaged``      | 3          | An endpoint that is not managed by Cilium, e.g.   |\n|                             |            | a Kubernetes pod that was launched before Cilium  |\n|                             |            | was installed.                                    |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:health``         | 4          | This is health checking traffic generated by      |\n|                             |            | Cilium agents.                                    |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:init``           | 5          | An endpoint for which the identity has not yet    |\n|                             |            | been resolved is assigned the init identity.      |\n|                             |            | This represents the phase of an endpoint in which |\n|                             |            | some of the metadata required to derive the       |\n|                             |            | security identity is still missing. This is       |\n|                             |            | typically the case in the bootstrapping phase.    |\n|                             |            |                                                   |\n|                             |            | The init identity is only allocated if the labels |\n|                             |            | of the endpoint are not known at creation time.   |\n|                             |            | This can be the case for the Docker plugin.       |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:remote-node``    | 6          | The collection of all remote cluster hosts.       |\n|                             |            | Any traffic that originates from or is designated |\n|                             |            | to one of the IPs of any host in any connected    |\n|                             |            | cluster other than the local node.                |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:kube-apiserver`` | 7          | Remote node(s) which have backend(s) serving the  |\n|                             |            | kube-apiserver running.                           |\n+-----------------------------+------------+---------------------------------------------------+\n| ``reserved:ingress``        | 8          | Given to the IPs used as the source address for   |\n|                             |            | connections from Ingress proxies.                 |\n+-----------------------------+------------+---------------------------------------------------+\n\nWell-known Identities\n---------------------\n\nThe following is a list of well-known identities which Cilium is aware of\nautomatically and will hand out a security identity without requiring to\ncontact any external dependencies such as the kvstore. The purpose of this is\nto allow bootstrapping Cilium and enable network connectivity with policy\nenforcement in the cluster for essential services without depending on any\ndependencies.\n\n======================== =================== ==================== ================= =========== ============================================================================\nDeployment               Namespace           ServiceAccount       Cluster Name      Numeric ID  Labels\n======================== =================== ==================== ================= =========== ============================================================================\nkube-dns                 kube-system         kube-dns             <cilium-cluster>  102         ``k8s-app=kube-dns``\nkube-dns (EKS)           kube-system         kube-dns             <cilium-cluster>  103         ``k8s-app=kube-dns``, ``eks.amazonaws.com/component=kube-dns``\ncore-dns                 kube-system         coredns              <cilium-cluster>  104         ``k8s-app=kube-dns``\ncore-dns (EKS)           kube-system         coredns              <cilium-cluster>  106         ``k8s-app=kube-dns``, ``eks.amazonaws.com/component=coredns``\ncilium-operator          <cilium-namespace>  cilium-operator      <cilium-cluster>  105         ``name=cilium-operator``, ``io.cilium/app=operator``\n======================== =================== ==================== ================= =========== ============================================================================\n\n*Note*: if ``cilium-cluster`` is not defined with the ``cluster-name`` option,\nthe default value will be set to \"``default``\".\n\nIdentity Management in the Cluster\n----------------------------------\n\nIdentities are valid in the entire cluster which means that if several pods or\ncontainers are started on several cluster nodes, all of them will resolve and\nshare a single identity if they share the identity relevant labels. This\nrequires coordination between cluster nodes.\n\n.. image:: ../images/identity_store.png\n    :align: center\n\nThe operation to resolve an endpoint identity is performed with the help of the\ndistributed key-value store which allows to perform atomic operations in the\nform *generate a new unique identifier if the following value has not been seen\nbefore*. This allows each cluster node to create the identity relevant subset\nof labels and then query the key-value store to derive the identity. Depending\non whether the set of labels has been queried before, either a new identity\nwill be created, or the identity of the initial query will be returned.\n\n.. _node:\n\nNode\n====\n\nCilium refers to a node as an individual member of a cluster. Each node must be\nrunning the ``cilium-agent`` and will operate in a mostly autonomous manner.\nSynchronization of state between Cilium agents running on different nodes is\nkept to a minimum for simplicity and scale. It occurs exclusively via the\nKey-Value store or with packet metadata.\n\nNode Address\n------------\n\nCilium will automatically detect the node's IPv4 and IPv6 address. The detected\nnode address is printed out when the ``cilium-agent`` starts:\n\n::\n\n    Local node-name: worker0\n    Node-IPv6: f00d::ac10:14:0:1\n    External-Node IPv4: 172.16.0.20\n    Internal-Node IPv4: 10.200.28.238\n\n",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/gettingstarted/terminology.rst",
  "extracted_at": "2025-09-03T01:13:29.366417Z"
}
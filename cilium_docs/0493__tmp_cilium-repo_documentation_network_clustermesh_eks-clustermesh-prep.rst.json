{
  "url": "file:///tmp/cilium-repo/Documentation/network/clustermesh/eks-clustermesh-prep.rst",
  "content": ".. _gs_clustermesh_eks_prep: \n \n EKS-to-EKS Clustermesh Preparation \n \n This is a step-by-step guide on how to install and prepare AWS EKS (AWS Elastic Kubernetes Service) clusters to meet the requirements for the clustermesh feature. \n In this guide you will install two EKS clusters and connect them together via clustermesh. \n Install cluster one\n################### \n \n \n Create environmental variables that will be appended to each resource name. \n .. code:: bash \n export NAME=\"$(whoami)-$RANDOM\"\nexport AWS_REGION=\"eu-west-2\"\n \n \n \n Create a VPC \n .. note::\nAvoid using the  172.17.0.0/16  CIDR range for your VPC to prevent potential issues since certain  AWS services <https://docs.aws.amazon.com/vpc/latest/userguide/vpc-cidr-blocks.html> __ utilize this range. \n .. code:: bash \n Cluster_1_VPC=$(aws ec2 create-vpc \\\n    --cidr-block 10.0.0.0/16 \\\n    --tag-specifications \"ResourceType=vpc,Tags=[{Key=Name,Value=Cluster_1_VPC}]\" \\\n    --region ${AWS_REGION} \\\n    --query 'Vpc.{VpcId:VpcId}' \\\n    --output text\n)\n \n \n \n Create Subnets. \n .. code:: bash \n # Create public subnets\nexport Cluster_1_Public_Subnet_1=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --cidr-block 10.0.1.0/24 \\\n    --availability-zone ${AWS_REGION}a \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_1_Public_Subnet_1},{Key=kubernetes.io/role/elb,Value=1}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text \n)\n\nexport Cluster_1_Public_Subnet_2=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --cidr-block 10.0.2.0/24 \\\n    --availability-zone ${AWS_REGION}b \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_1_Public_Subnet_2},{Key=kubernetes.io/role/elb,Value=1}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text \n)\n\n# Create private subnets\nexport Cluster_1_Private_Subnet_1=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --cidr-block 10.0.3.0/24 \\\n    --availability-zone ${AWS_REGION}a \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_1_Private_Subnet_1},{Key=kubernetes.io/role/internal-elb,Value=1}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text \n)\n\nexport Cluster_1_Private_Subnet_2=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --cidr-block 10.0.4.0/24 \\\n    --availability-zone ${AWS_REGION}b \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_1_Private_Subnet_2},{Key=kubernetes.io/role/internal-elb,Value=1}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text\n)\n \n \n \n Create an internet gateway and NAT then attach it to the VPC. \n .. code:: bash \n # Create internet gateway\nexport Cluster_1_IGW=$(aws ec2 create-internet-gateway \\\n    --tag-specifications \"ResourceType=internet-gateway, Tags=[{Key=Name,Value=Cluster_1_IGW}]\" \\\n    --query 'InternetGateway.InternetGatewayId' \\\n    --region ${AWS_REGION} \\\n    --output text\n)\n\n# Attach the internet gateway to the VPC\naws ec2 attach-internet-gateway \\\n    --internet-gateway-id ${Cluster_1_IGW} \\\n    --vpc-id ${Cluster_1_VPC}\n\n# Create NAT gateway\nCluster_1_EIP_1=$(aws ec2 allocate-address \\\n    --domain vpc \\\n     --tag-specifications \"ResourceType=elastic-ip, Tags=[{Key=Name,Value=Cluster_1_EIP_1}]\" \\\n    --query 'AllocationId' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\nCluster_1_EIP_2=$(aws ec2 allocate-address \\\n    --domain vpc \\\n     --tag-specifications \"ResourceType=elastic-ip, Tags=[{Key=Name,Value=Cluster_1_EIP_2}]\" \\\n    --query 'AllocationId' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\nCluster_1_NGW_1=$(aws ec2 create-nat-gateway \\\n    --subnet-id $Cluster_1_Public_Subnet_1 \\\n    --allocation-id ${Cluster_1_EIP_1} \\\n    --tag-specifications \"ResourceType=natgateway, Tags=[{Key=Name,Value=Cluster_1_NGW_1}]\" \\\n    --query 'NatGateway.{NatGatewayId:NatGatewayId}' \\\n    --output text\n)\n\nCluster_1_NGW_2=$(aws ec2 create-nat-gateway \\\n    --subnet-id $Cluster_1_Public_Subnet_2 \\\n    --allocation-id ${Cluster_1_EIP_2} \\\n    --tag-specifications \"ResourceType=natgateway, Tags=[{Key=Name,Value=Cluster_1_NGW_2}]\" \\\n    --query 'NatGateway.{NatGatewayId:NatGatewayId}' \\\n    --output text\n)\n \n \n \n Create route tables, routes, and route table associations. \n .. code:: bash \n # Create a public route table\nexport Cluster_1_Public_RT=$(aws ec2 create-route-table \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --tag-specifications \"ResourceType=route-table, Tags=[{Key=Name,Value=Cluster_1_Public_RT}]\" \\\n    --query 'RouteTable.{RouteTableId:RouteTableId}' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\n# Add a route to the internet gateway\naws ec2 create-route \\\n    --route-table-id ${Cluster_1_Public_RT} \\\n    --destination-cidr-block 0.0.0.0/0 \\\n    --gateway-id ${Cluster_1_IGW}\n\n# Associate public subnets with the public route table\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_1_Public_Subnet_1} \\\n    --route-table-id ${Cluster_1_Public_RT}\n\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_1_Public_Subnet_2} \\\n    --route-table-id ${Cluster_1_Public_RT}\n\n# Create private route tables\nexport Cluster_1_Private_RT_1=$(aws ec2 create-route-table \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --tag-specifications \"ResourceType=route-table, Tags=[{Key=Name,Value=Cluster_1_Private_RT_1}]\" \\\n    --query 'RouteTable.{RouteTableId:RouteTableId}' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\nexport Cluster_1_Private_RT_2=$(aws ec2 create-route-table \\\n    --vpc-id ${Cluster_1_VPC} \\\n    --tag-specifications \"ResourceType=route-table, Tags=[{Key=Name,Value=Cluster_1_Private_RT_2}]\" \\\n    --query 'RouteTable.{RouteTableId:RouteTableId}' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\n# Add routes to the NAT gateway\naws ec2 create-route \\\n    --route-table-id ${Cluster_1_Private_RT_1} \\\n    --destination-cidr-block 0.0.0.0/0 \\\n    --gateway-id ${Cluster_1_NGW_1}\n\naws ec2 create-route \\\n    --route-table-id ${Cluster_1_Private_RT_2} \\\n    --destination-cidr-block 0.0.0.0/0 \\\n    --gateway-id ${Cluster_1_NGW_2}\n\n# Associate each private subnet with their respective private route table\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_1_Private_Subnet_1} \\\n    --route-table-id ${Cluster_1_Private_RT_1}\n\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_1_Private_Subnet_2} \\\n    --route-table-id ${Cluster_1_Private_RT_2}\n \n \n \n Create a custom security group for the VPC. The default security group created with the EKS cluster only allows originating ingress traffic from the control-plane and other nodes within the cluster. \n .. code:: bash \n  # Create a security group\n export Cluster_1_SG=$(aws ec2 create-security-group \\\n     --group-name Cluster_1_Security_Group \\\n     --description \"Security group for Cluster 1\" \\\n     --vpc-id ${Cluster_1_VPC} \\\n     --tag-specifications \"ResourceType=security-group,Tags=[{Key=Name,Value=Cluster_1_SG}]\" \\\n     --region ${AWS_REGION} \\\n     --output text \\\n     --query 'GroupId'\n )\n\n # Add an inbound rule for all ingress traffic from the control-plane and other worker nodes within the cluster. An inbound rule for all ingress traffic from Cluster 2 will be added in the next section.\n aws ec2 authorize-security-group-ingress \\\n     --group-id ${Cluster_1_SG} \\\n     --protocol all \\\n     --port 0 \\\n     --source-group ${Cluster_1_SG}\\\n     --region ${AWS_REGION}\n \n \n \n You now have a virtual private cloud, subnets, nat gateway, internet gateway, and a route table. You can create an EKS cluster without a CNI and request to use our custom VNet and subnet. \n .. code:: bash \n  cat <<EOF >eks-cluster-1.yaml\n apiVersion: eksctl.io/v1alpha5\n kind: ClusterConfig\n\n metadata:\n   name: ${NAME}\n   region: ${AWS_REGION}\n vpc:\n   subnets:\n     private:\n       ${AWS_REGION}a: \n         id: ${Cluster_1_Private_Subnet_1}\n       ${AWS_REGION}b:  \n         id: ${Cluster_1_Private_Subnet_2}\n\n managedNodeGroups:\n - name: ng-1\n     instanceType: t3.small\n     securityGroups:\n       attachIDs: [\"${Cluster_1_SG}\"]\n     desiredCapacity: 2\n     privateNetworking: true\n     # Taint nodes so that application pods are\n     # not scheduled/executed until Cilium is deployed.\n     # Alternatively, see the note below.\n     taints:\n     - key: \"node.cilium.io/agent-not-ready\"\n         value: \"true\"\n         effect: \"NoExecute\"\n EOF\n\n eksctl create cluster -f ./eks-cluster-1.yaml\n \n \n \n Install cluster two\n################### \n \n \n Create environmental variables that will be appended to each resource name. \n .. code:: bash \n export NAME=\"$(whoami)-$RANDOM\"\nexport AWS_REGION=\"eu-west-2\"\n \n \n \n Create a VPC \n .. note::\nAvoid using the  172.17.0.0/16  CIDR range for your VPC to prevent potential issues since certain  AWS services <https://docs.aws.amazon.com/vpc/latest/userguide/vpc-cidr-blocks.html> __ utilize this range. \n .. code:: bash \n Cluster_2_VPC=$(aws ec2 create-vpc \\\n    --cidr-block 10.1.0.0/16 \\\n    --tag-specifications \"ResourceType=vpc,Tags=[{Key=Name,Value=Cluster_2_VPC}]\" \\\n    --region ${AWS_REGION} \\\n    --query 'Vpc.{VpcId:VpcId}' \\\n    --output text\n)\n \n \n \n Create Subnets. \n .. code:: bash \n # Create public subnets\nexport Cluster_2_Public_Subnet_1=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --cidr-block 10.1.1.0/24 \\\n    --availability-zone ${AWS_REGION}a \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_2_Public_Subnet_1}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text \n)\n\nexport Cluster_2_Public_Subnet_2=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --cidr-block 10.1.2.0/24 \\\n    --availability-zone ${AWS_REGION}b \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_2_Public_Subnet_2}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text \n)\n\n# Create private subnets\nexport Cluster_2_Private_Subnet_1=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --cidr-block 10.1.3.0/24 \\\n    --availability-zone ${AWS_REGION}a \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_2_Private_Subnet_1}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text \n)\n\nexport Cluster_2_Private_Subnet_2=$(aws ec2 create-subnet \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --cidr-block 10.1.4.0/24 \\\n    --availability-zone ${AWS_REGION}b \\\n    --tag-specifications \"ResourceType=subnet, Tags=[{Key=Name,Value=Cluster_2_Private_Subnet_2}]\" \\\n    --query 'Subnet.{SubnetId:SubnetId}' \\\n    --output text\n)\n \n \n \n Create an internet and NAT gateway, then attach it to the VPC. \n .. code:: bash \n # Create an internet gateway\nexport Cluster_2_IGW=$(aws ec2 create-internet-gateway \\\n    --tag-specifications \"ResourceType=internet-gateway, Tags=[{Key=Name,Value=Cluster_2_IGW}]\" \\\n    --query 'InternetGateway.InternetGatewayId' \\\n    --region ${AWS_REGION} \\\n    --output text\n)\n\n# Attach the internet gateway to the VPC\naws ec2 attach-internet-gateway \\\n    --internet-gateway-id ${Cluster_2_IGW} \\\n    --vpc-id ${Cluster_2_VPC}\n\n# Create elastic IP addresses\nCluster_2_EIP_1=$(aws ec2 allocate-address \\\n    --domain vpc \\\n     --tag-specifications \"ResourceType=elastic-ip, Tags=[{Key=Name,Value=Cluster_2_EIP_1}]\" \\\n    --query 'AllocationId' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\nCluster_2_EIP_2=$(aws ec2 allocate-address \\\n    --domain vpc \\\n     --tag-specifications \"ResourceType=elastic-ip, Tags=[{Key=Name,Value=Cluster_2_EIP_2}]\" \\\n    --query 'AllocationId' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\n# Create NAT gateways\nCluster_2_NGW_1=$(aws ec2 create-nat-gateway \\\n    --subnet-id ${Cluster_2_Public_Subnet_1} \\\n    --allocation-id ${Cluster_2_EIP_1} \\\n    --tag-specifications \"ResourceType=natgateway, Tags=[{Key=Name,Value=Cluster_2_NGW_1}]\" \\\n    --query 'NatGateway.{NatGatewayId:NatGatewayId}' \\\n    --output text\n)\n\nCluster_2_NGW_2=$(aws ec2 create-nat-gateway \\\n    --subnet-id ${Cluster_2_Public_Subnet_2} \\\n    --allocation-id ${Cluster_2_EIP_2} \\\n    --tag-specifications \"ResourceType=natgateway, Tags=[{Key=Name,Value=Cluster_2_NGW_2}]\" \\\n    --query 'NatGateway.{NatGatewayId:NatGatewayId}' \\\n    --output text\n)\n \n \n \n Create route tables, routes, and route table associations. \n .. code:: bash \n # Create a public route table\nexport Cluster_2_Public_RT=$(aws ec2 create-route-table \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --tag-specifications \"ResourceType=route-table, Tags=[{Key=Name,Value=Cluster_2_Public_RT}]\" \\\n    --query 'RouteTable.{RouteTableId:RouteTableId}' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\n# Add a route to the internet gateway\naws ec2 create-route \\\n    --route-table-id ${Cluster_2_Public_RT} \\\n    --destination-cidr-block 0.0.0.0/0 \\\n    --gateway-id ${Cluster_2_IGW}\n\n# Associate public subnets with the public route table\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_2_Public_Subnet_1} \\\n    --route-table-id ${Cluster_2_Public_RT}\n\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_2_Public_Subnet_2} \\\n    --route-table-id ${Cluster_2_Public_RT}\n\n# Create private route tables for each private subnet\nexport Cluster_2_Private_RT_1=$(aws ec2 create-route-table \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --tag-specifications \"ResourceType=route-table, Tags=[{Key=Name,Value=Cluster_2_Private_RT_1}]\" \\\n    --query 'RouteTable.{RouteTableId:RouteTableId}' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\nexport Cluster_2_Private_RT_2=$(aws ec2 create-route-table \\\n    --vpc-id ${Cluster_2_VPC} \\\n    --tag-specifications \"ResourceType=route-table, Tags=[{Key=Name,Value=Cluster_2_Private_RT_2}]\" \\\n    --query 'RouteTable.{RouteTableId:RouteTableId}' \\\n    --output text \\\n    --region ${AWS_REGION}\n)\n\n# Add routes to the NAT gateway\naws ec2 create-route \\\n    --route-table-id ${Cluster_2_Private_RT_1} \\\n    --destination-cidr-block 0.0.0.0/0 \\\n    --gateway-id ${Cluster_2_NGW_1}\n\naws ec2 create-route \\\n    --route-table-id ${Cluster_2_Private_RT_2} \\\n    --destination-cidr-block 0.0.0.0/0 \\\n    --gateway-id ${Cluster_2_NGW_2}\n\n# Associate each private subnet with their respective private route table\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_2_Private_Subnet_1} \\\n    --route-table-id ${Cluster_2_Private_RT_1}\n\naws ec2 associate-route-table \\\n    --subnet-id ${Cluster_2_Private_Subnet_2} \\\n    --route-table-id ${Cluster_2_Private_RT_2}\n \n \n \n Create a custom security group for the VPC. The default security group created with the EKS cluster only allows originating ingress traffic from the control-plane and other nodes within the cluster. \n .. code:: bash \n  # Create Security Group\n export Cluster_2_SG=$(aws ec2 create-security-group \\\n     --group-name Cluster_2_Security_Group \\\n     --description \"Security group for Cluster 2\" \\\n     --tag-specifications \"ResourceType=security-group,Tags=[{Key=Name,Value=Cluster_2_SG}]\" \\\n     --vpc-id ${Cluster_2_VPC} \\\n     --region ${AWS_REGION} \\\n     --output text \\\n     --query 'GroupId'\n )\n\n # Add an inbound rule for all ingress traffic from the control-plane and other worker nodes within the cluster.\n aws ec2 authorize-security-group-ingress \\\n     --group-id ${Cluster_2_SG} \\\n     --protocol all \\\n     --port 0 \\\n     --source-group ${Cluster_2_SG}\\\n     --region ${AWS_REGION}\n \n # Add an inbound rule for all ingress traffic from Cluster 1\n aws ec2 authorize-security-group-ingress \\\n     --group-id ${Cluster_2_SG} \\\n     --protocol all \\\n     --port 0 \\\n     --source-group ${Cluster_1_SG}\\\n     --region ${AWS_REGION}\n\n # In Cluster 1's security group, add an inbound rule for all ingress traffic from cluster 2.\n aws ec2 authorize-security-group-ingress \\\n     --group-id ${Cluster_1_SG} \\\n     --protocol all \\\n     --port 0 \\\n     --source-group ${Cluster_2_SG}\\\n     --region ${AWS_REGION}\n \n \n \n You now have a virtual private cloud, subnets, NAT gateway, internet gateway, and a route table. You can create an EKS cluster without a CNI and request to use our custom VNet and subnet. \n .. code:: bash \n  cat <<EOF >eks-cluster-2.yaml\n apiVersion: eksctl.io/v1alpha5\n kind: ClusterConfig\n\n metadata:\n name: ${NAME}\n region: ${AWS_REGION}\n vpc:\n   subnets:\n     private:\n       ${AWS_REGION}a: \n         id: ${Cluster_2_Private_Subnet_1}\n       ${AWS_REGION}b:  \n         id: ${Cluster_2_Private_Subnet_2}\n\n managedNodeGroups:\n   - name: ng-2\n     instanceType: t3.small\n     securityGroups:\n       attachIDs: [${Cluster_2_SG}]\n     desiredCapacity: 2\n     privateNetworking: true\n     taints:\n       - key: \"node.cilium.io/agent-not-ready\"\n         value: \"true\"\n         effect: \"NoExecute\"\n EOF\n eksctl create cluster -f ./eks-cluster-2.yaml\n \n \n \n Peering virtual networks\n######################## \n \n \n Create VPC peering between the two VPCs. \n .. code:: bash \n  # Create VPC peering connection\n export PEERING_CONNECTION_ID=$(aws ec2 create-vpc-peering-connection \\\n     --vpc-id ${Cluster_1_VPC} \\\n     --peer-vpc-id ${Cluster_2_VPC} \\\n     --peer-region ${AWS_REGION} \\\n     --output text \\\n     --query 'VpcPeeringConnection.VpcPeeringConnectionId'\n )\n\n # Grab the first VPC peering\n export PEERING_REQUEST_ID=$(aws ec2 describe-vpc-peering-connections \\\n     --filters \"Name=requester-vpc-info.vpc-id,Values=${Cluster_1_VPC}\" \\\n     --query \"VpcPeeringConnections[0].VpcPeeringConnectionId\" \\\n     --output text\n )\n\n # Accept VPC peering request\n aws ec2 accept-vpc-peering-connection \\\n     --vpc-peering-connection-id ${PEERING_REQUEST_ID} \\\n     --region ${AWS_REGION}\n \n \n \n Forward traffic from Cluster 1 VPC to Cluster 2 VPC. \n .. code:: bash \n  # Cluster 1\n # Add route to Private Route Table 1\n aws ec2 create-route \\\n     --route-table-id ${Cluster_1_Private_RT_1} \\\n     --destination-cidr-block 10.1.0.0/16 \\\n     --vpc-peering-connection-id ${PEERING_CONNECTION_ID} \\\n     --region ${AWS_REGION}\n\n # Add route to Private Route Table 2\n aws ec2 create-route \\\n     --route-table-id ${Cluster_1_Private_RT_2} \\\n     --destination-cidr-block 10.1.0.0/16 \\\n     --vpc-peering-connection-id ${PEERING_CONNECTION_ID} \\\n     --region ${AWS_REGION}\n \n \n \n Forward traffic from Cluster 2 VPC to Cluster 1 VPC. \n .. code:: bash \n  # Cluster 2\n # Add route to Private Route Table 1\n aws ec2 create-route \\\n     --route-table-id ${Cluster_2_Private_RT_1} \\\n     --destination-cidr-block 10.0.0.0/16 \\\n     --vpc-peering-connection-id ${PEERING_CONNECTION_ID} \\\n     --region ${AWS_REGION}\n\n # Add route to Private Route Table 2\n aws ec2 create-route \\\n     --route-table-id ${Cluster_2_Private_RT_2} \\\n     --destination-cidr-block 10.0.0.0/16 \\\n     --vpc-peering-connection-id ${PEERING_CONNECTION_ID} \\\n     --region ${AWS_REGION}\n \n \n \n Nodes in different clusters can now communicate directly. All clustermesh requirements are fulfilled.\nInstructions for enabling clustermesh are detailed in the :ref: gs_clustermesh  section.",
  "item_type": "unknown",
  "module_path": "/tmp/cilium-repo/Documentation/network/clustermesh/eks-clustermesh-prep.rst",
  "extracted_at": "2025-09-03T01:13:29.200006Z"
}